{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.txt','\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = data.copy()\n",
    "# normalize X\n",
    "high = data['X'].max()\n",
    "low = data['X'].min()\n",
    "normalized_data['X'] = ((data['X'] - low) / (high - low)) * 10 # within [-0.1,0.1]\n",
    "\n",
    "# normalize Y\n",
    "high = data['Y'].max()\n",
    "low = data['Y'].min()\n",
    "normalized_data['Y'] = ((data['Y'] - low) / (high - low)) * 10 # within [-0.1,0.1]\n",
    "\n",
    "# timestamp / 40\n",
    "normalized_data['timestamp'] = (data['timestamp'] / 40).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data.to_csv('data_normalized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(128,), (128, 8, 2), (128, 4, 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# functions for generate a batch of sample\n",
    "'''\n",
    "    Input:\n",
    "        data: the CSV\n",
    "        num_data: size of batch\n",
    "    Output:\n",
    "        IDs: list of selected IDs\n",
    "        input_sequence: batch with shape (num_data,input_length, 2)\n",
    "        output_sequence: batch with shape (num_data, output_length, 2)\n",
    "'''\n",
    "from random import shuffle\n",
    "def get_batch(data,num_data = 128,input_length = 8, output_length = 4):\n",
    "    # evaluate the total length of series required\n",
    "    total_length = input_length + output_length\n",
    "    # filter out the series that has at least the number of `total_length` long\n",
    "    id_counts = data.groupby('ID').ID.count()\n",
    "    # get a table of candidate id, whose sequence is longer than (or eq. to) total_length\n",
    "    candidate_id_counts = id_counts[id_counts >= total_length]\n",
    "    # get the random sequence...\n",
    "    # the candidate_id_counts is a series with ID as x and count as y\n",
    "    # to get the usable indices, get list series as a list of tuple like (id, count),\n",
    "    # then take the first one (list of id)\n",
    "    # and make it a list, and shuffle on it\n",
    "    random_ids_selected = list(map(lambda tup: tup[0],candidate_id_counts.items()))\n",
    "    shuffle(random_ids_selected)\n",
    "    \n",
    "    selected_ids = []\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "    # retrieve the coordinates of the sequence (from the beginning to `total_length`)\n",
    "    for i in random_ids_selected[:num_data]:\n",
    "        selected_ids.append(i)\n",
    "        # select X,Y from ID where ID == i order by timestamp...\n",
    "        sequence_of_i = data[data.ID == i].sort_values(by = \"timestamp\")[[\"X\",\"Y\"]]\n",
    "        # divide the sequence into two parts...\n",
    "        input_sequence = sequence_of_i.iloc[:input_length]\n",
    "        target_sequence = sequence_of_i.iloc[input_length:total_length]\n",
    "        # and append the new sequence to existing arrays\n",
    "        input_batch.append(np.array(input_sequence))\n",
    "        target_batch.append(np.array(target_sequence))\n",
    "    \n",
    "    # return and array of selected ids as well as the batch...\n",
    "    return np.stack(selected_ids), np.stack(input_batch), np.stack(target_batch)\n",
    "    \n",
    "\n",
    "# verify the shape is right...\n",
    "list(map(lambda a: a.shape,get_batch(normalized_data)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "    Visualize the traces in a batch\n",
    "    If batch size = B, sequence length = L...\n",
    "    Input:\n",
    "        batch: batch of sequence of arbitrary length, i.e. array of shape (B,L,2)\n",
    "    Output:\n",
    "        None, a graph will be drawn instead..\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_trace(batch,target_batch):\n",
    "    # first we make sure that the shape of the batch looks like (_, _, 2)\n",
    "    def check_shape(shape):\n",
    "        if len(shape) != 3:\n",
    "            raise ValueError(\"batch should be in 3 dimension\")\n",
    "        if shape[-1] != 2:\n",
    "            raise ValueError(\"Last axis should be storing X,Y coordinates\")\n",
    "    \n",
    "    check_shape(batch.shape)\n",
    "    check_shape(target_batch.shape)\n",
    "    # sub-routine for draw a particular batch\n",
    "    def draw_batch(batch,linestyle = None):\n",
    "        # now extract the dimension\n",
    "        batch_size, sequence_length, _ = batch.shape\n",
    "        for batch_id in range(batch_size):\n",
    "            # pick a random color for this trace\n",
    "            line_color = np.random.rand(3)\n",
    "            for sequence_pos in range(sequence_length - 1):\n",
    "                # get the two adjacent coordinates\n",
    "                cur_coord = batch[batch_id, sequence_pos]\n",
    "                next_coord = batch[batch_id, sequence_pos + 1]\n",
    "                # and draw the line...\n",
    "                # sneaky plot function requires x-coordinates to be put in the same argument, so are y-coordinates...\n",
    "                plt.plot([cur_coord[0],next_coord[0]],\n",
    "                         [cur_coord[1],next_coord[1]],\n",
    "                         linestyle = linestyle,\n",
    "                         c = line_color)\n",
    "    \n",
    "    draw_batch(batch)\n",
    "    draw_batch(target_batch, \":\")\n",
    "    # finally show the graph\n",
    "#     plt.show()\n",
    "    \n",
    "# let's test this visualization,\n",
    "_, input_batch, target_batch = get_batch(normalized_data,128,16,8)\n",
    "visualize_trace(input_batch,target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets define a vanilla LSTM model\n",
    "'''\n",
    "    According to the paper, there should be an RNN that takes a sequence and gives a sequence (like seq-to-seq)\n",
    "    except this output are hidden layers, like vectors of length 128\n",
    "    To interpret such result, a dense layer with ReLU is added to condense the output to 5 numbers,\n",
    "    namely, the mean_x, mean_y, sxx, syy, and sxy \n",
    "    of the bivariate gaussian of the probability of the agent at that given timestamp.\n",
    "    \n",
    "    The negative log likelihood between the real coordinate and this estimated distribution will be the loss.\n",
    "'''\n",
    "# first, the loss function, in Keras backend\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "'''\n",
    "    The function takes a series of params of bivariate normal distribution, and a batch of observed coordinates,\n",
    "    and return the log likelikhood of them...\n",
    "    \n",
    "    probability (likelihood) of the observed point (x,y) given the 5 parameters (mx,my,sx,sy,sp):\n",
    "        det(2 * pi * [[sx,sp],[sp,sy]]) ^(-0.5) \n",
    "            * exp(-0.5 * ((x,y) - (mx,my)).T * [[sx,sp],[sp,sy]] * ((x,y) - (mx,my)))\n",
    "    \n",
    "    after taking log and add a minus (* -1)...\n",
    "        -( (-0.5 * log(4 * pi ^ 2 * sx * sy - sp * sp)) + (-0.5 * (...)))\n",
    "    \n",
    "    If batch size = B, sequence length = D...\n",
    "    Input:\n",
    "        Batch bivariate parameters (estimated): K.variable with shape (B,D,5),\n",
    "        Batch of overserved coordinates (label): K.variable with shape (B,D,2)\n",
    "    \n",
    "    Output:\n",
    "        a scaler (K.variable with shape ()), which is the sum of negative log likelihood\n",
    "'''\n",
    "\n",
    "def negative_log_likelihood_loss(batch_observed_coordinates,batch_bivariate_params):\n",
    "    # first check the dimension...\n",
    "    input_shape = K.int_shape(batch_bivariate_params)\n",
    "    target_shape = K.int_shape(batch_observed_coordinates)\n",
    "    \n",
    "    if len(input_shape) != 3 or len(target_shape) != 3:\n",
    "        raise ValueError(\"Dimension of both tensors should be 3\")\n",
    "    \n",
    "    if input_shape[0] != target_shape[0]:\n",
    "        raise ValueError(\"Batch size of both tensors should be the same\")\n",
    "    \n",
    "    if input_shape[1] != target_shape[1]:\n",
    "        raise ValueError(\"Sequence length of both tensors should be the same\")\n",
    "    \n",
    "    if input_shape[2] != 5:\n",
    "        raise ValueError(\"Number of predicted parameters should be 5. Namely, (mx,my,sx,sy,sp)\")\n",
    "    \n",
    "    if target_shape[2] != 2:\n",
    "        raise ValueError(\"Dimension of target coordinates should be 2. Namely, (x,y)\")\n",
    "    \n",
    "    # then split the tensors into (mx,my,sx,sy,sp)...\n",
    "    # all of them should be of shape (B,D)\n",
    "    batch_mx = batch_bivariate_params[:,:,0]\n",
    "    batch_my = batch_bivariate_params[:,:,1]\n",
    "    batch_sx = batch_bivariate_params[:,:,2]\n",
    "    batch_sy = batch_bivariate_params[:,:,3]\n",
    "    batch_sp = batch_bivariate_params[:,:,4]\n",
    "    \n",
    "    batch_x = batch_observed_coordinates[:,:,0]\n",
    "    batch_y = batch_observed_coordinates[:,:,1]\n",
    "    \n",
    "    dx = batch_x - batch_mx # (B,D), (x - mx)\n",
    "    dy = batch_y - batch_my # (B,D), (y - my)\n",
    "    dydx = Multiply()([dx,dy])\n",
    "    \n",
    "    batch_x_change =  K.concatenate([batch_mx[:,0:1], batch_mx[:,1:] - batch_mx[:,:-1]])\n",
    "    batch_y_change =  K.concatenate([batch_my[:,0:1], batch_my[:,1:] - batch_my[:,:-1]])\n",
    "    target_x_change =  K.concatenate([batch_x[:,0:1], batch_x[:,1:] - batch_x[:,:-1]])\n",
    "    target_y_change =  K.concatenate([batch_y[:,0:1], batch_y[:,1:] - batch_y[:,:-1]])\n",
    "    \n",
    "    xy_dot = Multiply()([batch_x_change,target_x_change]) + Multiply()([batch_y_change,target_y_change])\n",
    "    batch_change_norm = K.sqrt(K.square(batch_x_change) + K.square(batch_y_change))\n",
    "    target_change_norm = K.sqrt(K.square(target_x_change) + K.square(target_y_change))\n",
    "    \n",
    "    norm_prod = Multiply()([batch_change_norm,target_change_norm]) + 1e-6\n",
    "    norm_prod_inv = K.pow(norm_prod,-1) # for numerical stability\n",
    "    direction_loss =  - K.mean(Multiply()([xy_dot,norm_prod_inv]))\n",
    "#     det_inv = K.print_tensor(K.pow(det,-1), message=\"det_inv\") # (B,D), (sx * sy - sp^2) ^-1\n",
    "    # (B,D), (dx^2 * sy - 2 * sp * dy * dx + sx * dy^2)\n",
    "    exp = -0.5 * Multiply()([K.square(dx),batch_sy]) - 2 * Multiply()([dydx, batch_sp]) + Multiply()([K.square(dy),batch_sx])\n",
    "    # (B,D), -0.5 * (dx^2 * sy - 2 * sp * dy * dx + sx * dy^2) * det(Cov)^(-1)\n",
    "#     exp = Multiply()([det_inv,exp]) * (-0.5)\n",
    "    \n",
    "    # evaluate the final NLL\n",
    "    '''\n",
    "        A remark here: it is determined that the determininat of the covariance matrix will not be considered as a loss,\n",
    "        as the value of that generally became very large (under the log function)\n",
    "        therefore only the exponents are used as the loss\n",
    "    '''\n",
    "#     batch_nll = - (exp)\n",
    "    batch_nll = K.square(dx) + K.square(dy) - 0.1 * exp + 0.1 * direction_loss\n",
    "    batch_error_total = K.sum(batch_nll, axis = 1) # (B,) sum of NLL in a sequence...\n",
    "    return K.print_tensor(K.mean(batch_error_total, axis = 0)) # (), average of sum of NLL...\n",
    "\n",
    "# now test it...\n",
    "# a regular 0-centered, non-skewing normal\n",
    "[mx,my,sx,sy,sp] = [0,0,.1,.1,0.]\n",
    "bivariate_params = np.array([[[mx,my,sx,sy,sp]]]) # (1,1,5)\n",
    "target_point = np.array([[[-0.,0]]]) # (1,1,2)\n",
    "\n",
    "bivariate_ph = K.variable(value = bivariate_params, dtype = \"float32\")\n",
    "target_ph = K.variable(value = target_point, dtype = \"float32\")\n",
    "nll = negative_log_likelihood_loss(target_ph,bivariate_ph)\n",
    "K.eval(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_layer(batch_predicted_coordinates):\n",
    "    return K.cumsum(batch_predicted_coordinates,axis = 1)\n",
    "    \n",
    "def check_tensor(batch_observed_coordinates,batch_predicted_coordinates):\n",
    "    input_shape = K.int_shape(batch_predicted_coordinates)\n",
    "    target_shape = K.int_shape(batch_observed_coordinates)\n",
    "\n",
    "    if len(input_shape) != 3 or len(target_shape) != 3:\n",
    "        raise ValueError(\"Dimension of both tensors should be 3\")\n",
    "\n",
    "    if input_shape[0] != target_shape[0]:\n",
    "        raise ValueError(\"Batch size of both tensors should be the same\")\n",
    "\n",
    "    if input_shape[1] != target_shape[1]:\n",
    "        raise ValueError(\"Sequence length of both tensors should be the same\")\n",
    "\n",
    "    if input_shape[2] != 2:\n",
    "        raise ValueError(\"Number of predicted parameters should be 2. Namely, (mx,my)\")\n",
    "\n",
    "    if target_shape[2] != 2:\n",
    "        raise ValueError(\"Dimension of target coordinates should be 2. Namely, (x,y)\")\n",
    "    \n",
    "def ms_loss(input_tensor):\n",
    "    batch_observed_coordinates,batch_predicted_coordinates = input_tensor\n",
    "    # first check the dimension...\n",
    "    check_tensor(batch_observed_coordinates,batch_predicted_coordinates)\n",
    "    \n",
    "    diff = K.square(batch_predicted_coordinates - batch_observed_coordinates)\n",
    "\n",
    "    return K.sum(diff)\n",
    "\n",
    "def dir_loss(input_tensor):\n",
    "    batch_observed_coordinates,batch_predicted_coordinates = input_tensor\n",
    "    check_tensor(batch_observed_coordinates,batch_predicted_coordinates)\n",
    "    \n",
    "    predict_dir = batch_predicted_coordinates[:,1:] - batch_predicted_coordinates[:,:-1]\n",
    "    \n",
    "    target_dir = batch_observed_coordinates[:,1:] - batch_observed_coordinates[:,:-1]\n",
    "    \n",
    "#     predic_dir_norm = \n",
    "    # this is to maximize the cosine (therefore angle = 0)\n",
    "    return K.sum(K.square((predict_dir - target_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then, the Vanilla LSTM\n",
    "from keras.models import Model\n",
    "from keras.initializers import RandomNormal\n",
    "from keras import optimizers\n",
    "def vanilla_lstm_model(num_hidden, input_length, predict_length, lr = 1e-3):\n",
    "# def vanilla_lstm_model(num_hidden,input_length, predict_length, input_tensor, target_tensor):\n",
    "    total_length = input_length + predict_length\n",
    "    # the input\n",
    "    input_sequence = Input(shape = (total_length,2), name = 'input_sequence', dtype = 'float32') # (T, 2)\n",
    "    target_sequence = Input(shape = (total_length,2), name = 'target_sequence', dtype = 'float32') # (T, 2)\n",
    "    lstm = LSTM(num_hidden, return_sequences = True)(input_sequence) # (B,T,num_hidden)\n",
    "#     params = TimeDistributed(Dense(5, activation = 'elu'), name = 'params')(lstm) # (B,T,5)\n",
    "    predicted_coordinates_raw = TimeDistributed(Dense(2, activation = 'elu'), name = 'params')(lstm)\n",
    "    \n",
    "    # retrieve the prediction\n",
    "    extract_target_sequence_layer = Lambda(lambda x: x[:,input_length:,:])\n",
    "    predicted_coordinates_masked = extract_target_sequence_layer(predicted_coordinates_raw)\n",
    "    target_coordinates_masked = extract_target_sequence_layer(target_sequence)\n",
    "    # the output layer\n",
    "    predicted_output = Lambda(infer_layer, name = \"predict\")(predicted_coordinates_masked)\n",
    "    # compute the loss\n",
    "    \n",
    "    # first part: the square loss\n",
    "    sq_loss = Lambda(ms_loss, name = 'square_loss')([target_coordinates_masked, predicted_output])\n",
    "    # second part: the direction loss\n",
    "    ori_loss = Lambda(dir_loss, name = 'dir_loss')([target_coordinates_masked, predicted_output])\n",
    "    \n",
    "    loss = Lambda(lambda ts: ts[0] + ts[1],name = 'loss')([sq_loss, ori_loss])\n",
    "    \n",
    "    model = Model(\n",
    "        inputs = [input_sequence,target_sequence],\n",
    "        outputs = [predicted_output,loss])\n",
    "    \n",
    "    model.compile(optimizer=optimizers.RMSprop(lr = lr, clipvalue = 10., decay = 1e-6),\n",
    "                  # since there are two outputs of the model, the estimated params and the NLL,\n",
    "                  # their loss value should be specified.\n",
    "                  # for params there are no loss regarding its value, but I just assign a zero as loss (or the computational graph will break)\n",
    "                  # I made it loss - loss = 0.\n",
    "                  # and for the NLL, return the loss as-is.\n",
    "                  loss= {\n",
    "                        'predict': lambda _, loss: loss - loss, # meh...\n",
    "                          'loss': lambda _, loss: loss\n",
    "                    })\n",
    "    \n",
    "    return input_sequence, target_sequence, model, predicted_output,loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# helper function for monitoring training progress\n",
    "from scipy.stats import multivariate_normal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "'''\n",
    "    Given a set of parameter (array of 5), visualize the heatmap of the bivariate normal distribution\n",
    "'''\n",
    "def draw_heatmap(params):\n",
    "    resolution = 100\n",
    "    interval = 1. / resolution\n",
    "    \n",
    "    x,y = np.mgrid[0:1:interval,0:1:interval]\n",
    "    pos = np.empty(x.shape + (2,))\n",
    "    pos[:,:,0] = x\n",
    "    pos[:,:,1] = y\n",
    "    result_distribution = None\n",
    "    for param in params:\n",
    "        mx,my,sx,sy,sp = param\n",
    "        F = multivariate_normal([mx,my],[[sx,sp],[sp,sy]])\n",
    "        result_distribution = F.pdf(pos) if result_distribution is None else result_distribution + F.pdf(pos)\n",
    "    plt.contourf(x,y,result_distribution)\n",
    "\n",
    "# try it out\n",
    "# fig = plt.figure()\n",
    "draw_heatmap(np.array([[0.3,0.1,0.4,0.2,.2],[0.9,0.2,0.1,0.9,0.]]))\n",
    "visualize_trace(input_batch,target_batch)\n",
    "# draw_heatmap(0.3,0.2,0.01,0.2,0.,fig)\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "    Draw the mean of the predicted params of all timestamps\n",
    "'''\n",
    "import matplotlib.cm as cm\n",
    "def draw_mean(params):\n",
    "    plt.xlim(0,10)\n",
    "    plt.ylim(0,10)\n",
    "    \n",
    "    \n",
    "    for batch in range(params.shape[0]):\n",
    "        line_color = np.random.rand(3) # choose a color to tell that these scatter points belong to the same prediction\n",
    "        xy_series = params[batch,:,:] # (D,2)\n",
    "        # prgressively change the color to indicate the direction\n",
    "        colors = cm.rainbow(np.linspace(0, 1, params.shape[1]))\n",
    "        plt.scatter(xy_series[:,0],xy_series[:,1], c = colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, LambdaCallback\n",
    "from livelossplot import PlotLossesKeras # kudos :)\n",
    "def get_callbacks(input_batch_padded,target_batch_padded,finetune = False):\n",
    "    # prepare callbacks\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='loss', \n",
    "                                  factor=0.5,\n",
    "                                  patience=50, \n",
    "                                  min_lr=1e-6)\n",
    "    csv_logger = CSVLogger(\"log.csv\")\n",
    "\n",
    "    def visualize_prediction(epoch, logs):\n",
    "        params, loss = model.predict([input_batch_padded,target_batch_padded])\n",
    "        # visualize the trace, as well as the distributions generated by the params...\n",
    "        # first clear the previous drawing...\n",
    "    #     try:\n",
    "        plt.gcf().clear()\n",
    "        visualize_trace(input_batch,target_batch)\n",
    "    #     params = params[:,INPUT_LENGTH + 1, :] # (B,5), and it should be the params immediately after the input\n",
    "    #     draw_heatmap(params)\n",
    "        draw_mean(params)\n",
    "        filename = '{}.png' if not finetune else '{}-finetune.png'\n",
    "        plt.savefig(filename.format(epoch))\n",
    "\n",
    "    plot_callback = LambdaCallback(on_epoch_begin = visualize_prediction)\n",
    "    \n",
    "    return [reduce_lr, \n",
    "            csv_logger,\n",
    "            #PlotLossesKeras(),\n",
    "           # plot_callback\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_sequence (InputLayer)     (None, 12, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 12, 128)      67072       input_sequence[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "params (TimeDistributed)        (None, 12, 2)        258         lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 4, 2)         0           params[0][0]                     \n",
      "                                                                 target_sequence[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "target_sequence (InputLayer)    (None, 12, 2)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "predict (Lambda)                (None, 4, 2)         0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "square_loss (Lambda)            ()                   0           lambda_9[1][0]                   \n",
      "                                                                 predict[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dir_loss (Lambda)               ()                   0           lambda_9[1][0]                   \n",
      "                                                                 predict[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "loss (Lambda)                   ()                   0           square_loss[0][0]                \n",
      "                                                                 dir_loss[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 67,330\n",
      "Trainable params: 67,330\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 204 samples, validate on 52 samples\n",
      "Epoch 1/1500\n",
      "204/204 [==============================] - 1s 4ms/step - loss: 4738.0728 - predict_loss: 0.0000e+00 - loss_loss: 4738.0728 - val_loss: 1976.0968 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1976.0968\n",
      "Epoch 2/1500\n",
      "204/204 [==============================] - 0s 532us/step - loss: 2110.7132 - predict_loss: 0.0000e+00 - loss_loss: 2110.7132 - val_loss: 1565.7340 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1565.7340\n",
      "Epoch 3/1500\n",
      "204/204 [==============================] - 0s 530us/step - loss: 1767.1897 - predict_loss: 0.0000e+00 - loss_loss: 1767.1897 - val_loss: 1268.3199 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1268.3199\n",
      "Epoch 4/1500\n",
      "204/204 [==============================] - 0s 573us/step - loss: 1478.8565 - predict_loss: 0.0000e+00 - loss_loss: 1478.8565 - val_loss: 1086.8917 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1086.8917\n",
      "Epoch 5/1500\n",
      "204/204 [==============================] - 0s 554us/step - loss: 1286.4829 - predict_loss: 0.0000e+00 - loss_loss: 1286.4829 - val_loss: 874.9778 - val_predict_loss: 0.0000e+00 - val_loss_loss: 874.9778\n",
      "Epoch 6/1500\n",
      "204/204 [==============================] - 0s 560us/step - loss: 1126.3625 - predict_loss: 0.0000e+00 - loss_loss: 1126.3625 - val_loss: 829.0348 - val_predict_loss: 0.0000e+00 - val_loss_loss: 829.0348\n",
      "Epoch 7/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 1010.4314 - predict_loss: 0.0000e+00 - loss_loss: 1010.4314 - val_loss: 653.5850 - val_predict_loss: 0.0000e+00 - val_loss_loss: 653.5850\n",
      "Epoch 8/1500\n",
      "204/204 [==============================] - 0s 572us/step - loss: 928.2160 - predict_loss: 0.0000e+00 - loss_loss: 928.2160 - val_loss: 692.6315 - val_predict_loss: 0.0000e+00 - val_loss_loss: 692.6315\n",
      "Epoch 9/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 844.2472 - predict_loss: 0.0000e+00 - loss_loss: 844.2472 - val_loss: 498.1601 - val_predict_loss: 0.0000e+00 - val_loss_loss: 498.1601\n",
      "Epoch 10/1500\n",
      "204/204 [==============================] - 0s 551us/step - loss: 753.8999 - predict_loss: 0.0000e+00 - loss_loss: 753.8999 - val_loss: 573.7027 - val_predict_loss: 0.0000e+00 - val_loss_loss: 573.7027\n",
      "Epoch 11/1500\n",
      "204/204 [==============================] - 0s 560us/step - loss: 714.3197 - predict_loss: 0.0000e+00 - loss_loss: 714.3197 - val_loss: 416.0748 - val_predict_loss: 0.0000e+00 - val_loss_loss: 416.0748\n",
      "Epoch 12/1500\n",
      "204/204 [==============================] - 0s 570us/step - loss: 629.3135 - predict_loss: 0.0000e+00 - loss_loss: 629.3135 - val_loss: 461.1162 - val_predict_loss: 0.0000e+00 - val_loss_loss: 461.1162\n",
      "Epoch 13/1500\n",
      "204/204 [==============================] - 0s 533us/step - loss: 589.7017 - predict_loss: 0.0000e+00 - loss_loss: 589.7017 - val_loss: 308.0960 - val_predict_loss: 0.0000e+00 - val_loss_loss: 308.0960\n",
      "Epoch 14/1500\n",
      "204/204 [==============================] - 0s 567us/step - loss: 525.4523 - predict_loss: 0.0000e+00 - loss_loss: 525.4523 - val_loss: 391.0104 - val_predict_loss: 0.0000e+00 - val_loss_loss: 391.0104\n",
      "Epoch 15/1500\n",
      "204/204 [==============================] - 0s 564us/step - loss: 474.9008 - predict_loss: 0.0000e+00 - loss_loss: 474.9008 - val_loss: 223.1190 - val_predict_loss: 0.0000e+00 - val_loss_loss: 223.1190\n",
      "Epoch 16/1500\n",
      "204/204 [==============================] - 0s 692us/step - loss: 441.1870 - predict_loss: 0.0000e+00 - loss_loss: 441.1870 - val_loss: 290.9761 - val_predict_loss: 0.0000e+00 - val_loss_loss: 290.9761\n",
      "Epoch 17/1500\n",
      "204/204 [==============================] - 0s 623us/step - loss: 397.2103 - predict_loss: 0.0000e+00 - loss_loss: 397.2103 - val_loss: 199.0186 - val_predict_loss: 0.0000e+00 - val_loss_loss: 199.0186\n",
      "Epoch 18/1500\n",
      "204/204 [==============================] - 0s 575us/step - loss: 354.8719 - predict_loss: 0.0000e+00 - loss_loss: 354.8719 - val_loss: 205.5867 - val_predict_loss: 0.0000e+00 - val_loss_loss: 205.5867\n",
      "Epoch 19/1500\n",
      "204/204 [==============================] - 0s 568us/step - loss: 345.1662 - predict_loss: 0.0000e+00 - loss_loss: 345.1662 - val_loss: 150.3084 - val_predict_loss: 0.0000e+00 - val_loss_loss: 150.3084\n",
      "Epoch 20/1500\n",
      "204/204 [==============================] - 0s 568us/step - loss: 303.3673 - predict_loss: 0.0000e+00 - loss_loss: 303.3673 - val_loss: 201.4624 - val_predict_loss: 0.0000e+00 - val_loss_loss: 201.4624\n",
      "Epoch 21/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 285.6450 - predict_loss: 0.0000e+00 - loss_loss: 285.6450 - val_loss: 100.6498 - val_predict_loss: 0.0000e+00 - val_loss_loss: 100.6498\n",
      "Epoch 22/1500\n",
      "204/204 [==============================] - 0s 553us/step - loss: 243.1661 - predict_loss: 0.0000e+00 - loss_loss: 243.1661 - val_loss: 153.9587 - val_predict_loss: 0.0000e+00 - val_loss_loss: 153.9587\n",
      "Epoch 23/1500\n",
      "204/204 [==============================] - 0s 582us/step - loss: 257.8729 - predict_loss: 0.0000e+00 - loss_loss: 257.8729 - val_loss: 120.9993 - val_predict_loss: 0.0000e+00 - val_loss_loss: 120.9993\n",
      "Epoch 24/1500\n",
      "204/204 [==============================] - 0s 641us/step - loss: 235.1214 - predict_loss: 0.0000e+00 - loss_loss: 235.1214 - val_loss: 64.1783 - val_predict_loss: 0.0000e+00 - val_loss_loss: 64.1783\n",
      "Epoch 25/1500\n",
      "204/204 [==============================] - 0s 685us/step - loss: 199.3399 - predict_loss: 0.0000e+00 - loss_loss: 199.3399 - val_loss: 113.2176 - val_predict_loss: 0.0000e+00 - val_loss_loss: 113.2176\n",
      "Epoch 26/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 600us/step - loss: 191.1354 - predict_loss: 0.0000e+00 - loss_loss: 191.1354 - val_loss: 61.7069 - val_predict_loss: 0.0000e+00 - val_loss_loss: 61.7069\n",
      "Epoch 27/1500\n",
      "204/204 [==============================] - 0s 526us/step - loss: 179.6224 - predict_loss: 0.0000e+00 - loss_loss: 179.6224 - val_loss: 84.7678 - val_predict_loss: 0.0000e+00 - val_loss_loss: 84.7678\n",
      "Epoch 28/1500\n",
      "204/204 [==============================] - 0s 566us/step - loss: 165.3809 - predict_loss: 0.0000e+00 - loss_loss: 165.3809 - val_loss: 59.2098 - val_predict_loss: 0.0000e+00 - val_loss_loss: 59.2098\n",
      "Epoch 29/1500\n",
      "204/204 [==============================] - 0s 529us/step - loss: 175.5767 - predict_loss: 0.0000e+00 - loss_loss: 175.5767 - val_loss: 53.2334 - val_predict_loss: 0.0000e+00 - val_loss_loss: 53.2334\n",
      "Epoch 30/1500\n",
      "204/204 [==============================] - 0s 567us/step - loss: 150.5504 - predict_loss: 0.0000e+00 - loss_loss: 150.5504 - val_loss: 35.4156 - val_predict_loss: 0.0000e+00 - val_loss_loss: 35.4156\n",
      "Epoch 31/1500\n",
      "204/204 [==============================] - 0s 562us/step - loss: 143.1312 - predict_loss: 0.0000e+00 - loss_loss: 143.1312 - val_loss: 60.9520 - val_predict_loss: 0.0000e+00 - val_loss_loss: 60.9520\n",
      "Epoch 32/1500\n",
      "204/204 [==============================] - 0s 521us/step - loss: 142.8753 - predict_loss: 0.0000e+00 - loss_loss: 142.8753 - val_loss: 50.0837 - val_predict_loss: 0.0000e+00 - val_loss_loss: 50.0837\n",
      "Epoch 33/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 130.3852 - predict_loss: 0.0000e+00 - loss_loss: 130.3852 - val_loss: 29.5821 - val_predict_loss: 0.0000e+00 - val_loss_loss: 29.5821\n",
      "Epoch 34/1500\n",
      "204/204 [==============================] - 0s 529us/step - loss: 125.0816 - predict_loss: 0.0000e+00 - loss_loss: 125.0816 - val_loss: 40.1002 - val_predict_loss: 0.0000e+00 - val_loss_loss: 40.1002\n",
      "Epoch 35/1500\n",
      "204/204 [==============================] - 0s 533us/step - loss: 131.4841 - predict_loss: 0.0000e+00 - loss_loss: 131.4841 - val_loss: 46.9277 - val_predict_loss: 0.0000e+00 - val_loss_loss: 46.9277\n",
      "Epoch 36/1500\n",
      "204/204 [==============================] - 0s 507us/step - loss: 115.0497 - predict_loss: 0.0000e+00 - loss_loss: 115.0497 - val_loss: 27.0187 - val_predict_loss: 0.0000e+00 - val_loss_loss: 27.0187\n",
      "Epoch 37/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 113.3408 - predict_loss: 0.0000e+00 - loss_loss: 113.3408 - val_loss: 34.7403 - val_predict_loss: 0.0000e+00 - val_loss_loss: 34.7403\n",
      "Epoch 38/1500\n",
      "204/204 [==============================] - 0s 472us/step - loss: 96.0095 - predict_loss: 0.0000e+00 - loss_loss: 96.0095 - val_loss: 36.6054 - val_predict_loss: 0.0000e+00 - val_loss_loss: 36.6054\n",
      "Epoch 39/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 110.0597 - predict_loss: 0.0000e+00 - loss_loss: 110.0597 - val_loss: 18.5217 - val_predict_loss: 0.0000e+00 - val_loss_loss: 18.5217\n",
      "Epoch 40/1500\n",
      "204/204 [==============================] - 0s 528us/step - loss: 94.9258 - predict_loss: 0.0000e+00 - loss_loss: 94.9258 - val_loss: 20.8721 - val_predict_loss: 0.0000e+00 - val_loss_loss: 20.8721\n",
      "Epoch 41/1500\n",
      "204/204 [==============================] - 0s 497us/step - loss: 89.5781 - predict_loss: 0.0000e+00 - loss_loss: 89.5781 - val_loss: 27.6147 - val_predict_loss: 0.0000e+00 - val_loss_loss: 27.6147\n",
      "Epoch 42/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 94.4980 - predict_loss: 0.0000e+00 - loss_loss: 94.4980 - val_loss: 18.5742 - val_predict_loss: 0.0000e+00 - val_loss_loss: 18.5742\n",
      "Epoch 43/1500\n",
      "204/204 [==============================] - 0s 634us/step - loss: 79.2455 - predict_loss: 0.0000e+00 - loss_loss: 79.2455 - val_loss: 13.8840 - val_predict_loss: 0.0000e+00 - val_loss_loss: 13.8840\n",
      "Epoch 44/1500\n",
      "204/204 [==============================] - 0s 630us/step - loss: 68.9835 - predict_loss: 0.0000e+00 - loss_loss: 68.9835 - val_loss: 17.6061 - val_predict_loss: 0.0000e+00 - val_loss_loss: 17.6061\n",
      "Epoch 45/1500\n",
      "204/204 [==============================] - 0s 680us/step - loss: 69.7237 - predict_loss: 0.0000e+00 - loss_loss: 69.7237 - val_loss: 43.9191 - val_predict_loss: 0.0000e+00 - val_loss_loss: 43.9191\n",
      "Epoch 46/1500\n",
      "204/204 [==============================] - 0s 728us/step - loss: 82.5488 - predict_loss: 0.0000e+00 - loss_loss: 82.5488 - val_loss: 9.3033 - val_predict_loss: 0.0000e+00 - val_loss_loss: 9.3033\n",
      "Epoch 47/1500\n",
      "204/204 [==============================] - 0s 550us/step - loss: 69.5407 - predict_loss: 0.0000e+00 - loss_loss: 69.5407 - val_loss: 20.9623 - val_predict_loss: 0.0000e+00 - val_loss_loss: 20.9623\n",
      "Epoch 48/1500\n",
      "204/204 [==============================] - 0s 497us/step - loss: 57.8142 - predict_loss: 0.0000e+00 - loss_loss: 57.8142 - val_loss: 9.9285 - val_predict_loss: 0.0000e+00 - val_loss_loss: 9.9285\n",
      "Epoch 49/1500\n",
      "204/204 [==============================] - 0s 439us/step - loss: 70.8589 - predict_loss: 0.0000e+00 - loss_loss: 70.8589 - val_loss: 29.6542 - val_predict_loss: 0.0000e+00 - val_loss_loss: 29.6542\n",
      "Epoch 50/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 75.7117 - predict_loss: 0.0000e+00 - loss_loss: 75.7117 - val_loss: 13.2880 - val_predict_loss: 0.0000e+00 - val_loss_loss: 13.2880\n",
      "Epoch 51/1500\n",
      "204/204 [==============================] - 0s 506us/step - loss: 54.0608 - predict_loss: 0.0000e+00 - loss_loss: 54.0608 - val_loss: 20.9597 - val_predict_loss: 0.0000e+00 - val_loss_loss: 20.9597\n",
      "Epoch 52/1500\n",
      "204/204 [==============================] - 0s 525us/step - loss: 55.4667 - predict_loss: 0.0000e+00 - loss_loss: 55.4667 - val_loss: 18.4523 - val_predict_loss: 0.0000e+00 - val_loss_loss: 18.4523\n",
      "Epoch 53/1500\n",
      "204/204 [==============================] - 0s 518us/step - loss: 60.6814 - predict_loss: 0.0000e+00 - loss_loss: 60.6814 - val_loss: 20.2629 - val_predict_loss: 0.0000e+00 - val_loss_loss: 20.2629\n",
      "Epoch 54/1500\n",
      "204/204 [==============================] - 0s 504us/step - loss: 52.3267 - predict_loss: 0.0000e+00 - loss_loss: 52.3267 - val_loss: 12.4038 - val_predict_loss: 0.0000e+00 - val_loss_loss: 12.4038\n",
      "Epoch 55/1500\n",
      "204/204 [==============================] - 0s 488us/step - loss: 48.5638 - predict_loss: 0.0000e+00 - loss_loss: 48.5638 - val_loss: 9.5918 - val_predict_loss: 0.0000e+00 - val_loss_loss: 9.5918\n",
      "Epoch 56/1500\n",
      "204/204 [==============================] - 0s 405us/step - loss: 51.4499 - predict_loss: 0.0000e+00 - loss_loss: 51.4499 - val_loss: 18.2711 - val_predict_loss: 0.0000e+00 - val_loss_loss: 18.2711\n",
      "Epoch 57/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 54.3555 - predict_loss: 0.0000e+00 - loss_loss: 54.3555 - val_loss: 6.6127 - val_predict_loss: 0.0000e+00 - val_loss_loss: 6.6127\n",
      "Epoch 58/1500\n",
      "204/204 [==============================] - 0s 525us/step - loss: 42.1871 - predict_loss: 0.0000e+00 - loss_loss: 42.1871 - val_loss: 9.4932 - val_predict_loss: 0.0000e+00 - val_loss_loss: 9.4932\n",
      "Epoch 59/1500\n",
      "204/204 [==============================] - 0s 516us/step - loss: 48.8984 - predict_loss: 0.0000e+00 - loss_loss: 48.8984 - val_loss: 7.5109 - val_predict_loss: 0.0000e+00 - val_loss_loss: 7.5109\n",
      "Epoch 60/1500\n",
      "204/204 [==============================] - 0s 471us/step - loss: 47.0615 - predict_loss: 0.0000e+00 - loss_loss: 47.0615 - val_loss: 5.6259 - val_predict_loss: 0.0000e+00 - val_loss_loss: 5.6259\n",
      "Epoch 61/1500\n",
      "204/204 [==============================] - 0s 514us/step - loss: 44.3025 - predict_loss: 0.0000e+00 - loss_loss: 44.3025 - val_loss: 12.2924 - val_predict_loss: 0.0000e+00 - val_loss_loss: 12.2924\n",
      "Epoch 62/1500\n",
      "204/204 [==============================] - 0s 454us/step - loss: 39.2069 - predict_loss: 0.0000e+00 - loss_loss: 39.2069 - val_loss: 8.8758 - val_predict_loss: 0.0000e+00 - val_loss_loss: 8.8758\n",
      "Epoch 63/1500\n",
      "204/204 [==============================] - 0s 569us/step - loss: 41.4024 - predict_loss: 0.0000e+00 - loss_loss: 41.4024 - val_loss: 3.7802 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.7802\n",
      "Epoch 64/1500\n",
      "204/204 [==============================] - 0s 478us/step - loss: 41.9409 - predict_loss: 0.0000e+00 - loss_loss: 41.9409 - val_loss: 5.2451 - val_predict_loss: 0.0000e+00 - val_loss_loss: 5.2451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1500\n",
      "204/204 [==============================] - 0s 464us/step - loss: 33.3623 - predict_loss: 0.0000e+00 - loss_loss: 33.3623 - val_loss: 5.3945 - val_predict_loss: 0.0000e+00 - val_loss_loss: 5.3945\n",
      "Epoch 66/1500\n",
      "204/204 [==============================] - 0s 416us/step - loss: 41.5813 - predict_loss: 0.0000e+00 - loss_loss: 41.5813 - val_loss: 4.8726 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.8726\n",
      "Epoch 67/1500\n",
      "204/204 [==============================] - 0s 428us/step - loss: 38.0115 - predict_loss: 0.0000e+00 - loss_loss: 38.0115 - val_loss: 11.6048 - val_predict_loss: 0.0000e+00 - val_loss_loss: 11.6048\n",
      "Epoch 68/1500\n",
      "204/204 [==============================] - 0s 456us/step - loss: 35.2191 - predict_loss: 0.0000e+00 - loss_loss: 35.2191 - val_loss: 10.6899 - val_predict_loss: 0.0000e+00 - val_loss_loss: 10.6899\n",
      "Epoch 69/1500\n",
      "204/204 [==============================] - 0s 358us/step - loss: 40.0179 - predict_loss: 0.0000e+00 - loss_loss: 40.0179 - val_loss: 2.4745 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.4745\n",
      "Epoch 70/1500\n",
      "204/204 [==============================] - 0s 454us/step - loss: 33.4727 - predict_loss: 0.0000e+00 - loss_loss: 33.4727 - val_loss: 4.7802 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.7802\n",
      "Epoch 71/1500\n",
      "204/204 [==============================] - 0s 457us/step - loss: 30.6916 - predict_loss: 0.0000e+00 - loss_loss: 30.6916 - val_loss: 7.0359 - val_predict_loss: 0.0000e+00 - val_loss_loss: 7.0359\n",
      "Epoch 72/1500\n",
      "204/204 [==============================] - 0s 463us/step - loss: 31.3063 - predict_loss: 0.0000e+00 - loss_loss: 31.3063 - val_loss: 4.5540 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.5540\n",
      "Epoch 73/1500\n",
      "204/204 [==============================] - 0s 450us/step - loss: 29.7308 - predict_loss: 0.0000e+00 - loss_loss: 29.7308 - val_loss: 8.0113 - val_predict_loss: 0.0000e+00 - val_loss_loss: 8.0113\n",
      "Epoch 74/1500\n",
      "204/204 [==============================] - 0s 407us/step - loss: 31.8049 - predict_loss: 0.0000e+00 - loss_loss: 31.8049 - val_loss: 4.2162 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.2162\n",
      "Epoch 75/1500\n",
      "204/204 [==============================] - 0s 542us/step - loss: 33.7753 - predict_loss: 0.0000e+00 - loss_loss: 33.7753 - val_loss: 2.9713 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9713\n",
      "Epoch 76/1500\n",
      "204/204 [==============================] - 0s 473us/step - loss: 26.2598 - predict_loss: 0.0000e+00 - loss_loss: 26.2598 - val_loss: 4.2878 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.2878\n",
      "Epoch 77/1500\n",
      "204/204 [==============================] - 0s 429us/step - loss: 24.9576 - predict_loss: 0.0000e+00 - loss_loss: 24.9576 - val_loss: 3.3846 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.3846\n",
      "Epoch 78/1500\n",
      "204/204 [==============================] - 0s 490us/step - loss: 33.8525 - predict_loss: 0.0000e+00 - loss_loss: 33.8525 - val_loss: 4.0016 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.0016\n",
      "Epoch 79/1500\n",
      "204/204 [==============================] - 0s 526us/step - loss: 26.0722 - predict_loss: 0.0000e+00 - loss_loss: 26.0722 - val_loss: 3.9621 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.9621\n",
      "Epoch 80/1500\n",
      "204/204 [==============================] - 0s 482us/step - loss: 27.0824 - predict_loss: 0.0000e+00 - loss_loss: 27.0824 - val_loss: 3.8898 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.8898\n",
      "Epoch 81/1500\n",
      "204/204 [==============================] - 0s 490us/step - loss: 23.9090 - predict_loss: 0.0000e+00 - loss_loss: 23.9090 - val_loss: 4.2751 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.2751\n",
      "Epoch 82/1500\n",
      "204/204 [==============================] - 0s 432us/step - loss: 31.2897 - predict_loss: 0.0000e+00 - loss_loss: 31.2897 - val_loss: 4.6686 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.6686\n",
      "Epoch 83/1500\n",
      "204/204 [==============================] - 0s 413us/step - loss: 24.8181 - predict_loss: 0.0000e+00 - loss_loss: 24.8181 - val_loss: 5.9711 - val_predict_loss: 0.0000e+00 - val_loss_loss: 5.9711\n",
      "Epoch 84/1500\n",
      "204/204 [==============================] - 0s 491us/step - loss: 25.0475 - predict_loss: 0.0000e+00 - loss_loss: 25.0475 - val_loss: 3.5853 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.5853\n",
      "Epoch 85/1500\n",
      "204/204 [==============================] - 0s 509us/step - loss: 27.0967 - predict_loss: 0.0000e+00 - loss_loss: 27.0967 - val_loss: 2.9259 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9259\n",
      "Epoch 86/1500\n",
      "204/204 [==============================] - 0s 479us/step - loss: 21.2515 - predict_loss: 0.0000e+00 - loss_loss: 21.2515 - val_loss: 3.3541 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.3541\n",
      "Epoch 87/1500\n",
      "204/204 [==============================] - 0s 507us/step - loss: 23.3381 - predict_loss: 0.0000e+00 - loss_loss: 23.3381 - val_loss: 8.5534 - val_predict_loss: 0.0000e+00 - val_loss_loss: 8.5534\n",
      "Epoch 88/1500\n",
      "204/204 [==============================] - 0s 486us/step - loss: 21.8680 - predict_loss: 0.0000e+00 - loss_loss: 21.8680 - val_loss: 7.3616 - val_predict_loss: 0.0000e+00 - val_loss_loss: 7.3616\n",
      "Epoch 89/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 24.6650 - predict_loss: 0.0000e+00 - loss_loss: 24.6650 - val_loss: 8.7528 - val_predict_loss: 0.0000e+00 - val_loss_loss: 8.7528\n",
      "Epoch 90/1500\n",
      "204/204 [==============================] - 0s 515us/step - loss: 21.7250 - predict_loss: 0.0000e+00 - loss_loss: 21.7250 - val_loss: 2.3354 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3354\n",
      "Epoch 91/1500\n",
      "204/204 [==============================] - 0s 437us/step - loss: 21.5724 - predict_loss: 0.0000e+00 - loss_loss: 21.5724 - val_loss: 3.0284 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.0284\n",
      "Epoch 92/1500\n",
      "204/204 [==============================] - 0s 442us/step - loss: 18.1209 - predict_loss: 0.0000e+00 - loss_loss: 18.1209 - val_loss: 5.2788 - val_predict_loss: 0.0000e+00 - val_loss_loss: 5.2788\n",
      "Epoch 93/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 25.8042 - predict_loss: 0.0000e+00 - loss_loss: 25.8042 - val_loss: 4.6131 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.6131\n",
      "Epoch 94/1500\n",
      "204/204 [==============================] - 0s 515us/step - loss: 23.5498 - predict_loss: 0.0000e+00 - loss_loss: 23.5498 - val_loss: 3.4170 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.4170\n",
      "Epoch 95/1500\n",
      "204/204 [==============================] - 0s 496us/step - loss: 19.3503 - predict_loss: 0.0000e+00 - loss_loss: 19.3503 - val_loss: 2.9567 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9567\n",
      "Epoch 96/1500\n",
      "204/204 [==============================] - 0s 428us/step - loss: 19.5126 - predict_loss: 0.0000e+00 - loss_loss: 19.5126 - val_loss: 2.8129 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.8129\n",
      "Epoch 97/1500\n",
      "204/204 [==============================] - 0s 435us/step - loss: 22.7543 - predict_loss: 0.0000e+00 - loss_loss: 22.7543 - val_loss: 2.6915 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6915\n",
      "Epoch 98/1500\n",
      "204/204 [==============================] - 0s 508us/step - loss: 20.9224 - predict_loss: 0.0000e+00 - loss_loss: 20.9224 - val_loss: 2.6685 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6685\n",
      "Epoch 99/1500\n",
      "204/204 [==============================] - 0s 503us/step - loss: 23.9314 - predict_loss: 0.0000e+00 - loss_loss: 23.9314 - val_loss: 3.9585 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.9585\n",
      "Epoch 100/1500\n",
      "204/204 [==============================] - 0s 481us/step - loss: 20.0193 - predict_loss: 0.0000e+00 - loss_loss: 20.0193 - val_loss: 2.9552 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9552\n",
      "Epoch 101/1500\n",
      "204/204 [==============================] - 0s 442us/step - loss: 21.2080 - predict_loss: 0.0000e+00 - loss_loss: 21.2080 - val_loss: 3.2172 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.2172\n",
      "Epoch 102/1500\n",
      "204/204 [==============================] - 0s 478us/step - loss: 17.5308 - predict_loss: 0.0000e+00 - loss_loss: 17.5308 - val_loss: 4.0847 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.0847\n",
      "Epoch 103/1500\n",
      "204/204 [==============================] - 0s 496us/step - loss: 20.6202 - predict_loss: 0.0000e+00 - loss_loss: 20.6202 - val_loss: 2.7083 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.7083\n",
      "Epoch 104/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 505us/step - loss: 19.7546 - predict_loss: 0.0000e+00 - loss_loss: 19.7546 - val_loss: 2.1223 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.1223\n",
      "Epoch 105/1500\n",
      "204/204 [==============================] - 0s 489us/step - loss: 17.8111 - predict_loss: 0.0000e+00 - loss_loss: 17.8111 - val_loss: 2.6331 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6331\n",
      "Epoch 106/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 19.4926 - predict_loss: 0.0000e+00 - loss_loss: 19.4926 - val_loss: 3.1627 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.1627\n",
      "Epoch 107/1500\n",
      "204/204 [==============================] - 0s 482us/step - loss: 20.0808 - predict_loss: 0.0000e+00 - loss_loss: 20.0808 - val_loss: 4.1975 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.1975\n",
      "Epoch 108/1500\n",
      "204/204 [==============================] - 0s 506us/step - loss: 16.3925 - predict_loss: 0.0000e+00 - loss_loss: 16.3925 - val_loss: 2.1063 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.1063\n",
      "Epoch 109/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 18.2372 - predict_loss: 0.0000e+00 - loss_loss: 18.2372 - val_loss: 2.2739 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2739\n",
      "Epoch 110/1500\n",
      "204/204 [==============================] - 0s 509us/step - loss: 16.4972 - predict_loss: 0.0000e+00 - loss_loss: 16.4972 - val_loss: 2.3868 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3868\n",
      "Epoch 111/1500\n",
      "204/204 [==============================] - 0s 517us/step - loss: 17.4545 - predict_loss: 0.0000e+00 - loss_loss: 17.4545 - val_loss: 4.1100 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.1100\n",
      "Epoch 112/1500\n",
      "204/204 [==============================] - 0s 499us/step - loss: 17.2084 - predict_loss: 0.0000e+00 - loss_loss: 17.2084 - val_loss: 4.3058 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.3058\n",
      "Epoch 113/1500\n",
      "204/204 [==============================] - 0s 517us/step - loss: 17.1269 - predict_loss: 0.0000e+00 - loss_loss: 17.1269 - val_loss: 2.2281 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2281\n",
      "Epoch 114/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 17.8154 - predict_loss: 0.0000e+00 - loss_loss: 17.8154 - val_loss: 7.5526 - val_predict_loss: 0.0000e+00 - val_loss_loss: 7.5526\n",
      "Epoch 115/1500\n",
      "204/204 [==============================] - 0s 420us/step - loss: 16.2390 - predict_loss: 0.0000e+00 - loss_loss: 16.2390 - val_loss: 3.3643 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.3643\n",
      "Epoch 116/1500\n",
      "204/204 [==============================] - 0s 505us/step - loss: 17.7213 - predict_loss: 0.0000e+00 - loss_loss: 17.7213 - val_loss: 2.5241 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.5241\n",
      "Epoch 117/1500\n",
      "204/204 [==============================] - 0s 471us/step - loss: 17.7133 - predict_loss: 0.0000e+00 - loss_loss: 17.7133 - val_loss: 4.1037 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.1037\n",
      "Epoch 118/1500\n",
      "204/204 [==============================] - 0s 461us/step - loss: 16.6034 - predict_loss: 0.0000e+00 - loss_loss: 16.6034 - val_loss: 3.2600 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.2600\n",
      "Epoch 119/1500\n",
      "204/204 [==============================] - 0s 521us/step - loss: 13.1306 - predict_loss: 0.0000e+00 - loss_loss: 13.1306 - val_loss: 3.0826 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.0826\n",
      "Epoch 120/1500\n",
      "204/204 [==============================] - 0s 560us/step - loss: 18.1185 - predict_loss: 0.0000e+00 - loss_loss: 18.1185 - val_loss: 3.8205 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.8205\n",
      "Epoch 121/1500\n",
      "204/204 [==============================] - 0s 527us/step - loss: 17.4559 - predict_loss: 0.0000e+00 - loss_loss: 17.4559 - val_loss: 2.7328 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.7328\n",
      "Epoch 122/1500\n",
      "204/204 [==============================] - 0s 502us/step - loss: 18.2981 - predict_loss: 0.0000e+00 - loss_loss: 18.2981 - val_loss: 2.6311 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6311\n",
      "Epoch 123/1500\n",
      "204/204 [==============================] - 0s 591us/step - loss: 11.7866 - predict_loss: 0.0000e+00 - loss_loss: 11.7866 - val_loss: 1.9874 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9874\n",
      "Epoch 124/1500\n",
      "204/204 [==============================] - 0s 424us/step - loss: 15.8090 - predict_loss: 0.0000e+00 - loss_loss: 15.8090 - val_loss: 3.6227 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.6227\n",
      "Epoch 125/1500\n",
      "204/204 [==============================] - 0s 479us/step - loss: 18.1604 - predict_loss: 0.0000e+00 - loss_loss: 18.1604 - val_loss: 4.4426 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.4426\n",
      "Epoch 126/1500\n",
      "204/204 [==============================] - 0s 497us/step - loss: 14.1799 - predict_loss: 0.0000e+00 - loss_loss: 14.1799 - val_loss: 2.4321 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.4321\n",
      "Epoch 127/1500\n",
      "204/204 [==============================] - 0s 447us/step - loss: 17.8256 - predict_loss: 0.0000e+00 - loss_loss: 17.8256 - val_loss: 2.6132 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6132\n",
      "Epoch 128/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 13.4154 - predict_loss: 0.0000e+00 - loss_loss: 13.4154 - val_loss: 2.8592 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.8592\n",
      "Epoch 129/1500\n",
      "204/204 [==============================] - 0s 578us/step - loss: 14.1322 - predict_loss: 0.0000e+00 - loss_loss: 14.1322 - val_loss: 2.8643 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.8643\n",
      "Epoch 130/1500\n",
      "204/204 [==============================] - 0s 534us/step - loss: 13.3346 - predict_loss: 0.0000e+00 - loss_loss: 13.3346 - val_loss: 6.3083 - val_predict_loss: 0.0000e+00 - val_loss_loss: 6.3083\n",
      "Epoch 131/1500\n",
      "204/204 [==============================] - 0s 473us/step - loss: 15.6189 - predict_loss: 0.0000e+00 - loss_loss: 15.6189 - val_loss: 3.3018 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.3018\n",
      "Epoch 132/1500\n",
      "204/204 [==============================] - 0s 472us/step - loss: 13.0870 - predict_loss: 0.0000e+00 - loss_loss: 13.0870 - val_loss: 1.8194 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8194\n",
      "Epoch 133/1500\n",
      "204/204 [==============================] - 0s 474us/step - loss: 17.9385 - predict_loss: 0.0000e+00 - loss_loss: 17.9385 - val_loss: 4.7056 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.7056\n",
      "Epoch 134/1500\n",
      "204/204 [==============================] - 0s 494us/step - loss: 13.5229 - predict_loss: 0.0000e+00 - loss_loss: 13.5229 - val_loss: 4.4007 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.4007\n",
      "Epoch 135/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 15.3643 - predict_loss: 0.0000e+00 - loss_loss: 15.3643 - val_loss: 4.9424 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.9424\n",
      "Epoch 136/1500\n",
      "204/204 [==============================] - 0s 542us/step - loss: 19.1361 - predict_loss: 0.0000e+00 - loss_loss: 19.1361 - val_loss: 1.8173 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8173\n",
      "Epoch 137/1500\n",
      "204/204 [==============================] - 0s 513us/step - loss: 12.1549 - predict_loss: 0.0000e+00 - loss_loss: 12.1549 - val_loss: 4.0316 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.0316\n",
      "Epoch 138/1500\n",
      "204/204 [==============================] - 0s 477us/step - loss: 15.8727 - predict_loss: 0.0000e+00 - loss_loss: 15.8727 - val_loss: 1.8520 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8520\n",
      "Epoch 139/1500\n",
      "204/204 [==============================] - 0s 499us/step - loss: 14.8050 - predict_loss: 0.0000e+00 - loss_loss: 14.8050 - val_loss: 2.1095 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.1095\n",
      "Epoch 140/1500\n",
      "204/204 [==============================] - 0s 486us/step - loss: 9.9927 - predict_loss: 0.0000e+00 - loss_loss: 9.9927 - val_loss: 5.7198 - val_predict_loss: 0.0000e+00 - val_loss_loss: 5.7198\n",
      "Epoch 141/1500\n",
      "204/204 [==============================] - 0s 518us/step - loss: 15.3087 - predict_loss: 0.0000e+00 - loss_loss: 15.3087 - val_loss: 3.7249 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.7249\n",
      "Epoch 142/1500\n",
      "204/204 [==============================] - 0s 477us/step - loss: 11.4452 - predict_loss: 0.0000e+00 - loss_loss: 11.4452 - val_loss: 2.9298 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9298\n",
      "Epoch 143/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 492us/step - loss: 17.0299 - predict_loss: 0.0000e+00 - loss_loss: 17.0299 - val_loss: 2.3977 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3977\n",
      "Epoch 144/1500\n",
      "204/204 [==============================] - 0s 532us/step - loss: 15.1442 - predict_loss: 0.0000e+00 - loss_loss: 15.1442 - val_loss: 2.9286 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9286\n",
      "Epoch 145/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 10.3825 - predict_loss: 0.0000e+00 - loss_loss: 10.3825 - val_loss: 1.8344 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8344\n",
      "Epoch 146/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 17.1699 - predict_loss: 0.0000e+00 - loss_loss: 17.1699 - val_loss: 1.7480 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7480\n",
      "Epoch 147/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 14.4832 - predict_loss: 0.0000e+00 - loss_loss: 14.4832 - val_loss: 1.9192 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9192\n",
      "Epoch 148/1500\n",
      "204/204 [==============================] - 0s 486us/step - loss: 9.0714 - predict_loss: 0.0000e+00 - loss_loss: 9.0714 - val_loss: 1.9329 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9329\n",
      "Epoch 149/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 14.4478 - predict_loss: 0.0000e+00 - loss_loss: 14.4478 - val_loss: 2.8738 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.8738\n",
      "Epoch 150/1500\n",
      "204/204 [==============================] - 0s 426us/step - loss: 11.5073 - predict_loss: 0.0000e+00 - loss_loss: 11.5073 - val_loss: 2.7354 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.7354\n",
      "Epoch 151/1500\n",
      "204/204 [==============================] - 0s 537us/step - loss: 15.7014 - predict_loss: 0.0000e+00 - loss_loss: 15.7014 - val_loss: 6.1035 - val_predict_loss: 0.0000e+00 - val_loss_loss: 6.1035\n",
      "Epoch 152/1500\n",
      "204/204 [==============================] - 0s 452us/step - loss: 12.6857 - predict_loss: 0.0000e+00 - loss_loss: 12.6857 - val_loss: 1.7692 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7692\n",
      "Epoch 153/1500\n",
      "204/204 [==============================] - 0s 483us/step - loss: 11.7226 - predict_loss: 0.0000e+00 - loss_loss: 11.7226 - val_loss: 2.6375 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6375\n",
      "Epoch 154/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 13.2154 - predict_loss: 0.0000e+00 - loss_loss: 13.2154 - val_loss: 2.3921 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3921\n",
      "Epoch 155/1500\n",
      "204/204 [==============================] - 0s 450us/step - loss: 11.4486 - predict_loss: 0.0000e+00 - loss_loss: 11.4486 - val_loss: 3.0782 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.0782\n",
      "Epoch 156/1500\n",
      "204/204 [==============================] - 0s 437us/step - loss: 9.2852 - predict_loss: 0.0000e+00 - loss_loss: 9.2852 - val_loss: 3.4462 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.4462\n",
      "Epoch 157/1500\n",
      "204/204 [==============================] - 0s 409us/step - loss: 13.1002 - predict_loss: 0.0000e+00 - loss_loss: 13.1002 - val_loss: 2.6795 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6795\n",
      "Epoch 158/1500\n",
      "204/204 [==============================] - 0s 493us/step - loss: 15.3149 - predict_loss: 0.0000e+00 - loss_loss: 15.3149 - val_loss: 2.0414 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0414\n",
      "Epoch 159/1500\n",
      "204/204 [==============================] - 0s 517us/step - loss: 12.9510 - predict_loss: 0.0000e+00 - loss_loss: 12.9510 - val_loss: 2.0845 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0845\n",
      "Epoch 160/1500\n",
      "204/204 [==============================] - 0s 469us/step - loss: 9.7142 - predict_loss: 0.0000e+00 - loss_loss: 9.7142 - val_loss: 2.3689 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3689\n",
      "Epoch 161/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 11.8423 - predict_loss: 0.0000e+00 - loss_loss: 11.8423 - val_loss: 1.7726 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7726\n",
      "Epoch 162/1500\n",
      "204/204 [==============================] - 0s 456us/step - loss: 11.8314 - predict_loss: 0.0000e+00 - loss_loss: 11.8314 - val_loss: 1.9562 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9562\n",
      "Epoch 163/1500\n",
      "204/204 [==============================] - 0s 515us/step - loss: 13.1668 - predict_loss: 0.0000e+00 - loss_loss: 13.1668 - val_loss: 1.8115 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8115\n",
      "Epoch 164/1500\n",
      "204/204 [==============================] - 0s 502us/step - loss: 9.3874 - predict_loss: 0.0000e+00 - loss_loss: 9.3874 - val_loss: 2.8779 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.8779\n",
      "Epoch 165/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 9.6802 - predict_loss: 0.0000e+00 - loss_loss: 9.6802 - val_loss: 3.1286 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.1286\n",
      "Epoch 166/1500\n",
      "204/204 [==============================] - 0s 477us/step - loss: 12.4122 - predict_loss: 0.0000e+00 - loss_loss: 12.4122 - val_loss: 1.6145 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6145\n",
      "Epoch 167/1500\n",
      "204/204 [==============================] - 0s 495us/step - loss: 13.3195 - predict_loss: 0.0000e+00 - loss_loss: 13.3195 - val_loss: 1.4855 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4855\n",
      "Epoch 168/1500\n",
      "204/204 [==============================] - 0s 538us/step - loss: 12.1765 - predict_loss: 0.0000e+00 - loss_loss: 12.1765 - val_loss: 1.7808 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7808\n",
      "Epoch 169/1500\n",
      "204/204 [==============================] - 0s 517us/step - loss: 11.7049 - predict_loss: 0.0000e+00 - loss_loss: 11.7049 - val_loss: 3.0160 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.0160\n",
      "Epoch 170/1500\n",
      "204/204 [==============================] - 0s 478us/step - loss: 11.1721 - predict_loss: 0.0000e+00 - loss_loss: 11.1721 - val_loss: 4.7485 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.7485\n",
      "Epoch 171/1500\n",
      "204/204 [==============================] - 0s 505us/step - loss: 8.6989 - predict_loss: 0.0000e+00 - loss_loss: 8.6989 - val_loss: 2.5830 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.5830\n",
      "Epoch 172/1500\n",
      "204/204 [==============================] - 0s 493us/step - loss: 10.1221 - predict_loss: 0.0000e+00 - loss_loss: 10.1221 - val_loss: 1.8958 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8958\n",
      "Epoch 173/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 15.8488 - predict_loss: 0.0000e+00 - loss_loss: 15.8488 - val_loss: 1.8230 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8230\n",
      "Epoch 174/1500\n",
      "204/204 [==============================] - 0s 543us/step - loss: 9.5949 - predict_loss: 0.0000e+00 - loss_loss: 9.5949 - val_loss: 3.1924 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.1924\n",
      "Epoch 175/1500\n",
      "204/204 [==============================] - 0s 478us/step - loss: 13.3741 - predict_loss: 0.0000e+00 - loss_loss: 13.3741 - val_loss: 3.6185 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.6185\n",
      "Epoch 176/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 10.0925 - predict_loss: 0.0000e+00 - loss_loss: 10.0925 - val_loss: 2.0764 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0764\n",
      "Epoch 177/1500\n",
      "204/204 [==============================] - 0s 551us/step - loss: 13.1566 - predict_loss: 0.0000e+00 - loss_loss: 13.1566 - val_loss: 2.6206 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6206\n",
      "Epoch 178/1500\n",
      "204/204 [==============================] - 0s 525us/step - loss: 12.1214 - predict_loss: 0.0000e+00 - loss_loss: 12.1214 - val_loss: 2.2630 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2630\n",
      "Epoch 179/1500\n",
      "204/204 [==============================] - 0s 510us/step - loss: 8.4764 - predict_loss: 0.0000e+00 - loss_loss: 8.4764 - val_loss: 2.0449 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0449\n",
      "Epoch 180/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 15.3000 - predict_loss: 0.0000e+00 - loss_loss: 15.3000 - val_loss: 1.3211 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3211\n",
      "Epoch 181/1500\n",
      "204/204 [==============================] - 0s 490us/step - loss: 11.4672 - predict_loss: 0.0000e+00 - loss_loss: 11.4672 - val_loss: 1.2362 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2362\n",
      "Epoch 182/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 484us/step - loss: 8.0382 - predict_loss: 0.0000e+00 - loss_loss: 8.0382 - val_loss: 3.7790 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.7790\n",
      "Epoch 183/1500\n",
      "204/204 [==============================] - 0s 438us/step - loss: 8.9320 - predict_loss: 0.0000e+00 - loss_loss: 8.9320 - val_loss: 1.9538 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9538\n",
      "Epoch 184/1500\n",
      "204/204 [==============================] - 0s 462us/step - loss: 14.3683 - predict_loss: 0.0000e+00 - loss_loss: 14.3683 - val_loss: 1.8224 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8224\n",
      "Epoch 185/1500\n",
      "204/204 [==============================] - 0s 467us/step - loss: 7.0325 - predict_loss: 0.0000e+00 - loss_loss: 7.0325 - val_loss: 5.4312 - val_predict_loss: 0.0000e+00 - val_loss_loss: 5.4312\n",
      "Epoch 186/1500\n",
      "204/204 [==============================] - 0s 454us/step - loss: 11.5956 - predict_loss: 0.0000e+00 - loss_loss: 11.5956 - val_loss: 2.4613 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.4613\n",
      "Epoch 187/1500\n",
      "204/204 [==============================] - 0s 506us/step - loss: 9.9035 - predict_loss: 0.0000e+00 - loss_loss: 9.9035 - val_loss: 1.2481 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2481\n",
      "Epoch 188/1500\n",
      "204/204 [==============================] - 0s 537us/step - loss: 8.4686 - predict_loss: 0.0000e+00 - loss_loss: 8.4686 - val_loss: 2.6471 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6471\n",
      "Epoch 189/1500\n",
      "204/204 [==============================] - 0s 537us/step - loss: 12.5606 - predict_loss: 0.0000e+00 - loss_loss: 12.5606 - val_loss: 1.8372 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8372\n",
      "Epoch 190/1500\n",
      "204/204 [==============================] - 0s 509us/step - loss: 8.5601 - predict_loss: 0.0000e+00 - loss_loss: 8.5601 - val_loss: 1.2288 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2288\n",
      "Epoch 191/1500\n",
      "204/204 [==============================] - 0s 480us/step - loss: 12.7277 - predict_loss: 0.0000e+00 - loss_loss: 12.7277 - val_loss: 1.6135 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6135\n",
      "Epoch 192/1500\n",
      "204/204 [==============================] - 0s 443us/step - loss: 8.9772 - predict_loss: 0.0000e+00 - loss_loss: 8.9772 - val_loss: 2.2130 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2130\n",
      "Epoch 193/1500\n",
      "204/204 [==============================] - 0s 481us/step - loss: 8.8263 - predict_loss: 0.0000e+00 - loss_loss: 8.8263 - val_loss: 1.4147 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4147\n",
      "Epoch 194/1500\n",
      "204/204 [==============================] - 0s 452us/step - loss: 9.1840 - predict_loss: 0.0000e+00 - loss_loss: 9.1840 - val_loss: 1.8152 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8152\n",
      "Epoch 195/1500\n",
      "204/204 [==============================] - 0s 410us/step - loss: 10.8264 - predict_loss: 0.0000e+00 - loss_loss: 10.8264 - val_loss: 1.8610 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8610\n",
      "Epoch 196/1500\n",
      "204/204 [==============================] - 0s 405us/step - loss: 13.3232 - predict_loss: 0.0000e+00 - loss_loss: 13.3232 - val_loss: 2.3303 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3303\n",
      "Epoch 197/1500\n",
      "204/204 [==============================] - 0s 478us/step - loss: 7.9158 - predict_loss: 0.0000e+00 - loss_loss: 7.9158 - val_loss: 1.7299 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7299\n",
      "Epoch 198/1500\n",
      "204/204 [==============================] - 0s 502us/step - loss: 10.9444 - predict_loss: 0.0000e+00 - loss_loss: 10.9444 - val_loss: 1.6318 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6318\n",
      "Epoch 199/1500\n",
      "204/204 [==============================] - 0s 442us/step - loss: 9.4416 - predict_loss: 0.0000e+00 - loss_loss: 9.4416 - val_loss: 1.8343 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8343\n",
      "Epoch 200/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 8.1717 - predict_loss: 0.0000e+00 - loss_loss: 8.1717 - val_loss: 1.8380 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8380\n",
      "Epoch 201/1500\n",
      "204/204 [==============================] - 0s 471us/step - loss: 10.1278 - predict_loss: 0.0000e+00 - loss_loss: 10.1278 - val_loss: 1.8707 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8707\n",
      "Epoch 202/1500\n",
      "204/204 [==============================] - 0s 504us/step - loss: 9.5959 - predict_loss: 0.0000e+00 - loss_loss: 9.5959 - val_loss: 1.2997 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2997\n",
      "Epoch 203/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 7.3607 - predict_loss: 0.0000e+00 - loss_loss: 7.3607 - val_loss: 1.5230 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5230\n",
      "Epoch 204/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 11.3334 - predict_loss: 0.0000e+00 - loss_loss: 11.3334 - val_loss: 1.9835 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9835\n",
      "Epoch 205/1500\n",
      "204/204 [==============================] - 0s 514us/step - loss: 7.2822 - predict_loss: 0.0000e+00 - loss_loss: 7.2822 - val_loss: 2.4530 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.4530\n",
      "Epoch 206/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 8.8847 - predict_loss: 0.0000e+00 - loss_loss: 8.8847 - val_loss: 1.7295 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7295\n",
      "Epoch 207/1500\n",
      "204/204 [==============================] - 0s 469us/step - loss: 10.5373 - predict_loss: 0.0000e+00 - loss_loss: 10.5373 - val_loss: 1.7507 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7507\n",
      "Epoch 208/1500\n",
      "204/204 [==============================] - 0s 467us/step - loss: 8.5425 - predict_loss: 0.0000e+00 - loss_loss: 8.5425 - val_loss: 1.7444 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7444\n",
      "Epoch 209/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 10.3470 - predict_loss: 0.0000e+00 - loss_loss: 10.3470 - val_loss: 1.3752 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3752\n",
      "Epoch 210/1500\n",
      "204/204 [==============================] - 0s 523us/step - loss: 8.4340 - predict_loss: 0.0000e+00 - loss_loss: 8.4340 - val_loss: 1.6891 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6891\n",
      "Epoch 211/1500\n",
      "204/204 [==============================] - 0s 498us/step - loss: 10.0613 - predict_loss: 0.0000e+00 - loss_loss: 10.0613 - val_loss: 1.7199 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7199\n",
      "Epoch 212/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 7.0736 - predict_loss: 0.0000e+00 - loss_loss: 7.0736 - val_loss: 3.0335 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.0335\n",
      "Epoch 213/1500\n",
      "204/204 [==============================] - 0s 504us/step - loss: 10.8154 - predict_loss: 0.0000e+00 - loss_loss: 10.8154 - val_loss: 2.7444 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.7444\n",
      "Epoch 214/1500\n",
      "204/204 [==============================] - 0s 495us/step - loss: 8.8835 - predict_loss: 0.0000e+00 - loss_loss: 8.8835 - val_loss: 3.5454 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.5454\n",
      "Epoch 215/1500\n",
      "204/204 [==============================] - 0s 468us/step - loss: 5.7506 - predict_loss: 0.0000e+00 - loss_loss: 5.7506 - val_loss: 1.6289 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6289\n",
      "Epoch 216/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 12.2305 - predict_loss: 0.0000e+00 - loss_loss: 12.2305 - val_loss: 2.0457 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0457\n",
      "Epoch 217/1500\n",
      "204/204 [==============================] - 0s 470us/step - loss: 8.4316 - predict_loss: 0.0000e+00 - loss_loss: 8.4316 - val_loss: 1.5345 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5345\n",
      "Epoch 218/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 9.2354 - predict_loss: 0.0000e+00 - loss_loss: 9.2354 - val_loss: 2.2475 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2475\n",
      "Epoch 219/1500\n",
      "204/204 [==============================] - 0s 548us/step - loss: 8.1998 - predict_loss: 0.0000e+00 - loss_loss: 8.1998 - val_loss: 1.0604 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0604\n",
      "Epoch 220/1500\n",
      "204/204 [==============================] - 0s 538us/step - loss: 10.8668 - predict_loss: 0.0000e+00 - loss_loss: 10.8668 - val_loss: 1.4886 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4886\n",
      "Epoch 221/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 501us/step - loss: 9.7561 - predict_loss: 0.0000e+00 - loss_loss: 9.7561 - val_loss: 2.1299 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.1299\n",
      "Epoch 222/1500\n",
      "204/204 [==============================] - 0s 462us/step - loss: 7.8118 - predict_loss: 0.0000e+00 - loss_loss: 7.8118 - val_loss: 1.3013 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3013\n",
      "Epoch 223/1500\n",
      "204/204 [==============================] - 0s 489us/step - loss: 9.6890 - predict_loss: 0.0000e+00 - loss_loss: 9.6890 - val_loss: 1.2772 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2772\n",
      "Epoch 224/1500\n",
      "204/204 [==============================] - 0s 499us/step - loss: 6.8595 - predict_loss: 0.0000e+00 - loss_loss: 6.8595 - val_loss: 1.5198 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5198\n",
      "Epoch 225/1500\n",
      "204/204 [==============================] - 0s 496us/step - loss: 9.7780 - predict_loss: 0.0000e+00 - loss_loss: 9.7780 - val_loss: 1.6085 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6085\n",
      "Epoch 226/1500\n",
      "204/204 [==============================] - 0s 430us/step - loss: 8.9988 - predict_loss: 0.0000e+00 - loss_loss: 8.9988 - val_loss: 1.9538 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9538\n",
      "Epoch 227/1500\n",
      "204/204 [==============================] - 0s 495us/step - loss: 8.6314 - predict_loss: 0.0000e+00 - loss_loss: 8.6314 - val_loss: 1.3867 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3867\n",
      "Epoch 228/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 9.3518 - predict_loss: 0.0000e+00 - loss_loss: 9.3518 - val_loss: 2.0726 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0726\n",
      "Epoch 229/1500\n",
      "204/204 [==============================] - 0s 525us/step - loss: 7.4467 - predict_loss: 0.0000e+00 - loss_loss: 7.4467 - val_loss: 3.8153 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.8153\n",
      "Epoch 230/1500\n",
      "204/204 [==============================] - 0s 495us/step - loss: 9.8694 - predict_loss: 0.0000e+00 - loss_loss: 9.8694 - val_loss: 1.4429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4429\n",
      "Epoch 231/1500\n",
      "204/204 [==============================] - 0s 521us/step - loss: 6.4345 - predict_loss: 0.0000e+00 - loss_loss: 6.4345 - val_loss: 2.9948 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9948\n",
      "Epoch 232/1500\n",
      "204/204 [==============================] - 0s 489us/step - loss: 11.2887 - predict_loss: 0.0000e+00 - loss_loss: 11.2887 - val_loss: 1.5992 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5992\n",
      "Epoch 233/1500\n",
      "204/204 [==============================] - 0s 517us/step - loss: 7.7746 - predict_loss: 0.0000e+00 - loss_loss: 7.7746 - val_loss: 1.8029 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8029\n",
      "Epoch 234/1500\n",
      "204/204 [==============================] - 0s 481us/step - loss: 8.3220 - predict_loss: 0.0000e+00 - loss_loss: 8.3220 - val_loss: 1.3990 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3990\n",
      "Epoch 235/1500\n",
      "204/204 [==============================] - 0s 359us/step - loss: 8.4818 - predict_loss: 0.0000e+00 - loss_loss: 8.4818 - val_loss: 1.2498 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2498\n",
      "Epoch 236/1500\n",
      "204/204 [==============================] - 0s 425us/step - loss: 8.7205 - predict_loss: 0.0000e+00 - loss_loss: 8.7205 - val_loss: 1.8296 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8296\n",
      "Epoch 237/1500\n",
      "204/204 [==============================] - 0s 452us/step - loss: 7.7406 - predict_loss: 0.0000e+00 - loss_loss: 7.7406 - val_loss: 2.9554 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9554\n",
      "Epoch 238/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 7.2151 - predict_loss: 0.0000e+00 - loss_loss: 7.2151 - val_loss: 2.9428 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.9428\n",
      "Epoch 239/1500\n",
      "204/204 [==============================] - 0s 446us/step - loss: 10.5946 - predict_loss: 0.0000e+00 - loss_loss: 10.5946 - val_loss: 1.4899 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4899\n",
      "Epoch 240/1500\n",
      "204/204 [==============================] - 0s 581us/step - loss: 7.5518 - predict_loss: 0.0000e+00 - loss_loss: 7.5518 - val_loss: 1.1350 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1350\n",
      "Epoch 241/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 10.5013 - predict_loss: 0.0000e+00 - loss_loss: 10.5013 - val_loss: 1.5972 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5972\n",
      "Epoch 242/1500\n",
      "204/204 [==============================] - 0s 502us/step - loss: 5.8238 - predict_loss: 0.0000e+00 - loss_loss: 5.8238 - val_loss: 1.1538 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1538\n",
      "Epoch 243/1500\n",
      "204/204 [==============================] - 0s 488us/step - loss: 8.2275 - predict_loss: 0.0000e+00 - loss_loss: 8.2275 - val_loss: 2.0503 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0503\n",
      "Epoch 244/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 7.8387 - predict_loss: 0.0000e+00 - loss_loss: 7.8387 - val_loss: 1.1717 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1717\n",
      "Epoch 245/1500\n",
      "204/204 [==============================] - 0s 490us/step - loss: 11.0118 - predict_loss: 0.0000e+00 - loss_loss: 11.0118 - val_loss: 1.5347 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5347\n",
      "Epoch 246/1500\n",
      "204/204 [==============================] - 0s 488us/step - loss: 6.8992 - predict_loss: 0.0000e+00 - loss_loss: 6.8992 - val_loss: 1.4431 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4431\n",
      "Epoch 247/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 6.3857 - predict_loss: 0.0000e+00 - loss_loss: 6.3857 - val_loss: 1.3812 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3812\n",
      "Epoch 248/1500\n",
      "204/204 [==============================] - 0s 478us/step - loss: 8.8464 - predict_loss: 0.0000e+00 - loss_loss: 8.8464 - val_loss: 1.6504 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6504\n",
      "Epoch 249/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 7.8551 - predict_loss: 0.0000e+00 - loss_loss: 7.8551 - val_loss: 1.3628 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3628\n",
      "Epoch 250/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 7.6054 - predict_loss: 0.0000e+00 - loss_loss: 7.6054 - val_loss: 1.4129 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4129\n",
      "Epoch 251/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 6.5076 - predict_loss: 0.0000e+00 - loss_loss: 6.5076 - val_loss: 1.9964 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9964\n",
      "Epoch 252/1500\n",
      "204/204 [==============================] - 0s 550us/step - loss: 6.5449 - predict_loss: 0.0000e+00 - loss_loss: 6.5449 - val_loss: 1.5758 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5758\n",
      "Epoch 253/1500\n",
      "204/204 [==============================] - 0s 451us/step - loss: 8.4538 - predict_loss: 0.0000e+00 - loss_loss: 8.4538 - val_loss: 1.2490 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2490\n",
      "Epoch 254/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 7.9369 - predict_loss: 0.0000e+00 - loss_loss: 7.9369 - val_loss: 1.2579 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2579\n",
      "Epoch 255/1500\n",
      "204/204 [==============================] - 0s 456us/step - loss: 7.3669 - predict_loss: 0.0000e+00 - loss_loss: 7.3669 - val_loss: 1.4695 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4695\n",
      "Epoch 256/1500\n",
      "204/204 [==============================] - 0s 453us/step - loss: 9.4822 - predict_loss: 0.0000e+00 - loss_loss: 9.4822 - val_loss: 1.3634 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3634\n",
      "Epoch 257/1500\n",
      "204/204 [==============================] - 0s 516us/step - loss: 7.3080 - predict_loss: 0.0000e+00 - loss_loss: 7.3080 - val_loss: 3.1899 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.1899\n",
      "Epoch 258/1500\n",
      "204/204 [==============================] - 0s 489us/step - loss: 6.7944 - predict_loss: 0.0000e+00 - loss_loss: 6.7944 - val_loss: 1.2038 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2038\n",
      "Epoch 259/1500\n",
      "204/204 [==============================] - 0s 506us/step - loss: 7.7229 - predict_loss: 0.0000e+00 - loss_loss: 7.7229 - val_loss: 1.3250 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3250\n",
      "Epoch 260/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 538us/step - loss: 9.7281 - predict_loss: 0.0000e+00 - loss_loss: 9.7281 - val_loss: 1.5838 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5838\n",
      "Epoch 261/1500\n",
      "204/204 [==============================] - 0s 509us/step - loss: 8.5382 - predict_loss: 0.0000e+00 - loss_loss: 8.5382 - val_loss: 1.0577 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0577\n",
      "Epoch 262/1500\n",
      "204/204 [==============================] - 0s 475us/step - loss: 5.6723 - predict_loss: 0.0000e+00 - loss_loss: 5.6723 - val_loss: 1.6261 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6261\n",
      "Epoch 263/1500\n",
      "204/204 [==============================] - 0s 458us/step - loss: 9.6587 - predict_loss: 0.0000e+00 - loss_loss: 9.6587 - val_loss: 1.2780 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2780\n",
      "Epoch 264/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 5.8359 - predict_loss: 0.0000e+00 - loss_loss: 5.8359 - val_loss: 2.8828 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.8828\n",
      "Epoch 265/1500\n",
      "204/204 [==============================] - 0s 574us/step - loss: 8.4434 - predict_loss: 0.0000e+00 - loss_loss: 8.4434 - val_loss: 2.2631 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2631\n",
      "Epoch 266/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 6.8872 - predict_loss: 0.0000e+00 - loss_loss: 6.8872 - val_loss: 1.0682 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0682\n",
      "Epoch 267/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 6.6085 - predict_loss: 0.0000e+00 - loss_loss: 6.6085 - val_loss: 2.4509 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.4509\n",
      "Epoch 268/1500\n",
      "204/204 [==============================] - 0s 534us/step - loss: 10.3141 - predict_loss: 0.0000e+00 - loss_loss: 10.3141 - val_loss: 1.8984 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8984\n",
      "Epoch 269/1500\n",
      "204/204 [==============================] - 0s 471us/step - loss: 7.1772 - predict_loss: 0.0000e+00 - loss_loss: 7.1772 - val_loss: 1.6967 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6967\n",
      "Epoch 270/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 5.9622 - predict_loss: 0.0000e+00 - loss_loss: 5.9622 - val_loss: 3.4586 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.4586\n",
      "Epoch 271/1500\n",
      "204/204 [==============================] - 0s 465us/step - loss: 9.0048 - predict_loss: 0.0000e+00 - loss_loss: 9.0048 - val_loss: 1.2226 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2226\n",
      "Epoch 272/1500\n",
      "204/204 [==============================] - 0s 464us/step - loss: 7.5219 - predict_loss: 0.0000e+00 - loss_loss: 7.5219 - val_loss: 2.0354 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0354\n",
      "Epoch 273/1500\n",
      "204/204 [==============================] - 0s 425us/step - loss: 7.2314 - predict_loss: 0.0000e+00 - loss_loss: 7.2314 - val_loss: 1.3947 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3947\n",
      "Epoch 274/1500\n",
      "204/204 [==============================] - 0s 504us/step - loss: 5.9929 - predict_loss: 0.0000e+00 - loss_loss: 5.9929 - val_loss: 1.7439 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7439\n",
      "Epoch 275/1500\n",
      "204/204 [==============================] - 0s 431us/step - loss: 8.1863 - predict_loss: 0.0000e+00 - loss_loss: 8.1863 - val_loss: 1.5865 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5865\n",
      "Epoch 276/1500\n",
      "204/204 [==============================] - 0s 459us/step - loss: 4.5762 - predict_loss: 0.0000e+00 - loss_loss: 4.5762 - val_loss: 2.2133 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2133\n",
      "Epoch 277/1500\n",
      "204/204 [==============================] - 0s 470us/step - loss: 10.0567 - predict_loss: 0.0000e+00 - loss_loss: 10.0567 - val_loss: 2.4026 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.4026\n",
      "Epoch 278/1500\n",
      "204/204 [==============================] - 0s 451us/step - loss: 8.3994 - predict_loss: 0.0000e+00 - loss_loss: 8.3994 - val_loss: 1.6972 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6972\n",
      "Epoch 279/1500\n",
      "204/204 [==============================] - 0s 526us/step - loss: 6.4683 - predict_loss: 0.0000e+00 - loss_loss: 6.4683 - val_loss: 1.2049 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2049\n",
      "Epoch 280/1500\n",
      "204/204 [==============================] - 0s 528us/step - loss: 6.4533 - predict_loss: 0.0000e+00 - loss_loss: 6.4533 - val_loss: 1.3569 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3569\n",
      "Epoch 281/1500\n",
      "204/204 [==============================] - 0s 517us/step - loss: 6.5627 - predict_loss: 0.0000e+00 - loss_loss: 6.5627 - val_loss: 1.7891 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7891\n",
      "Epoch 282/1500\n",
      "204/204 [==============================] - 0s 496us/step - loss: 7.5937 - predict_loss: 0.0000e+00 - loss_loss: 7.5937 - val_loss: 1.7248 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7248\n",
      "Epoch 283/1500\n",
      "204/204 [==============================] - 0s 502us/step - loss: 6.6905 - predict_loss: 0.0000e+00 - loss_loss: 6.6905 - val_loss: 1.6489 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6489\n",
      "Epoch 284/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 6.6507 - predict_loss: 0.0000e+00 - loss_loss: 6.6507 - val_loss: 1.9495 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9495\n",
      "Epoch 285/1500\n",
      "204/204 [==============================] - 0s 529us/step - loss: 9.4871 - predict_loss: 0.0000e+00 - loss_loss: 9.4871 - val_loss: 1.3426 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3426\n",
      "Epoch 286/1500\n",
      "204/204 [==============================] - 0s 502us/step - loss: 7.7818 - predict_loss: 0.0000e+00 - loss_loss: 7.7818 - val_loss: 1.6351 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6351\n",
      "Epoch 287/1500\n",
      "204/204 [==============================] - 0s 502us/step - loss: 4.8536 - predict_loss: 0.0000e+00 - loss_loss: 4.8536 - val_loss: 1.1591 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1591\n",
      "Epoch 288/1500\n",
      "204/204 [==============================] - 0s 477us/step - loss: 7.6300 - predict_loss: 0.0000e+00 - loss_loss: 7.6300 - val_loss: 1.2301 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2301\n",
      "Epoch 289/1500\n",
      "204/204 [==============================] - 0s 505us/step - loss: 7.1931 - predict_loss: 0.0000e+00 - loss_loss: 7.1931 - val_loss: 2.4738 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.4738\n",
      "Epoch 290/1500\n",
      "204/204 [==============================] - 0s 514us/step - loss: 5.4191 - predict_loss: 0.0000e+00 - loss_loss: 5.4191 - val_loss: 2.0724 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0724\n",
      "Epoch 291/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 8.1066 - predict_loss: 0.0000e+00 - loss_loss: 8.1066 - val_loss: 1.4195 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4195\n",
      "Epoch 292/1500\n",
      "204/204 [==============================] - 0s 472us/step - loss: 7.4483 - predict_loss: 0.0000e+00 - loss_loss: 7.4483 - val_loss: 1.2405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2405\n",
      "Epoch 293/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 7.4118 - predict_loss: 0.0000e+00 - loss_loss: 7.4118 - val_loss: 2.6691 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6691\n",
      "Epoch 294/1500\n",
      "204/204 [==============================] - 0s 473us/step - loss: 5.7931 - predict_loss: 0.0000e+00 - loss_loss: 5.7931 - val_loss: 1.4589 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4589\n",
      "Epoch 295/1500\n",
      "204/204 [==============================] - 0s 414us/step - loss: 6.1989 - predict_loss: 0.0000e+00 - loss_loss: 6.1989 - val_loss: 2.6766 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6766\n",
      "Epoch 296/1500\n",
      "204/204 [==============================] - 0s 452us/step - loss: 8.4110 - predict_loss: 0.0000e+00 - loss_loss: 8.4110 - val_loss: 1.4345 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4345\n",
      "Epoch 297/1500\n",
      "204/204 [==============================] - 0s 525us/step - loss: 7.0203 - predict_loss: 0.0000e+00 - loss_loss: 7.0203 - val_loss: 1.5772 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5772\n",
      "Epoch 298/1500\n",
      "204/204 [==============================] - 0s 503us/step - loss: 7.2422 - predict_loss: 0.0000e+00 - loss_loss: 7.2422 - val_loss: 1.1081 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1081\n",
      "Epoch 299/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 502us/step - loss: 5.7714 - predict_loss: 0.0000e+00 - loss_loss: 5.7714 - val_loss: 0.7022 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.7022\n",
      "Epoch 300/1500\n",
      "204/204 [==============================] - 0s 472us/step - loss: 9.6308 - predict_loss: 0.0000e+00 - loss_loss: 9.6308 - val_loss: 1.4014 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4014\n",
      "Epoch 301/1500\n",
      "204/204 [==============================] - 0s 430us/step - loss: 4.1852 - predict_loss: 0.0000e+00 - loss_loss: 4.1852 - val_loss: 0.9705 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9705\n",
      "Epoch 302/1500\n",
      "204/204 [==============================] - 0s 466us/step - loss: 7.1185 - predict_loss: 0.0000e+00 - loss_loss: 7.1185 - val_loss: 2.3067 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3067\n",
      "Epoch 303/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 9.3076 - predict_loss: 0.0000e+00 - loss_loss: 9.3076 - val_loss: 2.1862 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.1862\n",
      "Epoch 304/1500\n",
      "204/204 [==============================] - 0s 509us/step - loss: 6.9587 - predict_loss: 0.0000e+00 - loss_loss: 6.9587 - val_loss: 1.0846 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0846\n",
      "Epoch 305/1500\n",
      "204/204 [==============================] - 0s 430us/step - loss: 5.3968 - predict_loss: 0.0000e+00 - loss_loss: 5.3968 - val_loss: 1.1110 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1110\n",
      "Epoch 306/1500\n",
      "204/204 [==============================] - 0s 520us/step - loss: 6.4574 - predict_loss: 0.0000e+00 - loss_loss: 6.4574 - val_loss: 1.1795 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1795\n",
      "Epoch 307/1500\n",
      "204/204 [==============================] - 0s 476us/step - loss: 5.4149 - predict_loss: 0.0000e+00 - loss_loss: 5.4149 - val_loss: 1.7146 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7146\n",
      "Epoch 308/1500\n",
      "204/204 [==============================] - 0s 463us/step - loss: 9.1924 - predict_loss: 0.0000e+00 - loss_loss: 9.1924 - val_loss: 1.3033 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3033\n",
      "Epoch 309/1500\n",
      "204/204 [==============================] - 0s 508us/step - loss: 7.6173 - predict_loss: 0.0000e+00 - loss_loss: 7.6173 - val_loss: 1.1033 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1033\n",
      "Epoch 310/1500\n",
      "204/204 [==============================] - 0s 526us/step - loss: 5.7915 - predict_loss: 0.0000e+00 - loss_loss: 5.7915 - val_loss: 1.5604 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5604\n",
      "Epoch 311/1500\n",
      "204/204 [==============================] - 0s 480us/step - loss: 7.2411 - predict_loss: 0.0000e+00 - loss_loss: 7.2411 - val_loss: 0.9814 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9814\n",
      "Epoch 312/1500\n",
      "204/204 [==============================] - 0s 471us/step - loss: 5.9095 - predict_loss: 0.0000e+00 - loss_loss: 5.9095 - val_loss: 1.4333 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4333\n",
      "Epoch 313/1500\n",
      "204/204 [==============================] - 0s 469us/step - loss: 5.3844 - predict_loss: 0.0000e+00 - loss_loss: 5.3844 - val_loss: 1.1685 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1685\n",
      "Epoch 314/1500\n",
      "204/204 [==============================] - 0s 463us/step - loss: 6.8249 - predict_loss: 0.0000e+00 - loss_loss: 6.8249 - val_loss: 1.0980 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0980\n",
      "Epoch 315/1500\n",
      "204/204 [==============================] - 0s 466us/step - loss: 7.4267 - predict_loss: 0.0000e+00 - loss_loss: 7.4267 - val_loss: 1.2074 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2074\n",
      "Epoch 316/1500\n",
      "204/204 [==============================] - 0s 500us/step - loss: 5.9313 - predict_loss: 0.0000e+00 - loss_loss: 5.9313 - val_loss: 1.5809 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5809\n",
      "Epoch 317/1500\n",
      "204/204 [==============================] - 0s 470us/step - loss: 4.5562 - predict_loss: 0.0000e+00 - loss_loss: 4.5562 - val_loss: 1.8499 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8499\n",
      "Epoch 318/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 9.2392 - predict_loss: 0.0000e+00 - loss_loss: 9.2392 - val_loss: 1.1765 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1765\n",
      "Epoch 319/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 5.2993 - predict_loss: 0.0000e+00 - loss_loss: 5.2993 - val_loss: 1.8225 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8225\n",
      "Epoch 320/1500\n",
      "204/204 [==============================] - 0s 483us/step - loss: 6.4743 - predict_loss: 0.0000e+00 - loss_loss: 6.4743 - val_loss: 2.4064 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.4064\n",
      "Epoch 321/1500\n",
      "204/204 [==============================] - 0s 532us/step - loss: 6.4169 - predict_loss: 0.0000e+00 - loss_loss: 6.4169 - val_loss: 4.8802 - val_predict_loss: 0.0000e+00 - val_loss_loss: 4.8802\n",
      "Epoch 322/1500\n",
      "204/204 [==============================] - 0s 477us/step - loss: 6.9921 - predict_loss: 0.0000e+00 - loss_loss: 6.9921 - val_loss: 0.9150 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9150\n",
      "Epoch 323/1500\n",
      "204/204 [==============================] - 0s 549us/step - loss: 5.2158 - predict_loss: 0.0000e+00 - loss_loss: 5.2158 - val_loss: 1.3538 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3538\n",
      "Epoch 324/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 5.4873 - predict_loss: 0.0000e+00 - loss_loss: 5.4873 - val_loss: 2.0430 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0430\n",
      "Epoch 325/1500\n",
      "204/204 [==============================] - 0s 601us/step - loss: 7.5816 - predict_loss: 0.0000e+00 - loss_loss: 7.5816 - val_loss: 1.0008 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0008\n",
      "Epoch 326/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 4.5821 - predict_loss: 0.0000e+00 - loss_loss: 4.5821 - val_loss: 1.0577 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0577\n",
      "Epoch 327/1500\n",
      "204/204 [==============================] - 0s 503us/step - loss: 7.3808 - predict_loss: 0.0000e+00 - loss_loss: 7.3808 - val_loss: 1.1006 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1006\n",
      "Epoch 328/1500\n",
      "204/204 [==============================] - 0s 515us/step - loss: 5.3456 - predict_loss: 0.0000e+00 - loss_loss: 5.3456 - val_loss: 1.4572 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4572\n",
      "Epoch 329/1500\n",
      "204/204 [==============================] - 0s 510us/step - loss: 6.0954 - predict_loss: 0.0000e+00 - loss_loss: 6.0954 - val_loss: 1.2801 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2801\n",
      "Epoch 330/1500\n",
      "204/204 [==============================] - 0s 529us/step - loss: 4.0856 - predict_loss: 0.0000e+00 - loss_loss: 4.0856 - val_loss: 1.9237 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9237\n",
      "Epoch 331/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 9.1277 - predict_loss: 0.0000e+00 - loss_loss: 9.1277 - val_loss: 1.5212 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5212\n",
      "Epoch 332/1500\n",
      "204/204 [==============================] - 0s 442us/step - loss: 5.9356 - predict_loss: 0.0000e+00 - loss_loss: 5.9356 - val_loss: 1.7008 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7008\n",
      "Epoch 333/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 6.1857 - predict_loss: 0.0000e+00 - loss_loss: 6.1857 - val_loss: 2.7129 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.7129\n",
      "Epoch 334/1500\n",
      "204/204 [==============================] - 0s 536us/step - loss: 6.7934 - predict_loss: 0.0000e+00 - loss_loss: 6.7934 - val_loss: 1.0594 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0594\n",
      "Epoch 335/1500\n",
      "204/204 [==============================] - 0s 555us/step - loss: 5.6769 - predict_loss: 0.0000e+00 - loss_loss: 5.6769 - val_loss: 2.1484 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.1484\n",
      "Epoch 336/1500\n",
      "204/204 [==============================] - 0s 536us/step - loss: 5.4980 - predict_loss: 0.0000e+00 - loss_loss: 5.4980 - val_loss: 1.6853 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6853\n",
      "Epoch 337/1500\n",
      "204/204 [==============================] - 0s 510us/step - loss: 7.2553 - predict_loss: 0.0000e+00 - loss_loss: 7.2553 - val_loss: 1.1538 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1538\n",
      "Epoch 338/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 464us/step - loss: 4.4366 - predict_loss: 0.0000e+00 - loss_loss: 4.4366 - val_loss: 1.4155 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4155\n",
      "Epoch 339/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 6.9557 - predict_loss: 0.0000e+00 - loss_loss: 6.9557 - val_loss: 1.2829 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2829\n",
      "Epoch 340/1500\n",
      "204/204 [==============================] - 0s 509us/step - loss: 5.5435 - predict_loss: 0.0000e+00 - loss_loss: 5.5435 - val_loss: 2.1514 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.1514\n",
      "Epoch 341/1500\n",
      "204/204 [==============================] - 0s 470us/step - loss: 7.2882 - predict_loss: 0.0000e+00 - loss_loss: 7.2882 - val_loss: 1.7839 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7839\n",
      "Epoch 342/1500\n",
      "204/204 [==============================] - 0s 505us/step - loss: 5.6924 - predict_loss: 0.0000e+00 - loss_loss: 5.6924 - val_loss: 0.9075 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9075\n",
      "Epoch 343/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 4.6971 - predict_loss: 0.0000e+00 - loss_loss: 4.6971 - val_loss: 2.3040 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3040\n",
      "Epoch 344/1500\n",
      "204/204 [==============================] - 0s 466us/step - loss: 7.2139 - predict_loss: 0.0000e+00 - loss_loss: 7.2139 - val_loss: 1.1202 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1202\n",
      "Epoch 345/1500\n",
      "204/204 [==============================] - 0s 445us/step - loss: 6.2280 - predict_loss: 0.0000e+00 - loss_loss: 6.2280 - val_loss: 3.7107 - val_predict_loss: 0.0000e+00 - val_loss_loss: 3.7107\n",
      "Epoch 346/1500\n",
      "204/204 [==============================] - 0s 508us/step - loss: 5.3937 - predict_loss: 0.0000e+00 - loss_loss: 5.3937 - val_loss: 1.8127 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8127\n",
      "Epoch 347/1500\n",
      "204/204 [==============================] - 0s 482us/step - loss: 4.6932 - predict_loss: 0.0000e+00 - loss_loss: 4.6932 - val_loss: 1.1388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1388\n",
      "Epoch 348/1500\n",
      "204/204 [==============================] - 0s 440us/step - loss: 7.7326 - predict_loss: 0.0000e+00 - loss_loss: 7.7326 - val_loss: 2.2331 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2331\n",
      "Epoch 349/1500\n",
      "204/204 [==============================] - 0s 443us/step - loss: 5.6677 - predict_loss: 0.0000e+00 - loss_loss: 5.6677 - val_loss: 1.6365 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6365\n",
      "Epoch 350/1500\n",
      "204/204 [==============================] - 0s 456us/step - loss: 6.3310 - predict_loss: 0.0000e+00 - loss_loss: 6.3310 - val_loss: 1.6910 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6910\n",
      "Epoch 351/1500\n",
      "204/204 [==============================] - 0s 444us/step - loss: 6.1182 - predict_loss: 0.0000e+00 - loss_loss: 6.1182 - val_loss: 1.2475 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2475\n",
      "Epoch 352/1500\n",
      "204/204 [==============================] - 0s 465us/step - loss: 5.8607 - predict_loss: 0.0000e+00 - loss_loss: 5.8607 - val_loss: 1.1920 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1920\n",
      "Epoch 353/1500\n",
      "204/204 [==============================] - 0s 463us/step - loss: 5.4237 - predict_loss: 0.0000e+00 - loss_loss: 5.4237 - val_loss: 2.3402 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3402\n",
      "Epoch 354/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 7.3068 - predict_loss: 0.0000e+00 - loss_loss: 7.3068 - val_loss: 1.3538 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3538\n",
      "Epoch 355/1500\n",
      "204/204 [==============================] - 0s 513us/step - loss: 5.7155 - predict_loss: 0.0000e+00 - loss_loss: 5.7155 - val_loss: 1.5542 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5542\n",
      "Epoch 356/1500\n",
      "204/204 [==============================] - 0s 494us/step - loss: 5.3156 - predict_loss: 0.0000e+00 - loss_loss: 5.3156 - val_loss: 1.9806 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9806\n",
      "Epoch 357/1500\n",
      "204/204 [==============================] - 0s 554us/step - loss: 6.2632 - predict_loss: 0.0000e+00 - loss_loss: 6.2632 - val_loss: 1.1114 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1114\n",
      "Epoch 358/1500\n",
      "204/204 [==============================] - 0s 454us/step - loss: 6.3032 - predict_loss: 0.0000e+00 - loss_loss: 6.3032 - val_loss: 1.3495 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3495\n",
      "Epoch 359/1500\n",
      "204/204 [==============================] - 0s 432us/step - loss: 5.9060 - predict_loss: 0.0000e+00 - loss_loss: 5.9060 - val_loss: 1.1145 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1145\n",
      "Epoch 360/1500\n",
      "204/204 [==============================] - 0s 446us/step - loss: 5.1812 - predict_loss: 0.0000e+00 - loss_loss: 5.1812 - val_loss: 1.6079 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6079\n",
      "Epoch 361/1500\n",
      "204/204 [==============================] - 0s 443us/step - loss: 6.3352 - predict_loss: 0.0000e+00 - loss_loss: 6.3352 - val_loss: 1.3491 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3491\n",
      "Epoch 362/1500\n",
      "204/204 [==============================] - 0s 430us/step - loss: 5.9338 - predict_loss: 0.0000e+00 - loss_loss: 5.9338 - val_loss: 1.2526 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2526\n",
      "Epoch 363/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 6.3699 - predict_loss: 0.0000e+00 - loss_loss: 6.3699 - val_loss: 0.9996 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9996\n",
      "Epoch 364/1500\n",
      "204/204 [==============================] - 0s 511us/step - loss: 6.8974 - predict_loss: 0.0000e+00 - loss_loss: 6.8974 - val_loss: 0.9405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9405\n",
      "Epoch 365/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 4.7596 - predict_loss: 0.0000e+00 - loss_loss: 4.7596 - val_loss: 1.0141 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0141\n",
      "Epoch 366/1500\n",
      "204/204 [==============================] - 0s 527us/step - loss: 5.4621 - predict_loss: 0.0000e+00 - loss_loss: 5.4621 - val_loss: 1.2771 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2771\n",
      "Epoch 367/1500\n",
      "204/204 [==============================] - 0s 515us/step - loss: 6.5831 - predict_loss: 0.0000e+00 - loss_loss: 6.5831 - val_loss: 1.0272 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0272\n",
      "Epoch 368/1500\n",
      "204/204 [==============================] - 0s 488us/step - loss: 6.5655 - predict_loss: 0.0000e+00 - loss_loss: 6.5655 - val_loss: 1.5359 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5359\n",
      "Epoch 369/1500\n",
      "204/204 [==============================] - 0s 533us/step - loss: 3.4419 - predict_loss: 0.0000e+00 - loss_loss: 3.4419 - val_loss: 1.9231 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9231\n",
      "Epoch 370/1500\n",
      "204/204 [==============================] - 0s 499us/step - loss: 7.7389 - predict_loss: 0.0000e+00 - loss_loss: 7.7389 - val_loss: 1.3368 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3368\n",
      "Epoch 371/1500\n",
      "204/204 [==============================] - 0s 483us/step - loss: 5.7753 - predict_loss: 0.0000e+00 - loss_loss: 5.7753 - val_loss: 1.0875 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0875\n",
      "Epoch 372/1500\n",
      "204/204 [==============================] - 0s 454us/step - loss: 5.5101 - predict_loss: 0.0000e+00 - loss_loss: 5.5101 - val_loss: 1.3301 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3301\n",
      "Epoch 373/1500\n",
      "204/204 [==============================] - 0s 420us/step - loss: 4.8456 - predict_loss: 0.0000e+00 - loss_loss: 4.8456 - val_loss: 1.9941 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9941\n",
      "Epoch 374/1500\n",
      "204/204 [==============================] - 0s 480us/step - loss: 5.4093 - predict_loss: 0.0000e+00 - loss_loss: 5.4093 - val_loss: 1.1105 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1105\n",
      "Epoch 375/1500\n",
      "204/204 [==============================] - 0s 482us/step - loss: 6.1984 - predict_loss: 0.0000e+00 - loss_loss: 6.1984 - val_loss: 2.6399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.6399\n",
      "Epoch 376/1500\n",
      "204/204 [==============================] - 0s 513us/step - loss: 3.8964 - predict_loss: 0.0000e+00 - loss_loss: 3.8964 - val_loss: 1.2543 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2543\n",
      "Epoch 377/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 524us/step - loss: 7.5963 - predict_loss: 0.0000e+00 - loss_loss: 7.5963 - val_loss: 1.3208 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3208\n",
      "Epoch 378/1500\n",
      "204/204 [==============================] - 0s 404us/step - loss: 4.4030 - predict_loss: 0.0000e+00 - loss_loss: 4.4030 - val_loss: 1.8235 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8235\n",
      "Epoch 379/1500\n",
      "204/204 [==============================] - 0s 470us/step - loss: 6.6208 - predict_loss: 0.0000e+00 - loss_loss: 6.6208 - val_loss: 1.5277 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5277\n",
      "Epoch 380/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 5.3980 - predict_loss: 0.0000e+00 - loss_loss: 5.3980 - val_loss: 0.9204 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9204\n",
      "Epoch 381/1500\n",
      "204/204 [==============================] - 0s 498us/step - loss: 5.9485 - predict_loss: 0.0000e+00 - loss_loss: 5.9485 - val_loss: 1.3355 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3355\n",
      "Epoch 382/1500\n",
      "204/204 [==============================] - 0s 472us/step - loss: 5.8599 - predict_loss: 0.0000e+00 - loss_loss: 5.8599 - val_loss: 1.4995 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4995\n",
      "Epoch 383/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 4.9559 - predict_loss: 0.0000e+00 - loss_loss: 4.9559 - val_loss: 1.6569 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6569\n",
      "Epoch 384/1500\n",
      "204/204 [==============================] - 0s 535us/step - loss: 5.8401 - predict_loss: 0.0000e+00 - loss_loss: 5.8401 - val_loss: 0.8989 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.8989\n",
      "Epoch 385/1500\n",
      "204/204 [==============================] - 0s 467us/step - loss: 4.1677 - predict_loss: 0.0000e+00 - loss_loss: 4.1677 - val_loss: 1.0111 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0111\n",
      "Epoch 386/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 6.6092 - predict_loss: 0.0000e+00 - loss_loss: 6.6092 - val_loss: 1.2083 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2083\n",
      "Epoch 387/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 6.1742 - predict_loss: 0.0000e+00 - loss_loss: 6.1742 - val_loss: 1.5430 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5430\n",
      "Epoch 388/1500\n",
      "204/204 [==============================] - 0s 476us/step - loss: 3.4159 - predict_loss: 0.0000e+00 - loss_loss: 3.4159 - val_loss: 1.4560 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4560\n",
      "Epoch 389/1500\n",
      "204/204 [==============================] - 0s 468us/step - loss: 6.4660 - predict_loss: 0.0000e+00 - loss_loss: 6.4660 - val_loss: 1.6234 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6234\n",
      "Epoch 390/1500\n",
      "204/204 [==============================] - 0s 433us/step - loss: 4.8455 - predict_loss: 0.0000e+00 - loss_loss: 4.8455 - val_loss: 0.9692 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9692\n",
      "Epoch 391/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 5.3348 - predict_loss: 0.0000e+00 - loss_loss: 5.3348 - val_loss: 1.4533 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4533\n",
      "Epoch 392/1500\n",
      "204/204 [==============================] - 0s 434us/step - loss: 4.7674 - predict_loss: 0.0000e+00 - loss_loss: 4.7674 - val_loss: 1.4575 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4575\n",
      "Epoch 393/1500\n",
      "204/204 [==============================] - 0s 347us/step - loss: 6.9644 - predict_loss: 0.0000e+00 - loss_loss: 6.9644 - val_loss: 0.9675 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9675\n",
      "Epoch 394/1500\n",
      "204/204 [==============================] - 0s 424us/step - loss: 5.1183 - predict_loss: 0.0000e+00 - loss_loss: 5.1183 - val_loss: 1.8596 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8596\n",
      "Epoch 395/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 4.3024 - predict_loss: 0.0000e+00 - loss_loss: 4.3024 - val_loss: 1.3629 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.3629\n",
      "Epoch 396/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 5.5158 - predict_loss: 0.0000e+00 - loss_loss: 5.5158 - val_loss: 2.3979 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.3979\n",
      "Epoch 397/1500\n",
      "204/204 [==============================] - 0s 499us/step - loss: 5.7257 - predict_loss: 0.0000e+00 - loss_loss: 5.7257 - val_loss: 0.8927 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.8927\n",
      "Epoch 398/1500\n",
      "204/204 [==============================] - 0s 532us/step - loss: 3.9461 - predict_loss: 0.0000e+00 - loss_loss: 3.9461 - val_loss: 1.0405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0405\n",
      "Epoch 399/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 6.2015 - predict_loss: 0.0000e+00 - loss_loss: 6.2015 - val_loss: 1.0021 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0021\n",
      "Epoch 400/1500\n",
      "204/204 [==============================] - 0s 510us/step - loss: 4.6902 - predict_loss: 0.0000e+00 - loss_loss: 4.6902 - val_loss: 2.0484 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.0484\n",
      "Epoch 401/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 4.7145 - predict_loss: 0.0000e+00 - loss_loss: 4.7145 - val_loss: 1.2566 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2566\n",
      "Epoch 402/1500\n",
      "204/204 [==============================] - 0s 488us/step - loss: 5.9358 - predict_loss: 0.0000e+00 - loss_loss: 5.9358 - val_loss: 1.2320 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2320\n",
      "Epoch 403/1500\n",
      "204/204 [==============================] - 0s 452us/step - loss: 4.4589 - predict_loss: 0.0000e+00 - loss_loss: 4.4589 - val_loss: 1.6297 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6297\n",
      "Epoch 404/1500\n",
      "204/204 [==============================] - 0s 539us/step - loss: 5.1893 - predict_loss: 0.0000e+00 - loss_loss: 5.1893 - val_loss: 1.1549 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1549\n",
      "Epoch 405/1500\n",
      "204/204 [==============================] - 0s 491us/step - loss: 4.9716 - predict_loss: 0.0000e+00 - loss_loss: 4.9716 - val_loss: 1.1256 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1256\n",
      "Epoch 406/1500\n",
      "204/204 [==============================] - 0s 516us/step - loss: 7.2923 - predict_loss: 0.0000e+00 - loss_loss: 7.2923 - val_loss: 1.1250 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1250\n",
      "Epoch 407/1500\n",
      "204/204 [==============================] - 0s 427us/step - loss: 4.3156 - predict_loss: 0.0000e+00 - loss_loss: 4.3156 - val_loss: 0.9143 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9143\n",
      "Epoch 408/1500\n",
      "204/204 [==============================] - 0s 491us/step - loss: 4.5167 - predict_loss: 0.0000e+00 - loss_loss: 4.5167 - val_loss: 1.0121 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0121\n",
      "Epoch 409/1500\n",
      "204/204 [==============================] - 0s 471us/step - loss: 5.9205 - predict_loss: 0.0000e+00 - loss_loss: 5.9205 - val_loss: 1.5156 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.5156\n",
      "Epoch 410/1500\n",
      "204/204 [==============================] - 0s 498us/step - loss: 4.2550 - predict_loss: 0.0000e+00 - loss_loss: 4.2550 - val_loss: 1.2877 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2877\n",
      "Epoch 411/1500\n",
      "204/204 [==============================] - 0s 494us/step - loss: 4.1248 - predict_loss: 0.0000e+00 - loss_loss: 4.1248 - val_loss: 1.7473 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.7473\n",
      "Epoch 412/1500\n",
      "204/204 [==============================] - 0s 487us/step - loss: 4.9408 - predict_loss: 0.0000e+00 - loss_loss: 4.9408 - val_loss: 0.9082 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9082\n",
      "Epoch 413/1500\n",
      "204/204 [==============================] - 0s 458us/step - loss: 5.1922 - predict_loss: 0.0000e+00 - loss_loss: 5.1922 - val_loss: 1.4820 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4820\n",
      "Epoch 414/1500\n",
      "204/204 [==============================] - 0s 426us/step - loss: 4.2746 - predict_loss: 0.0000e+00 - loss_loss: 4.2746 - val_loss: 1.1184 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1184\n",
      "Epoch 415/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 4.4626 - predict_loss: 0.0000e+00 - loss_loss: 4.4626 - val_loss: 1.4211 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4211\n",
      "Epoch 416/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 538us/step - loss: 6.1382 - predict_loss: 0.0000e+00 - loss_loss: 6.1382 - val_loss: 1.2423 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2423\n",
      "Epoch 417/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 3.7832 - predict_loss: 0.0000e+00 - loss_loss: 3.7832 - val_loss: 1.1822 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1822\n",
      "Epoch 418/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 5.6167 - predict_loss: 0.0000e+00 - loss_loss: 5.6167 - val_loss: 1.6727 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6727\n",
      "Epoch 419/1500\n",
      "204/204 [==============================] - 0s 498us/step - loss: 4.3984 - predict_loss: 0.0000e+00 - loss_loss: 4.3984 - val_loss: 1.6302 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.6302\n",
      "Epoch 420/1500\n",
      "204/204 [==============================] - 0s 496us/step - loss: 5.3809 - predict_loss: 0.0000e+00 - loss_loss: 5.3809 - val_loss: 1.0726 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0726\n",
      "Epoch 421/1500\n",
      "204/204 [==============================] - 0s 462us/step - loss: 5.9634 - predict_loss: 0.0000e+00 - loss_loss: 5.9634 - val_loss: 1.2530 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2530\n",
      "Epoch 422/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 3.8660 - predict_loss: 0.0000e+00 - loss_loss: 3.8660 - val_loss: 0.9885 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9885\n",
      "Epoch 423/1500\n",
      "204/204 [==============================] - 0s 536us/step - loss: 4.9827 - predict_loss: 0.0000e+00 - loss_loss: 4.9827 - val_loss: 1.9844 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.9844\n",
      "Epoch 424/1500\n",
      "204/204 [==============================] - 0s 510us/step - loss: 5.0378 - predict_loss: 0.0000e+00 - loss_loss: 5.0378 - val_loss: 0.7748 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.7748\n",
      "Epoch 425/1500\n",
      "204/204 [==============================] - 0s 481us/step - loss: 4.7916 - predict_loss: 0.0000e+00 - loss_loss: 4.7916 - val_loss: 1.1638 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1638\n",
      "Epoch 426/1500\n",
      "204/204 [==============================] - 0s 557us/step - loss: 4.2402 - predict_loss: 0.0000e+00 - loss_loss: 4.2402 - val_loss: 1.0781 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0781\n",
      "Epoch 427/1500\n",
      "204/204 [==============================] - 0s 546us/step - loss: 4.7076 - predict_loss: 0.0000e+00 - loss_loss: 4.7076 - val_loss: 0.6971 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.6971\n",
      "Epoch 428/1500\n",
      "204/204 [==============================] - 0s 548us/step - loss: 5.4383 - predict_loss: 0.0000e+00 - loss_loss: 5.4383 - val_loss: 0.8890 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.8890\n",
      "Epoch 429/1500\n",
      "204/204 [==============================] - 0s 507us/step - loss: 4.8970 - predict_loss: 0.0000e+00 - loss_loss: 4.8970 - val_loss: 0.8591 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.8591\n",
      "Epoch 430/1500\n",
      "204/204 [==============================] - 0s 584us/step - loss: 4.1748 - predict_loss: 0.0000e+00 - loss_loss: 4.1748 - val_loss: 1.0057 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.0057\n",
      "Epoch 431/1500\n",
      "204/204 [==============================] - 0s 456us/step - loss: 4.8048 - predict_loss: 0.0000e+00 - loss_loss: 4.8048 - val_loss: 2.1437 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.1437\n",
      "Epoch 432/1500\n",
      "204/204 [==============================] - 0s 455us/step - loss: 5.0123 - predict_loss: 0.0000e+00 - loss_loss: 5.0123 - val_loss: 1.1527 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1527\n",
      "Epoch 433/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 3.8534 - predict_loss: 0.0000e+00 - loss_loss: 3.8534 - val_loss: 1.4720 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4720\n",
      "Epoch 434/1500\n",
      "204/204 [==============================] - 0s 506us/step - loss: 6.0280 - predict_loss: 0.0000e+00 - loss_loss: 6.0280 - val_loss: 1.2042 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.2042\n",
      "Epoch 435/1500\n",
      "204/204 [==============================] - 0s 525us/step - loss: 3.8689 - predict_loss: 0.0000e+00 - loss_loss: 3.8689 - val_loss: 2.2732 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.2732\n",
      "Epoch 436/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 5.6255 - predict_loss: 0.0000e+00 - loss_loss: 5.6255 - val_loss: 1.8280 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.8280\n",
      "Epoch 437/1500\n",
      "204/204 [==============================] - 0s 489us/step - loss: 4.7797 - predict_loss: 0.0000e+00 - loss_loss: 4.7797 - val_loss: 1.1321 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.1321\n",
      "Epoch 438/1500\n",
      "204/204 [==============================] - 0s 510us/step - loss: 5.5753 - predict_loss: 0.0000e+00 - loss_loss: 5.5753 - val_loss: 1.4084 - val_predict_loss: 0.0000e+00 - val_loss_loss: 1.4084\n",
      "Epoch 439/1500\n",
      "204/204 [==============================] - 0s 1ms/step - loss: 5.2308 - predict_loss: 0.0000e+00 - loss_loss: 5.2308 - val_loss: 2.8658 - val_predict_loss: 0.0000e+00 - val_loss_loss: 2.8658\n",
      "Epoch 440/1500\n",
      "204/204 [==============================] - 0s 508us/step - loss: 1.3391 - predict_loss: 0.0000e+00 - loss_loss: 1.3391 - val_loss: 0.5931 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5931\n",
      "Epoch 441/1500\n",
      "204/204 [==============================] - 0s 541us/step - loss: 1.0538 - predict_loss: 0.0000e+00 - loss_loss: 1.0538 - val_loss: 0.4498 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4498\n",
      "Epoch 442/1500\n",
      "204/204 [==============================] - 0s 507us/step - loss: 1.5217 - predict_loss: 0.0000e+00 - loss_loss: 1.5217 - val_loss: 0.7662 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.7662\n",
      "Epoch 443/1500\n",
      "204/204 [==============================] - 0s 505us/step - loss: 1.1393 - predict_loss: 0.0000e+00 - loss_loss: 1.1393 - val_loss: 0.6424 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.6424\n",
      "Epoch 444/1500\n",
      "204/204 [==============================] - 0s 609us/step - loss: 2.0725 - predict_loss: 0.0000e+00 - loss_loss: 2.0725 - val_loss: 0.7095 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.7095\n",
      "Epoch 445/1500\n",
      "204/204 [==============================] - 0s 499us/step - loss: 1.2781 - predict_loss: 0.0000e+00 - loss_loss: 1.2781 - val_loss: 0.5961 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5961\n",
      "Epoch 446/1500\n",
      "204/204 [==============================] - 0s 498us/step - loss: 1.6969 - predict_loss: 0.0000e+00 - loss_loss: 1.6969 - val_loss: 0.5887 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5887\n",
      "Epoch 447/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 1.6818 - predict_loss: 0.0000e+00 - loss_loss: 1.6818 - val_loss: 0.3729 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3729\n",
      "Epoch 448/1500\n",
      "204/204 [==============================] - 0s 527us/step - loss: 1.5497 - predict_loss: 0.0000e+00 - loss_loss: 1.5497 - val_loss: 0.8453 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.8453\n",
      "Epoch 449/1500\n",
      "204/204 [==============================] - 0s 523us/step - loss: 1.6539 - predict_loss: 0.0000e+00 - loss_loss: 1.6539 - val_loss: 0.7349 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.7349\n",
      "Epoch 450/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 1.5144 - predict_loss: 0.0000e+00 - loss_loss: 1.5144 - val_loss: 0.5285 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5285\n",
      "Epoch 451/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 1.2098 - predict_loss: 0.0000e+00 - loss_loss: 1.2098 - val_loss: 0.9928 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.9928\n",
      "Epoch 452/1500\n",
      "204/204 [==============================] - 0s 591us/step - loss: 2.1114 - predict_loss: 0.0000e+00 - loss_loss: 2.1114 - val_loss: 0.6078 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.6078\n",
      "Epoch 453/1500\n",
      "204/204 [==============================] - 0s 597us/step - loss: 1.5013 - predict_loss: 0.0000e+00 - loss_loss: 1.5013 - val_loss: 0.6292 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.6292\n",
      "Epoch 454/1500\n",
      "204/204 [==============================] - 0s 622us/step - loss: 1.5878 - predict_loss: 0.0000e+00 - loss_loss: 1.5878 - val_loss: 0.5565 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5565\n",
      "Epoch 455/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 601us/step - loss: 1.6182 - predict_loss: 0.0000e+00 - loss_loss: 1.6182 - val_loss: 0.6611 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.6611\n",
      "Epoch 456/1500\n",
      "204/204 [==============================] - 0s 597us/step - loss: 1.0352 - predict_loss: 0.0000e+00 - loss_loss: 1.0352 - val_loss: 0.5669 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5669\n",
      "Epoch 457/1500\n",
      "204/204 [==============================] - 0s 463us/step - loss: 2.2226 - predict_loss: 0.0000e+00 - loss_loss: 2.2226 - val_loss: 0.6713 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.6713\n",
      "Epoch 458/1500\n",
      "204/204 [==============================] - 0s 453us/step - loss: 1.5119 - predict_loss: 0.0000e+00 - loss_loss: 1.5119 - val_loss: 0.4826 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4826\n",
      "Epoch 459/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 1.5725 - predict_loss: 0.0000e+00 - loss_loss: 1.5725 - val_loss: 0.5712 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5712\n",
      "Epoch 460/1500\n",
      "204/204 [==============================] - 0s 426us/step - loss: 1.6125 - predict_loss: 0.0000e+00 - loss_loss: 1.6125 - val_loss: 0.8663 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.8663\n",
      "Epoch 461/1500\n",
      "204/204 [==============================] - 0s 317us/step - loss: 1.4072 - predict_loss: 0.0000e+00 - loss_loss: 1.4072 - val_loss: 0.7216 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.7216\n",
      "Epoch 462/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 1.6028 - predict_loss: 0.0000e+00 - loss_loss: 1.6028 - val_loss: 0.3524 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3524\n",
      "Epoch 463/1500\n",
      "204/204 [==============================] - 0s 353us/step - loss: 1.6181 - predict_loss: 0.0000e+00 - loss_loss: 1.6181 - val_loss: 0.4662 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4662\n",
      "Epoch 464/1500\n",
      "204/204 [==============================] - 0s 302us/step - loss: 1.2603 - predict_loss: 0.0000e+00 - loss_loss: 1.2603 - val_loss: 0.5596 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5596\n",
      "Epoch 465/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 1.5253 - predict_loss: 0.0000e+00 - loss_loss: 1.5253 - val_loss: 0.4920 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4920\n",
      "Epoch 466/1500\n",
      "204/204 [==============================] - 0s 342us/step - loss: 1.6279 - predict_loss: 0.0000e+00 - loss_loss: 1.6279 - val_loss: 0.5961 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5961\n",
      "Epoch 467/1500\n",
      "204/204 [==============================] - 0s 396us/step - loss: 1.4119 - predict_loss: 0.0000e+00 - loss_loss: 1.4119 - val_loss: 0.3878 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3878\n",
      "Epoch 468/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 1.4544 - predict_loss: 0.0000e+00 - loss_loss: 1.4544 - val_loss: 0.8412 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.8412\n",
      "Epoch 469/1500\n",
      "204/204 [==============================] - 0s 518us/step - loss: 1.9098 - predict_loss: 0.0000e+00 - loss_loss: 1.9098 - val_loss: 0.5141 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5141\n",
      "Epoch 470/1500\n",
      "204/204 [==============================] - 0s 480us/step - loss: 1.3875 - predict_loss: 0.0000e+00 - loss_loss: 1.3875 - val_loss: 0.7751 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.7751\n",
      "Epoch 471/1500\n",
      "204/204 [==============================] - 0s 473us/step - loss: 1.2975 - predict_loss: 0.0000e+00 - loss_loss: 1.2975 - val_loss: 0.4769 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4769\n",
      "Epoch 472/1500\n",
      "204/204 [==============================] - 0s 486us/step - loss: 1.3351 - predict_loss: 0.0000e+00 - loss_loss: 1.3351 - val_loss: 0.4196 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4196\n",
      "Epoch 473/1500\n",
      "204/204 [==============================] - 0s 488us/step - loss: 1.7966 - predict_loss: 0.0000e+00 - loss_loss: 1.7966 - val_loss: 0.4959 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4959\n",
      "Epoch 474/1500\n",
      "204/204 [==============================] - 0s 544us/step - loss: 1.0562 - predict_loss: 0.0000e+00 - loss_loss: 1.0562 - val_loss: 0.6619 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.6619\n",
      "Epoch 475/1500\n",
      "204/204 [==============================] - 0s 521us/step - loss: 1.7476 - predict_loss: 0.0000e+00 - loss_loss: 1.7476 - val_loss: 0.3443 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3443\n",
      "Epoch 476/1500\n",
      "204/204 [==============================] - 0s 612us/step - loss: 1.5766 - predict_loss: 0.0000e+00 - loss_loss: 1.5766 - val_loss: 0.5351 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5351\n",
      "Epoch 477/1500\n",
      "204/204 [==============================] - 0s 481us/step - loss: 1.4415 - predict_loss: 0.0000e+00 - loss_loss: 1.4415 - val_loss: 0.3562 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3562\n",
      "Epoch 478/1500\n",
      "204/204 [==============================] - 0s 443us/step - loss: 1.5353 - predict_loss: 0.0000e+00 - loss_loss: 1.5353 - val_loss: 0.4568 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4568\n",
      "Epoch 479/1500\n",
      "204/204 [==============================] - 0s 365us/step - loss: 1.8000 - predict_loss: 0.0000e+00 - loss_loss: 1.8000 - val_loss: 0.3797 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3797\n",
      "Epoch 480/1500\n",
      "204/204 [==============================] - 0s 419us/step - loss: 1.4702 - predict_loss: 0.0000e+00 - loss_loss: 1.4702 - val_loss: 0.4123 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4123\n",
      "Epoch 481/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 1.4616 - predict_loss: 0.0000e+00 - loss_loss: 1.4616 - val_loss: 0.6769 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.6769\n",
      "Epoch 482/1500\n",
      "204/204 [==============================] - 0s 381us/step - loss: 1.5899 - predict_loss: 0.0000e+00 - loss_loss: 1.5899 - val_loss: 0.3726 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3726\n",
      "Epoch 483/1500\n",
      "204/204 [==============================] - 0s 456us/step - loss: 1.3028 - predict_loss: 0.0000e+00 - loss_loss: 1.3028 - val_loss: 0.3299 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3299\n",
      "Epoch 484/1500\n",
      "204/204 [==============================] - 0s 465us/step - loss: 1.6923 - predict_loss: 0.0000e+00 - loss_loss: 1.6923 - val_loss: 0.3025 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3025\n",
      "Epoch 485/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 1.1806 - predict_loss: 0.0000e+00 - loss_loss: 1.1806 - val_loss: 0.3831 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3831\n",
      "Epoch 486/1500\n",
      "204/204 [==============================] - 0s 462us/step - loss: 1.3814 - predict_loss: 0.0000e+00 - loss_loss: 1.3814 - val_loss: 0.3463 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3463\n",
      "Epoch 487/1500\n",
      "204/204 [==============================] - 0s 472us/step - loss: 1.8393 - predict_loss: 0.0000e+00 - loss_loss: 1.8393 - val_loss: 0.4810 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4810\n",
      "Epoch 488/1500\n",
      "204/204 [==============================] - 0s 457us/step - loss: 1.3523 - predict_loss: 0.0000e+00 - loss_loss: 1.3523 - val_loss: 0.5190 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5190\n",
      "Epoch 489/1500\n",
      "204/204 [==============================] - 0s 468us/step - loss: 1.4462 - predict_loss: 0.0000e+00 - loss_loss: 1.4462 - val_loss: 0.3885 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3885\n",
      "Epoch 490/1500\n",
      "204/204 [==============================] - 0s 476us/step - loss: 1.5283 - predict_loss: 0.0000e+00 - loss_loss: 1.5283 - val_loss: 0.5028 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5028\n",
      "Epoch 491/1500\n",
      "204/204 [==============================] - 0s 545us/step - loss: 1.4567 - predict_loss: 0.0000e+00 - loss_loss: 1.4567 - val_loss: 0.5323 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5323\n",
      "Epoch 492/1500\n",
      "204/204 [==============================] - 0s 486us/step - loss: 1.3854 - predict_loss: 0.0000e+00 - loss_loss: 1.3854 - val_loss: 0.8104 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.8104\n",
      "Epoch 493/1500\n",
      "204/204 [==============================] - 0s 597us/step - loss: 1.8113 - predict_loss: 0.0000e+00 - loss_loss: 1.8113 - val_loss: 0.3561 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3561\n",
      "Epoch 494/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 553us/step - loss: 1.2203 - predict_loss: 0.0000e+00 - loss_loss: 1.2203 - val_loss: 0.4478 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4478\n",
      "Epoch 495/1500\n",
      "204/204 [==============================] - 0s 587us/step - loss: 1.4703 - predict_loss: 0.0000e+00 - loss_loss: 1.4703 - val_loss: 0.4731 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4731\n",
      "Epoch 496/1500\n",
      "204/204 [==============================] - 0s 562us/step - loss: 1.6155 - predict_loss: 0.0000e+00 - loss_loss: 1.6155 - val_loss: 0.5181 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5181\n",
      "Epoch 497/1500\n",
      "204/204 [==============================] - 0s 424us/step - loss: 1.3322 - predict_loss: 0.0000e+00 - loss_loss: 1.3322 - val_loss: 0.3627 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3627\n",
      "Epoch 498/1500\n",
      "204/204 [==============================] - 0s 422us/step - loss: 1.1325 - predict_loss: 0.0000e+00 - loss_loss: 1.1325 - val_loss: 0.3974 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3974\n",
      "Epoch 499/1500\n",
      "204/204 [==============================] - 0s 543us/step - loss: 1.6618 - predict_loss: 0.0000e+00 - loss_loss: 1.6618 - val_loss: 0.3839 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3839\n",
      "Epoch 500/1500\n",
      "204/204 [==============================] - 0s 539us/step - loss: 1.1044 - predict_loss: 0.0000e+00 - loss_loss: 1.1044 - val_loss: 0.3492 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3492\n",
      "Epoch 501/1500\n",
      "204/204 [==============================] - 0s 470us/step - loss: 1.2412 - predict_loss: 0.0000e+00 - loss_loss: 1.2412 - val_loss: 0.4876 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4876\n",
      "Epoch 502/1500\n",
      "204/204 [==============================] - 0s 483us/step - loss: 1.9561 - predict_loss: 0.0000e+00 - loss_loss: 1.9561 - val_loss: 0.4173 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4173\n",
      "Epoch 503/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 1.4517 - predict_loss: 0.0000e+00 - loss_loss: 1.4517 - val_loss: 0.3887 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3887\n",
      "Epoch 504/1500\n",
      "204/204 [==============================] - 0s 559us/step - loss: 1.5302 - predict_loss: 0.0000e+00 - loss_loss: 1.5302 - val_loss: 0.5249 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5249\n",
      "Epoch 505/1500\n",
      "204/204 [==============================] - 0s 539us/step - loss: 1.3911 - predict_loss: 0.0000e+00 - loss_loss: 1.3911 - val_loss: 0.3691 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3691\n",
      "Epoch 506/1500\n",
      "204/204 [==============================] - 0s 548us/step - loss: 1.4088 - predict_loss: 0.0000e+00 - loss_loss: 1.4088 - val_loss: 0.5537 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.5537\n",
      "Epoch 507/1500\n",
      "204/204 [==============================] - 0s 522us/step - loss: 1.5132 - predict_loss: 0.0000e+00 - loss_loss: 1.5132 - val_loss: 0.4529 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.4529\n",
      "Epoch 508/1500\n",
      "204/204 [==============================] - 0s 468us/step - loss: 0.3545 - predict_loss: 0.0000e+00 - loss_loss: 0.3545 - val_loss: 0.2958 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2958\n",
      "Epoch 509/1500\n",
      "204/204 [==============================] - 0s 415us/step - loss: 0.4812 - predict_loss: 0.0000e+00 - loss_loss: 0.4812 - val_loss: 0.3457 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3457\n",
      "Epoch 510/1500\n",
      "204/204 [==============================] - 0s 472us/step - loss: 0.4789 - predict_loss: 0.0000e+00 - loss_loss: 0.4789 - val_loss: 0.2831 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2831\n",
      "Epoch 511/1500\n",
      "204/204 [==============================] - 0s 481us/step - loss: 0.5333 - predict_loss: 0.0000e+00 - loss_loss: 0.5333 - val_loss: 0.2664 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2664\n",
      "Epoch 512/1500\n",
      "204/204 [==============================] - 0s 518us/step - loss: 0.4137 - predict_loss: 0.0000e+00 - loss_loss: 0.4137 - val_loss: 0.1892 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1892\n",
      "Epoch 513/1500\n",
      "204/204 [==============================] - 0s 437us/step - loss: 0.7463 - predict_loss: 0.0000e+00 - loss_loss: 0.7463 - val_loss: 0.2161 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2161\n",
      "Epoch 514/1500\n",
      "204/204 [==============================] - 0s 510us/step - loss: 0.3860 - predict_loss: 0.0000e+00 - loss_loss: 0.3860 - val_loss: 0.2554 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2554\n",
      "Epoch 515/1500\n",
      "204/204 [==============================] - 0s 469us/step - loss: 0.4860 - predict_loss: 0.0000e+00 - loss_loss: 0.4860 - val_loss: 0.3050 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3050\n",
      "Epoch 516/1500\n",
      "204/204 [==============================] - 0s 460us/step - loss: 0.5967 - predict_loss: 0.0000e+00 - loss_loss: 0.5967 - val_loss: 0.2268 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2268\n",
      "Epoch 517/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 0.4199 - predict_loss: 0.0000e+00 - loss_loss: 0.4199 - val_loss: 0.2414 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2414\n",
      "Epoch 518/1500\n",
      "204/204 [==============================] - 0s 533us/step - loss: 0.4984 - predict_loss: 0.0000e+00 - loss_loss: 0.4984 - val_loss: 0.2600 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2600\n",
      "Epoch 519/1500\n",
      "204/204 [==============================] - 0s 563us/step - loss: 0.3642 - predict_loss: 0.0000e+00 - loss_loss: 0.3642 - val_loss: 0.1943 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1943\n",
      "Epoch 520/1500\n",
      "204/204 [==============================] - 0s 581us/step - loss: 0.5749 - predict_loss: 0.0000e+00 - loss_loss: 0.5749 - val_loss: 0.1794 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1794\n",
      "Epoch 521/1500\n",
      "204/204 [==============================] - 0s 490us/step - loss: 0.4059 - predict_loss: 0.0000e+00 - loss_loss: 0.4059 - val_loss: 0.2463 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2463\n",
      "Epoch 522/1500\n",
      "204/204 [==============================] - 0s 582us/step - loss: 0.3989 - predict_loss: 0.0000e+00 - loss_loss: 0.3989 - val_loss: 0.2619 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2619\n",
      "Epoch 523/1500\n",
      "204/204 [==============================] - 0s 516us/step - loss: 0.4042 - predict_loss: 0.0000e+00 - loss_loss: 0.4042 - val_loss: 0.1563 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1563\n",
      "Epoch 524/1500\n",
      "204/204 [==============================] - 0s 524us/step - loss: 0.6944 - predict_loss: 0.0000e+00 - loss_loss: 0.6944 - val_loss: 0.1616 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1616\n",
      "Epoch 525/1500\n",
      "204/204 [==============================] - 0s 532us/step - loss: 0.4444 - predict_loss: 0.0000e+00 - loss_loss: 0.4444 - val_loss: 0.1740 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1740\n",
      "Epoch 526/1500\n",
      "204/204 [==============================] - 0s 562us/step - loss: 0.5565 - predict_loss: 0.0000e+00 - loss_loss: 0.5565 - val_loss: 0.2246 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2246\n",
      "Epoch 527/1500\n",
      "204/204 [==============================] - 0s 594us/step - loss: 0.4107 - predict_loss: 0.0000e+00 - loss_loss: 0.4107 - val_loss: 0.2159 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2159\n",
      "Epoch 528/1500\n",
      "204/204 [==============================] - 0s 593us/step - loss: 0.6114 - predict_loss: 0.0000e+00 - loss_loss: 0.6114 - val_loss: 0.1865 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1865\n",
      "Epoch 529/1500\n",
      "204/204 [==============================] - 0s 507us/step - loss: 0.4076 - predict_loss: 0.0000e+00 - loss_loss: 0.4076 - val_loss: 0.1750 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1750\n",
      "Epoch 530/1500\n",
      "204/204 [==============================] - 0s 583us/step - loss: 0.5840 - predict_loss: 0.0000e+00 - loss_loss: 0.5840 - val_loss: 0.2432 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2432\n",
      "Epoch 531/1500\n",
      "204/204 [==============================] - 0s 594us/step - loss: 0.4532 - predict_loss: 0.0000e+00 - loss_loss: 0.4532 - val_loss: 0.1746 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1746\n",
      "Epoch 532/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 0.4076 - predict_loss: 0.0000e+00 - loss_loss: 0.4076 - val_loss: 0.1570 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1570\n",
      "Epoch 533/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 552us/step - loss: 0.3685 - predict_loss: 0.0000e+00 - loss_loss: 0.3685 - val_loss: 0.2231 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2231\n",
      "Epoch 534/1500\n",
      "204/204 [==============================] - 0s 482us/step - loss: 0.6148 - predict_loss: 0.0000e+00 - loss_loss: 0.6148 - val_loss: 0.1531 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1531\n",
      "Epoch 535/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 0.5224 - predict_loss: 0.0000e+00 - loss_loss: 0.5224 - val_loss: 0.2130 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2130\n",
      "Epoch 536/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 0.4573 - predict_loss: 0.0000e+00 - loss_loss: 0.4573 - val_loss: 0.1910 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1910\n",
      "Epoch 537/1500\n",
      "204/204 [==============================] - 0s 566us/step - loss: 0.4797 - predict_loss: 0.0000e+00 - loss_loss: 0.4797 - val_loss: 0.2936 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2936\n",
      "Epoch 538/1500\n",
      "204/204 [==============================] - 0s 526us/step - loss: 0.5402 - predict_loss: 0.0000e+00 - loss_loss: 0.5402 - val_loss: 0.2494 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2494\n",
      "Epoch 539/1500\n",
      "204/204 [==============================] - 0s 580us/step - loss: 0.5048 - predict_loss: 0.0000e+00 - loss_loss: 0.5048 - val_loss: 0.1457 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1457\n",
      "Epoch 540/1500\n",
      "204/204 [==============================] - 0s 420us/step - loss: 0.4303 - predict_loss: 0.0000e+00 - loss_loss: 0.4303 - val_loss: 0.1480 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1480\n",
      "Epoch 541/1500\n",
      "204/204 [==============================] - 0s 498us/step - loss: 0.4617 - predict_loss: 0.0000e+00 - loss_loss: 0.4617 - val_loss: 0.1948 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1948\n",
      "Epoch 542/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 0.4888 - predict_loss: 0.0000e+00 - loss_loss: 0.4888 - val_loss: 0.2301 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2301\n",
      "Epoch 543/1500\n",
      "204/204 [==============================] - 0s 501us/step - loss: 0.4585 - predict_loss: 0.0000e+00 - loss_loss: 0.4585 - val_loss: 0.1695 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1695\n",
      "Epoch 544/1500\n",
      "204/204 [==============================] - 0s 495us/step - loss: 0.4236 - predict_loss: 0.0000e+00 - loss_loss: 0.4236 - val_loss: 0.2073 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2073\n",
      "Epoch 545/1500\n",
      "204/204 [==============================] - 0s 396us/step - loss: 0.4842 - predict_loss: 0.0000e+00 - loss_loss: 0.4842 - val_loss: 0.1689 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1689\n",
      "Epoch 546/1500\n",
      "204/204 [==============================] - 0s 572us/step - loss: 0.5498 - predict_loss: 0.0000e+00 - loss_loss: 0.5498 - val_loss: 0.1846 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1846\n",
      "Epoch 547/1500\n",
      "204/204 [==============================] - 0s 532us/step - loss: 0.5089 - predict_loss: 0.0000e+00 - loss_loss: 0.5089 - val_loss: 0.1476 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1476\n",
      "Epoch 548/1500\n",
      "204/204 [==============================] - 0s 490us/step - loss: 0.4735 - predict_loss: 0.0000e+00 - loss_loss: 0.4735 - val_loss: 0.1432 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1432\n",
      "Epoch 549/1500\n",
      "204/204 [==============================] - 0s 480us/step - loss: 0.3791 - predict_loss: 0.0000e+00 - loss_loss: 0.3791 - val_loss: 0.1674 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1674\n",
      "Epoch 550/1500\n",
      "204/204 [==============================] - 0s 555us/step - loss: 0.6390 - predict_loss: 0.0000e+00 - loss_loss: 0.6390 - val_loss: 0.1619 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1619\n",
      "Epoch 551/1500\n",
      "204/204 [==============================] - 0s 557us/step - loss: 0.3393 - predict_loss: 0.0000e+00 - loss_loss: 0.3393 - val_loss: 0.2698 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2698\n",
      "Epoch 552/1500\n",
      "204/204 [==============================] - 0s 338us/step - loss: 0.6287 - predict_loss: 0.0000e+00 - loss_loss: 0.6287 - val_loss: 0.2305 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2305\n",
      "Epoch 553/1500\n",
      "204/204 [==============================] - 0s 372us/step - loss: 0.4332 - predict_loss: 0.0000e+00 - loss_loss: 0.4332 - val_loss: 0.1424 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1424\n",
      "Epoch 554/1500\n",
      "204/204 [==============================] - 0s 518us/step - loss: 0.5653 - predict_loss: 0.0000e+00 - loss_loss: 0.5653 - val_loss: 0.2505 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2505\n",
      "Epoch 555/1500\n",
      "204/204 [==============================] - 0s 494us/step - loss: 0.4262 - predict_loss: 0.0000e+00 - loss_loss: 0.4262 - val_loss: 0.1551 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1551\n",
      "Epoch 556/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.3674 - predict_loss: 0.0000e+00 - loss_loss: 0.3674 - val_loss: 0.3091 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.3091\n",
      "Epoch 557/1500\n",
      "204/204 [==============================] - 0s 399us/step - loss: 0.5299 - predict_loss: 0.0000e+00 - loss_loss: 0.5299 - val_loss: 0.1791 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1791\n",
      "Epoch 558/1500\n",
      "204/204 [==============================] - 0s 456us/step - loss: 0.4857 - predict_loss: 0.0000e+00 - loss_loss: 0.4857 - val_loss: 0.1587 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1587\n",
      "Epoch 559/1500\n",
      "204/204 [==============================] - 0s 495us/step - loss: 0.3687 - predict_loss: 0.0000e+00 - loss_loss: 0.3687 - val_loss: 0.1508 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1508\n",
      "Epoch 560/1500\n",
      "204/204 [==============================] - 0s 427us/step - loss: 0.6456 - predict_loss: 0.0000e+00 - loss_loss: 0.6456 - val_loss: 0.2155 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2155\n",
      "Epoch 561/1500\n",
      "204/204 [==============================] - 0s 429us/step - loss: 0.4497 - predict_loss: 0.0000e+00 - loss_loss: 0.4497 - val_loss: 0.1457 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1457\n",
      "Epoch 562/1500\n",
      "204/204 [==============================] - 0s 358us/step - loss: 0.3102 - predict_loss: 0.0000e+00 - loss_loss: 0.3102 - val_loss: 0.2129 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2129\n",
      "Epoch 563/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.5646 - predict_loss: 0.0000e+00 - loss_loss: 0.5646 - val_loss: 0.1642 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1642\n",
      "Epoch 564/1500\n",
      "204/204 [==============================] - 0s 353us/step - loss: 0.4649 - predict_loss: 0.0000e+00 - loss_loss: 0.4649 - val_loss: 0.1597 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1597\n",
      "Epoch 565/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 0.3708 - predict_loss: 0.0000e+00 - loss_loss: 0.3708 - val_loss: 0.1469 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1469\n",
      "Epoch 566/1500\n",
      "204/204 [==============================] - 0s 432us/step - loss: 0.4941 - predict_loss: 0.0000e+00 - loss_loss: 0.4941 - val_loss: 0.1780 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1780\n",
      "Epoch 567/1500\n",
      "204/204 [==============================] - 0s 480us/step - loss: 0.4947 - predict_loss: 0.0000e+00 - loss_loss: 0.4947 - val_loss: 0.1487 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1487\n",
      "Epoch 568/1500\n",
      "204/204 [==============================] - 0s 392us/step - loss: 0.5582 - predict_loss: 0.0000e+00 - loss_loss: 0.5582 - val_loss: 0.1575 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1575\n",
      "Epoch 569/1500\n",
      "204/204 [==============================] - 0s 395us/step - loss: 0.5234 - predict_loss: 0.0000e+00 - loss_loss: 0.5234 - val_loss: 0.1751 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1751\n",
      "Epoch 570/1500\n",
      "204/204 [==============================] - 0s 378us/step - loss: 0.2549 - predict_loss: 0.0000e+00 - loss_loss: 0.2549 - val_loss: 0.1482 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1482\n",
      "Epoch 571/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.5789 - predict_loss: 0.0000e+00 - loss_loss: 0.5789 - val_loss: 0.2094 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2094\n",
      "Epoch 572/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 430us/step - loss: 0.3548 - predict_loss: 0.0000e+00 - loss_loss: 0.3548 - val_loss: 0.1622 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1622\n",
      "Epoch 573/1500\n",
      "204/204 [==============================] - 0s 417us/step - loss: 0.5557 - predict_loss: 0.0000e+00 - loss_loss: 0.5557 - val_loss: 0.2209 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2209\n",
      "Epoch 574/1500\n",
      "204/204 [==============================] - 0s 452us/step - loss: 0.4124 - predict_loss: 0.0000e+00 - loss_loss: 0.4124 - val_loss: 0.1773 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1773\n",
      "Epoch 575/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.4405 - predict_loss: 0.0000e+00 - loss_loss: 0.4405 - val_loss: 0.1927 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1927\n",
      "Epoch 576/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 0.3419 - predict_loss: 0.0000e+00 - loss_loss: 0.3419 - val_loss: 0.1261 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1261\n",
      "Epoch 577/1500\n",
      "204/204 [==============================] - 0s 406us/step - loss: 0.6745 - predict_loss: 0.0000e+00 - loss_loss: 0.6745 - val_loss: 0.1412 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1412\n",
      "Epoch 578/1500\n",
      "204/204 [==============================] - 0s 353us/step - loss: 0.4064 - predict_loss: 0.0000e+00 - loss_loss: 0.4064 - val_loss: 0.1591 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1591\n",
      "Epoch 579/1500\n",
      "204/204 [==============================] - 0s 379us/step - loss: 0.3412 - predict_loss: 0.0000e+00 - loss_loss: 0.3412 - val_loss: 0.1527 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1527\n",
      "Epoch 580/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 0.7549 - predict_loss: 0.0000e+00 - loss_loss: 0.7549 - val_loss: 0.1131 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1131\n",
      "Epoch 581/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.3438 - predict_loss: 0.0000e+00 - loss_loss: 0.3438 - val_loss: 0.1865 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1865\n",
      "Epoch 582/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.4324 - predict_loss: 0.0000e+00 - loss_loss: 0.4324 - val_loss: 0.1861 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1861\n",
      "Epoch 583/1500\n",
      "204/204 [==============================] - 0s 416us/step - loss: 0.3456 - predict_loss: 0.0000e+00 - loss_loss: 0.3456 - val_loss: 0.1572 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1572\n",
      "Epoch 584/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.5069 - predict_loss: 0.0000e+00 - loss_loss: 0.5069 - val_loss: 0.1533 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1533\n",
      "Epoch 585/1500\n",
      "204/204 [==============================] - 0s 396us/step - loss: 0.5033 - predict_loss: 0.0000e+00 - loss_loss: 0.5033 - val_loss: 0.2069 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2069\n",
      "Epoch 586/1500\n",
      "204/204 [==============================] - 0s 422us/step - loss: 0.4671 - predict_loss: 0.0000e+00 - loss_loss: 0.4671 - val_loss: 0.1318 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1318\n",
      "Epoch 587/1500\n",
      "204/204 [==============================] - 0s 365us/step - loss: 0.5459 - predict_loss: 0.0000e+00 - loss_loss: 0.5459 - val_loss: 0.1495 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1495\n",
      "Epoch 588/1500\n",
      "204/204 [==============================] - 0s 373us/step - loss: 0.3702 - predict_loss: 0.0000e+00 - loss_loss: 0.3702 - val_loss: 0.1318 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1318\n",
      "Epoch 589/1500\n",
      "204/204 [==============================] - 0s 382us/step - loss: 0.4130 - predict_loss: 0.0000e+00 - loss_loss: 0.4130 - val_loss: 0.1660 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1660\n",
      "Epoch 590/1500\n",
      "204/204 [==============================] - 0s 383us/step - loss: 0.4397 - predict_loss: 0.0000e+00 - loss_loss: 0.4397 - val_loss: 0.1349 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1349\n",
      "Epoch 591/1500\n",
      "204/204 [==============================] - 0s 381us/step - loss: 0.3690 - predict_loss: 0.0000e+00 - loss_loss: 0.3690 - val_loss: 0.1542 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1542\n",
      "Epoch 592/1500\n",
      "204/204 [==============================] - 0s 371us/step - loss: 0.4125 - predict_loss: 0.0000e+00 - loss_loss: 0.4125 - val_loss: 0.1506 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1506\n",
      "Epoch 593/1500\n",
      "204/204 [==============================] - 0s 370us/step - loss: 0.5329 - predict_loss: 0.0000e+00 - loss_loss: 0.5329 - val_loss: 0.1293 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1293\n",
      "Epoch 594/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.4414 - predict_loss: 0.0000e+00 - loss_loss: 0.4414 - val_loss: 0.1319 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1319\n",
      "Epoch 595/1500\n",
      "204/204 [==============================] - 0s 293us/step - loss: 0.3846 - predict_loss: 0.0000e+00 - loss_loss: 0.3846 - val_loss: 0.1286 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1286\n",
      "Epoch 596/1500\n",
      "204/204 [==============================] - 0s 308us/step - loss: 0.4358 - predict_loss: 0.0000e+00 - loss_loss: 0.4358 - val_loss: 0.1088 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1088\n",
      "Epoch 597/1500\n",
      "204/204 [==============================] - 0s 311us/step - loss: 0.5893 - predict_loss: 0.0000e+00 - loss_loss: 0.5893 - val_loss: 0.1739 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1739\n",
      "Epoch 598/1500\n",
      "204/204 [==============================] - 0s 297us/step - loss: 0.4572 - predict_loss: 0.0000e+00 - loss_loss: 0.4572 - val_loss: 0.1988 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1988\n",
      "Epoch 599/1500\n",
      "204/204 [==============================] - 0s 302us/step - loss: 0.3810 - predict_loss: 0.0000e+00 - loss_loss: 0.3810 - val_loss: 0.1453 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1453\n",
      "Epoch 600/1500\n",
      "204/204 [==============================] - 0s 368us/step - loss: 0.4843 - predict_loss: 0.0000e+00 - loss_loss: 0.4843 - val_loss: 0.1502 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1502\n",
      "Epoch 601/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 0.5618 - predict_loss: 0.0000e+00 - loss_loss: 0.5618 - val_loss: 0.1297 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1297\n",
      "Epoch 602/1500\n",
      "204/204 [==============================] - 0s 427us/step - loss: 0.3234 - predict_loss: 0.0000e+00 - loss_loss: 0.3234 - val_loss: 0.1177 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1177\n",
      "Epoch 603/1500\n",
      "204/204 [==============================] - 0s 405us/step - loss: 0.4373 - predict_loss: 0.0000e+00 - loss_loss: 0.4373 - val_loss: 0.1951 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1951\n",
      "Epoch 604/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.5250 - predict_loss: 0.0000e+00 - loss_loss: 0.5250 - val_loss: 0.1415 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1415\n",
      "Epoch 605/1500\n",
      "204/204 [==============================] - 0s 405us/step - loss: 0.5202 - predict_loss: 0.0000e+00 - loss_loss: 0.5202 - val_loss: 0.1384 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1384\n",
      "Epoch 606/1500\n",
      "204/204 [==============================] - 0s 389us/step - loss: 0.4873 - predict_loss: 0.0000e+00 - loss_loss: 0.4873 - val_loss: 0.1429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1429\n",
      "Epoch 607/1500\n",
      "204/204 [==============================] - 0s 370us/step - loss: 0.4417 - predict_loss: 0.0000e+00 - loss_loss: 0.4417 - val_loss: 0.1314 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1314\n",
      "Epoch 608/1500\n",
      "204/204 [==============================] - 0s 402us/step - loss: 0.3712 - predict_loss: 0.0000e+00 - loss_loss: 0.3712 - val_loss: 0.1651 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1651\n",
      "Epoch 609/1500\n",
      "204/204 [==============================] - 0s 353us/step - loss: 0.6886 - predict_loss: 0.0000e+00 - loss_loss: 0.6886 - val_loss: 0.1478 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1478\n",
      "Epoch 610/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.3954 - predict_loss: 0.0000e+00 - loss_loss: 0.3954 - val_loss: 0.2086 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2086\n",
      "Epoch 611/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 403us/step - loss: 0.3424 - predict_loss: 0.0000e+00 - loss_loss: 0.3424 - val_loss: 0.1848 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1848\n",
      "Epoch 612/1500\n",
      "204/204 [==============================] - 0s 428us/step - loss: 0.5007 - predict_loss: 0.0000e+00 - loss_loss: 0.5007 - val_loss: 0.1581 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1581\n",
      "Epoch 613/1500\n",
      "204/204 [==============================] - 0s 502us/step - loss: 0.5523 - predict_loss: 0.0000e+00 - loss_loss: 0.5523 - val_loss: 0.1514 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1514\n",
      "Epoch 614/1500\n",
      "204/204 [==============================] - 0s 374us/step - loss: 0.4064 - predict_loss: 0.0000e+00 - loss_loss: 0.4064 - val_loss: 0.1554 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1554\n",
      "Epoch 615/1500\n",
      "204/204 [==============================] - 0s 352us/step - loss: 0.4969 - predict_loss: 0.0000e+00 - loss_loss: 0.4969 - val_loss: 0.1486 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1486\n",
      "Epoch 616/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.5897 - predict_loss: 0.0000e+00 - loss_loss: 0.5897 - val_loss: 0.2007 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.2007\n",
      "Epoch 617/1500\n",
      "204/204 [==============================] - 0s 380us/step - loss: 0.4843 - predict_loss: 0.0000e+00 - loss_loss: 0.4843 - val_loss: 0.1677 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1677\n",
      "Epoch 618/1500\n",
      "204/204 [==============================] - 0s 443us/step - loss: 0.3610 - predict_loss: 0.0000e+00 - loss_loss: 0.3610 - val_loss: 0.1388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1388\n",
      "Epoch 619/1500\n",
      "204/204 [==============================] - 0s 396us/step - loss: 0.6140 - predict_loss: 0.0000e+00 - loss_loss: 0.6140 - val_loss: 0.1625 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1625\n",
      "Epoch 620/1500\n",
      "204/204 [==============================] - 0s 379us/step - loss: 0.3727 - predict_loss: 0.0000e+00 - loss_loss: 0.3727 - val_loss: 0.1322 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1322\n",
      "Epoch 621/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.5221 - predict_loss: 0.0000e+00 - loss_loss: 0.5221 - val_loss: 0.1396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1396\n",
      "Epoch 622/1500\n",
      "204/204 [==============================] - 0s 372us/step - loss: 0.1235 - predict_loss: 0.0000e+00 - loss_loss: 0.1235 - val_loss: 0.1180 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1180\n",
      "Epoch 623/1500\n",
      "204/204 [==============================] - 0s 361us/step - loss: 0.1355 - predict_loss: 0.0000e+00 - loss_loss: 0.1355 - val_loss: 0.1024 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1024\n",
      "Epoch 624/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.2418 - predict_loss: 0.0000e+00 - loss_loss: 0.2418 - val_loss: 0.1119 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1119\n",
      "Epoch 625/1500\n",
      "204/204 [==============================] - 0s 384us/step - loss: 0.1840 - predict_loss: 0.0000e+00 - loss_loss: 0.1840 - val_loss: 0.1018 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1018\n",
      "Epoch 626/1500\n",
      "204/204 [==============================] - 0s 426us/step - loss: 0.1740 - predict_loss: 0.0000e+00 - loss_loss: 0.1740 - val_loss: 0.1124 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1124\n",
      "Epoch 627/1500\n",
      "204/204 [==============================] - 0s 388us/step - loss: 0.2044 - predict_loss: 0.0000e+00 - loss_loss: 0.2044 - val_loss: 0.1146 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1146\n",
      "Epoch 628/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.1203 - predict_loss: 0.0000e+00 - loss_loss: 0.1203 - val_loss: 0.1001 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1001\n",
      "Epoch 629/1500\n",
      "204/204 [==============================] - 0s 398us/step - loss: 0.2851 - predict_loss: 0.0000e+00 - loss_loss: 0.2851 - val_loss: 0.1510 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1510\n",
      "Epoch 630/1500\n",
      "204/204 [==============================] - 0s 382us/step - loss: 0.1391 - predict_loss: 0.0000e+00 - loss_loss: 0.1391 - val_loss: 0.1372 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1372\n",
      "Epoch 631/1500\n",
      "204/204 [==============================] - 0s 404us/step - loss: 0.2435 - predict_loss: 0.0000e+00 - loss_loss: 0.2435 - val_loss: 0.1031 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1031\n",
      "Epoch 632/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 0.1225 - predict_loss: 0.0000e+00 - loss_loss: 0.1225 - val_loss: 0.0977 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0977\n",
      "Epoch 633/1500\n",
      "204/204 [==============================] - 0s 416us/step - loss: 0.1652 - predict_loss: 0.0000e+00 - loss_loss: 0.1652 - val_loss: 0.0853 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0853\n",
      "Epoch 634/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.2004 - predict_loss: 0.0000e+00 - loss_loss: 0.2004 - val_loss: 0.0890 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0890\n",
      "Epoch 635/1500\n",
      "204/204 [==============================] - 0s 376us/step - loss: 0.1561 - predict_loss: 0.0000e+00 - loss_loss: 0.1561 - val_loss: 0.0919 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0919\n",
      "Epoch 636/1500\n",
      "204/204 [==============================] - 0s 413us/step - loss: 0.2530 - predict_loss: 0.0000e+00 - loss_loss: 0.2530 - val_loss: 0.1064 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1064\n",
      "Epoch 637/1500\n",
      "204/204 [==============================] - 0s 367us/step - loss: 0.1383 - predict_loss: 0.0000e+00 - loss_loss: 0.1383 - val_loss: 0.0888 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0888\n",
      "Epoch 638/1500\n",
      "204/204 [==============================] - 0s 382us/step - loss: 0.1981 - predict_loss: 0.0000e+00 - loss_loss: 0.1981 - val_loss: 0.1388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1388\n",
      "Epoch 639/1500\n",
      "204/204 [==============================] - 0s 399us/step - loss: 0.2147 - predict_loss: 0.0000e+00 - loss_loss: 0.2147 - val_loss: 0.0757 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0757\n",
      "Epoch 640/1500\n",
      "204/204 [==============================] - 0s 344us/step - loss: 0.1234 - predict_loss: 0.0000e+00 - loss_loss: 0.1234 - val_loss: 0.0895 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0895\n",
      "Epoch 641/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.1744 - predict_loss: 0.0000e+00 - loss_loss: 0.1744 - val_loss: 0.0931 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0931\n",
      "Epoch 642/1500\n",
      "204/204 [==============================] - 0s 397us/step - loss: 0.1723 - predict_loss: 0.0000e+00 - loss_loss: 0.1723 - val_loss: 0.1022 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1022\n",
      "Epoch 643/1500\n",
      "204/204 [==============================] - 0s 416us/step - loss: 0.2080 - predict_loss: 0.0000e+00 - loss_loss: 0.2080 - val_loss: 0.0924 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0924\n",
      "Epoch 644/1500\n",
      "204/204 [==============================] - 0s 378us/step - loss: 0.2038 - predict_loss: 0.0000e+00 - loss_loss: 0.2038 - val_loss: 0.0955 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0955\n",
      "Epoch 645/1500\n",
      "204/204 [==============================] - 0s 364us/step - loss: 0.1479 - predict_loss: 0.0000e+00 - loss_loss: 0.1479 - val_loss: 0.0907 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0907\n",
      "Epoch 646/1500\n",
      "204/204 [==============================] - 0s 370us/step - loss: 0.2478 - predict_loss: 0.0000e+00 - loss_loss: 0.2478 - val_loss: 0.0915 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0915\n",
      "Epoch 647/1500\n",
      "204/204 [==============================] - 0s 342us/step - loss: 0.1394 - predict_loss: 0.0000e+00 - loss_loss: 0.1394 - val_loss: 0.0940 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0940\n",
      "Epoch 648/1500\n",
      "204/204 [==============================] - 0s 359us/step - loss: 0.2081 - predict_loss: 0.0000e+00 - loss_loss: 0.2081 - val_loss: 0.1078 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1078\n",
      "Epoch 649/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.2214 - predict_loss: 0.0000e+00 - loss_loss: 0.2214 - val_loss: 0.0918 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0918\n",
      "Epoch 650/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 374us/step - loss: 0.1508 - predict_loss: 0.0000e+00 - loss_loss: 0.1508 - val_loss: 0.1123 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1123\n",
      "Epoch 651/1500\n",
      "204/204 [==============================] - 0s 407us/step - loss: 0.1608 - predict_loss: 0.0000e+00 - loss_loss: 0.1608 - val_loss: 0.0976 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0976\n",
      "Epoch 652/1500\n",
      "204/204 [==============================] - 0s 361us/step - loss: 0.2237 - predict_loss: 0.0000e+00 - loss_loss: 0.2237 - val_loss: 0.0907 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0907\n",
      "Epoch 653/1500\n",
      "204/204 [==============================] - 0s 378us/step - loss: 0.1211 - predict_loss: 0.0000e+00 - loss_loss: 0.1211 - val_loss: 0.1206 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1206\n",
      "Epoch 654/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.1635 - predict_loss: 0.0000e+00 - loss_loss: 0.1635 - val_loss: 0.0803 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0803\n",
      "Epoch 655/1500\n",
      "204/204 [==============================] - 0s 342us/step - loss: 0.2710 - predict_loss: 0.0000e+00 - loss_loss: 0.2710 - val_loss: 0.0877 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0877\n",
      "Epoch 656/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.1127 - predict_loss: 0.0000e+00 - loss_loss: 0.1127 - val_loss: 0.0812 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0812\n",
      "Epoch 657/1500\n",
      "204/204 [==============================] - 0s 379us/step - loss: 0.2430 - predict_loss: 0.0000e+00 - loss_loss: 0.2430 - val_loss: 0.0789 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0789\n",
      "Epoch 658/1500\n",
      "204/204 [==============================] - 0s 356us/step - loss: 0.1295 - predict_loss: 0.0000e+00 - loss_loss: 0.1295 - val_loss: 0.0790 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0790\n",
      "Epoch 659/1500\n",
      "204/204 [==============================] - 0s 437us/step - loss: 0.1550 - predict_loss: 0.0000e+00 - loss_loss: 0.1550 - val_loss: 0.1089 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1089\n",
      "Epoch 660/1500\n",
      "204/204 [==============================] - 0s 389us/step - loss: 0.2711 - predict_loss: 0.0000e+00 - loss_loss: 0.2711 - val_loss: 0.1034 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1034\n",
      "Epoch 661/1500\n",
      "204/204 [==============================] - 0s 334us/step - loss: 0.1694 - predict_loss: 0.0000e+00 - loss_loss: 0.1694 - val_loss: 0.0707 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0707\n",
      "Epoch 662/1500\n",
      "204/204 [==============================] - 0s 354us/step - loss: 0.1769 - predict_loss: 0.0000e+00 - loss_loss: 0.1769 - val_loss: 0.0799 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0799\n",
      "Epoch 663/1500\n",
      "204/204 [==============================] - 0s 395us/step - loss: 0.1857 - predict_loss: 0.0000e+00 - loss_loss: 0.1857 - val_loss: 0.0775 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0775\n",
      "Epoch 664/1500\n",
      "204/204 [==============================] - 0s 371us/step - loss: 0.1316 - predict_loss: 0.0000e+00 - loss_loss: 0.1316 - val_loss: 0.1002 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1002\n",
      "Epoch 665/1500\n",
      "204/204 [==============================] - 0s 398us/step - loss: 0.2417 - predict_loss: 0.0000e+00 - loss_loss: 0.2417 - val_loss: 0.0876 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0876\n",
      "Epoch 666/1500\n",
      "204/204 [==============================] - 0s 394us/step - loss: 0.1572 - predict_loss: 0.0000e+00 - loss_loss: 0.1572 - val_loss: 0.0712 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0712\n",
      "Epoch 667/1500\n",
      "204/204 [==============================] - 0s 399us/step - loss: 0.1164 - predict_loss: 0.0000e+00 - loss_loss: 0.1164 - val_loss: 0.1269 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1269\n",
      "Epoch 668/1500\n",
      "204/204 [==============================] - 0s 334us/step - loss: 0.2662 - predict_loss: 0.0000e+00 - loss_loss: 0.2662 - val_loss: 0.0800 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0800\n",
      "Epoch 669/1500\n",
      "204/204 [==============================] - 0s 314us/step - loss: 0.1694 - predict_loss: 0.0000e+00 - loss_loss: 0.1694 - val_loss: 0.0802 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0802\n",
      "Epoch 670/1500\n",
      "204/204 [==============================] - 0s 297us/step - loss: 0.1456 - predict_loss: 0.0000e+00 - loss_loss: 0.1456 - val_loss: 0.1005 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1005\n",
      "Epoch 671/1500\n",
      "204/204 [==============================] - 0s 302us/step - loss: 0.1954 - predict_loss: 0.0000e+00 - loss_loss: 0.1954 - val_loss: 0.0791 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0791\n",
      "Epoch 672/1500\n",
      "204/204 [==============================] - 0s 314us/step - loss: 0.1211 - predict_loss: 0.0000e+00 - loss_loss: 0.1211 - val_loss: 0.1265 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1265\n",
      "Epoch 673/1500\n",
      "204/204 [==============================] - 0s 322us/step - loss: 0.2389 - predict_loss: 0.0000e+00 - loss_loss: 0.2389 - val_loss: 0.0995 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0995\n",
      "Epoch 674/1500\n",
      "204/204 [==============================] - 0s 317us/step - loss: 0.1659 - predict_loss: 0.0000e+00 - loss_loss: 0.1659 - val_loss: 0.0751 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0751\n",
      "Epoch 675/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.1303 - predict_loss: 0.0000e+00 - loss_loss: 0.1303 - val_loss: 0.1091 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1091\n",
      "Epoch 676/1500\n",
      "204/204 [==============================] - 0s 307us/step - loss: 0.2602 - predict_loss: 0.0000e+00 - loss_loss: 0.2602 - val_loss: 0.0713 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0713\n",
      "Epoch 677/1500\n",
      "204/204 [==============================] - 0s 323us/step - loss: 0.0910 - predict_loss: 0.0000e+00 - loss_loss: 0.0910 - val_loss: 0.0768 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0768\n",
      "Epoch 678/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.2202 - predict_loss: 0.0000e+00 - loss_loss: 0.2202 - val_loss: 0.0796 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0796\n",
      "Epoch 679/1500\n",
      "204/204 [==============================] - 0s 336us/step - loss: 0.1489 - predict_loss: 0.0000e+00 - loss_loss: 0.1489 - val_loss: 0.0736 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0736\n",
      "Epoch 680/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.1895 - predict_loss: 0.0000e+00 - loss_loss: 0.1895 - val_loss: 0.0989 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0989\n",
      "Epoch 681/1500\n",
      "204/204 [==============================] - 0s 338us/step - loss: 0.1672 - predict_loss: 0.0000e+00 - loss_loss: 0.1672 - val_loss: 0.0643 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0643\n",
      "Epoch 682/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.1174 - predict_loss: 0.0000e+00 - loss_loss: 0.1174 - val_loss: 0.0787 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0787\n",
      "Epoch 683/1500\n",
      "204/204 [==============================] - 0s 351us/step - loss: 0.1377 - predict_loss: 0.0000e+00 - loss_loss: 0.1377 - val_loss: 0.1081 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1081\n",
      "Epoch 684/1500\n",
      "204/204 [==============================] - 0s 380us/step - loss: 0.2498 - predict_loss: 0.0000e+00 - loss_loss: 0.2498 - val_loss: 0.0769 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0769\n",
      "Epoch 685/1500\n",
      "204/204 [==============================] - 0s 344us/step - loss: 0.1587 - predict_loss: 0.0000e+00 - loss_loss: 0.1587 - val_loss: 0.0865 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0865\n",
      "Epoch 686/1500\n",
      "204/204 [==============================] - 0s 401us/step - loss: 0.1459 - predict_loss: 0.0000e+00 - loss_loss: 0.1459 - val_loss: 0.0891 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0891\n",
      "Epoch 687/1500\n",
      "204/204 [==============================] - 0s 402us/step - loss: 0.1967 - predict_loss: 0.0000e+00 - loss_loss: 0.1967 - val_loss: 0.0707 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0707\n",
      "Epoch 688/1500\n",
      "204/204 [==============================] - 0s 395us/step - loss: 0.1932 - predict_loss: 0.0000e+00 - loss_loss: 0.1932 - val_loss: 0.0987 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0987\n",
      "Epoch 689/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 374us/step - loss: 0.1146 - predict_loss: 0.0000e+00 - loss_loss: 0.1146 - val_loss: 0.0716 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0716\n",
      "Epoch 690/1500\n",
      "204/204 [==============================] - 0s 340us/step - loss: 0.2755 - predict_loss: 0.0000e+00 - loss_loss: 0.2755 - val_loss: 0.0929 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0929\n",
      "Epoch 691/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.0981 - predict_loss: 0.0000e+00 - loss_loss: 0.0981 - val_loss: 0.0884 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0884\n",
      "Epoch 692/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.2207 - predict_loss: 0.0000e+00 - loss_loss: 0.2207 - val_loss: 0.0916 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0916\n",
      "Epoch 693/1500\n",
      "204/204 [==============================] - 0s 376us/step - loss: 0.1515 - predict_loss: 0.0000e+00 - loss_loss: 0.1515 - val_loss: 0.0862 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0862\n",
      "Epoch 694/1500\n",
      "204/204 [==============================] - 0s 370us/step - loss: 0.1299 - predict_loss: 0.0000e+00 - loss_loss: 0.1299 - val_loss: 0.0758 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0758\n",
      "Epoch 695/1500\n",
      "204/204 [==============================] - 0s 354us/step - loss: 0.2247 - predict_loss: 0.0000e+00 - loss_loss: 0.2247 - val_loss: 0.0740 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0740\n",
      "Epoch 696/1500\n",
      "204/204 [==============================] - 0s 394us/step - loss: 0.1209 - predict_loss: 0.0000e+00 - loss_loss: 0.1209 - val_loss: 0.0786 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0786\n",
      "Epoch 697/1500\n",
      "204/204 [==============================] - 0s 352us/step - loss: 0.2303 - predict_loss: 0.0000e+00 - loss_loss: 0.2303 - val_loss: 0.0801 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0801\n",
      "Epoch 698/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.1233 - predict_loss: 0.0000e+00 - loss_loss: 0.1233 - val_loss: 0.0845 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0845\n",
      "Epoch 699/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.1367 - predict_loss: 0.0000e+00 - loss_loss: 0.1367 - val_loss: 0.0690 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0690\n",
      "Epoch 700/1500\n",
      "204/204 [==============================] - 0s 329us/step - loss: 0.2557 - predict_loss: 0.0000e+00 - loss_loss: 0.2557 - val_loss: 0.0709 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0709\n",
      "Epoch 701/1500\n",
      "204/204 [==============================] - 0s 377us/step - loss: 0.1287 - predict_loss: 0.0000e+00 - loss_loss: 0.1287 - val_loss: 0.0623 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0623\n",
      "Epoch 702/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 0.1784 - predict_loss: 0.0000e+00 - loss_loss: 0.1784 - val_loss: 0.0858 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0858\n",
      "Epoch 703/1500\n",
      "204/204 [==============================] - 0s 409us/step - loss: 0.1892 - predict_loss: 0.0000e+00 - loss_loss: 0.1892 - val_loss: 0.0750 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0750\n",
      "Epoch 704/1500\n",
      "204/204 [==============================] - 0s 364us/step - loss: 0.1387 - predict_loss: 0.0000e+00 - loss_loss: 0.1387 - val_loss: 0.0720 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0720\n",
      "Epoch 705/1500\n",
      "204/204 [==============================] - 0s 348us/step - loss: 0.1797 - predict_loss: 0.0000e+00 - loss_loss: 0.1797 - val_loss: 0.0851 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0851\n",
      "Epoch 706/1500\n",
      "204/204 [==============================] - 0s 407us/step - loss: 0.1659 - predict_loss: 0.0000e+00 - loss_loss: 0.1659 - val_loss: 0.0687 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0687\n",
      "Epoch 707/1500\n",
      "204/204 [==============================] - 0s 394us/step - loss: 0.1321 - predict_loss: 0.0000e+00 - loss_loss: 0.1321 - val_loss: 0.1037 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1037\n",
      "Epoch 708/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 0.1648 - predict_loss: 0.0000e+00 - loss_loss: 0.1648 - val_loss: 0.0747 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0747\n",
      "Epoch 709/1500\n",
      "204/204 [==============================] - 0s 347us/step - loss: 0.1948 - predict_loss: 0.0000e+00 - loss_loss: 0.1948 - val_loss: 0.0846 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0846\n",
      "Epoch 710/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.1862 - predict_loss: 0.0000e+00 - loss_loss: 0.1862 - val_loss: 0.0700 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0700\n",
      "Epoch 711/1500\n",
      "204/204 [==============================] - 0s 366us/step - loss: 0.1354 - predict_loss: 0.0000e+00 - loss_loss: 0.1354 - val_loss: 0.0852 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0852\n",
      "Epoch 712/1500\n",
      "204/204 [==============================] - 0s 358us/step - loss: 0.2129 - predict_loss: 0.0000e+00 - loss_loss: 0.2129 - val_loss: 0.0883 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0883\n",
      "Epoch 713/1500\n",
      "204/204 [==============================] - 0s 292us/step - loss: 0.1539 - predict_loss: 0.0000e+00 - loss_loss: 0.1539 - val_loss: 0.0771 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0771\n",
      "Epoch 714/1500\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.1156 - predict_loss: 0.0000e+00 - loss_loss: 0.1156 - val_loss: 0.0961 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0961\n",
      "Epoch 715/1500\n",
      "204/204 [==============================] - 0s 344us/step - loss: 0.1678 - predict_loss: 0.0000e+00 - loss_loss: 0.1678 - val_loss: 0.0798 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0798\n",
      "Epoch 716/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.1670 - predict_loss: 0.0000e+00 - loss_loss: 0.1670 - val_loss: 0.0753 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0753\n",
      "Epoch 717/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.1880 - predict_loss: 0.0000e+00 - loss_loss: 0.1880 - val_loss: 0.0686 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0686\n",
      "Epoch 718/1500\n",
      "204/204 [==============================] - 0s 366us/step - loss: 0.1035 - predict_loss: 0.0000e+00 - loss_loss: 0.1035 - val_loss: 0.0878 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0878\n",
      "Epoch 719/1500\n",
      "204/204 [==============================] - 0s 444us/step - loss: 0.2596 - predict_loss: 0.0000e+00 - loss_loss: 0.2596 - val_loss: 0.0946 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0946\n",
      "Epoch 720/1500\n",
      "204/204 [==============================] - 0s 298us/step - loss: 0.1010 - predict_loss: 0.0000e+00 - loss_loss: 0.1010 - val_loss: 0.0749 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0749\n",
      "Epoch 721/1500\n",
      "204/204 [==============================] - 0s 301us/step - loss: 0.1914 - predict_loss: 0.0000e+00 - loss_loss: 0.1914 - val_loss: 0.0780 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0780\n",
      "Epoch 722/1500\n",
      "204/204 [==============================] - 0s 295us/step - loss: 0.1574 - predict_loss: 0.0000e+00 - loss_loss: 0.1574 - val_loss: 0.0921 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0921\n",
      "Epoch 723/1500\n",
      "204/204 [==============================] - 0s 301us/step - loss: 0.2130 - predict_loss: 0.0000e+00 - loss_loss: 0.2130 - val_loss: 0.0724 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0724\n",
      "Epoch 724/1500\n",
      "204/204 [==============================] - 0s 354us/step - loss: 0.1749 - predict_loss: 0.0000e+00 - loss_loss: 0.1749 - val_loss: 0.0722 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0722\n",
      "Epoch 725/1500\n",
      "204/204 [==============================] - 0s 391us/step - loss: 0.1003 - predict_loss: 0.0000e+00 - loss_loss: 0.1003 - val_loss: 0.0676 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0676\n",
      "Epoch 726/1500\n",
      "204/204 [==============================] - 0s 377us/step - loss: 0.2339 - predict_loss: 0.0000e+00 - loss_loss: 0.2339 - val_loss: 0.0717 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0717\n",
      "Epoch 727/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.1681 - predict_loss: 0.0000e+00 - loss_loss: 0.1681 - val_loss: 0.0669 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0669\n",
      "Epoch 728/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 359us/step - loss: 0.1506 - predict_loss: 0.0000e+00 - loss_loss: 0.1506 - val_loss: 0.1083 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.1083\n",
      "Epoch 729/1500\n",
      "204/204 [==============================] - 0s 377us/step - loss: 0.0881 - predict_loss: 0.0000e+00 - loss_loss: 0.0881 - val_loss: 0.0596 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0596\n",
      "Epoch 730/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.0758 - predict_loss: 0.0000e+00 - loss_loss: 0.0758 - val_loss: 0.0658 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0658\n",
      "Epoch 731/1500\n",
      "204/204 [==============================] - 0s 370us/step - loss: 0.0873 - predict_loss: 0.0000e+00 - loss_loss: 0.0873 - val_loss: 0.0678 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0678\n",
      "Epoch 732/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.1064 - predict_loss: 0.0000e+00 - loss_loss: 0.1064 - val_loss: 0.0667 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0667\n",
      "Epoch 733/1500\n",
      "204/204 [==============================] - 0s 358us/step - loss: 0.0776 - predict_loss: 0.0000e+00 - loss_loss: 0.0776 - val_loss: 0.0647 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0647\n",
      "Epoch 734/1500\n",
      "204/204 [==============================] - 0s 355us/step - loss: 0.0977 - predict_loss: 0.0000e+00 - loss_loss: 0.0977 - val_loss: 0.0855 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0855\n",
      "Epoch 735/1500\n",
      "204/204 [==============================] - 0s 380us/step - loss: 0.1020 - predict_loss: 0.0000e+00 - loss_loss: 0.1020 - val_loss: 0.0661 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0661\n",
      "Epoch 736/1500\n",
      "204/204 [==============================] - 0s 402us/step - loss: 0.0903 - predict_loss: 0.0000e+00 - loss_loss: 0.0903 - val_loss: 0.0634 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0634\n",
      "Epoch 737/1500\n",
      "204/204 [==============================] - 0s 338us/step - loss: 0.1145 - predict_loss: 0.0000e+00 - loss_loss: 0.1145 - val_loss: 0.0594 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0594\n",
      "Epoch 738/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.0798 - predict_loss: 0.0000e+00 - loss_loss: 0.0798 - val_loss: 0.0919 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0919\n",
      "Epoch 739/1500\n",
      "204/204 [==============================] - 0s 353us/step - loss: 0.0897 - predict_loss: 0.0000e+00 - loss_loss: 0.0897 - val_loss: 0.0831 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0831\n",
      "Epoch 740/1500\n",
      "204/204 [==============================] - 0s 359us/step - loss: 0.0921 - predict_loss: 0.0000e+00 - loss_loss: 0.0921 - val_loss: 0.0694 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0694\n",
      "Epoch 741/1500\n",
      "204/204 [==============================] - 0s 343us/step - loss: 0.0792 - predict_loss: 0.0000e+00 - loss_loss: 0.0792 - val_loss: 0.0609 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0609\n",
      "Epoch 742/1500\n",
      "204/204 [==============================] - 0s 378us/step - loss: 0.0859 - predict_loss: 0.0000e+00 - loss_loss: 0.0859 - val_loss: 0.0734 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0734\n",
      "Epoch 743/1500\n",
      "204/204 [==============================] - 0s 372us/step - loss: 0.0973 - predict_loss: 0.0000e+00 - loss_loss: 0.0973 - val_loss: 0.0558 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0558\n",
      "Epoch 744/1500\n",
      "204/204 [==============================] - 0s 369us/step - loss: 0.0849 - predict_loss: 0.0000e+00 - loss_loss: 0.0849 - val_loss: 0.0665 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0665\n",
      "Epoch 745/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 0.0991 - predict_loss: 0.0000e+00 - loss_loss: 0.0991 - val_loss: 0.0610 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0610\n",
      "Epoch 746/1500\n",
      "204/204 [==============================] - 0s 382us/step - loss: 0.0820 - predict_loss: 0.0000e+00 - loss_loss: 0.0820 - val_loss: 0.0651 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0651\n",
      "Epoch 747/1500\n",
      "204/204 [==============================] - 0s 359us/step - loss: 0.0935 - predict_loss: 0.0000e+00 - loss_loss: 0.0935 - val_loss: 0.0604 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0604\n",
      "Epoch 748/1500\n",
      "204/204 [==============================] - 0s 424us/step - loss: 0.0759 - predict_loss: 0.0000e+00 - loss_loss: 0.0759 - val_loss: 0.0801 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0801\n",
      "Epoch 749/1500\n",
      "204/204 [==============================] - 0s 347us/step - loss: 0.1073 - predict_loss: 0.0000e+00 - loss_loss: 0.1073 - val_loss: 0.0672 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0672\n",
      "Epoch 750/1500\n",
      "204/204 [==============================] - 0s 344us/step - loss: 0.0863 - predict_loss: 0.0000e+00 - loss_loss: 0.0863 - val_loss: 0.0527 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0527\n",
      "Epoch 751/1500\n",
      "204/204 [==============================] - 0s 364us/step - loss: 0.0907 - predict_loss: 0.0000e+00 - loss_loss: 0.0907 - val_loss: 0.0556 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0556\n",
      "Epoch 752/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 0.0647 - predict_loss: 0.0000e+00 - loss_loss: 0.0647 - val_loss: 0.0558 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0558\n",
      "Epoch 753/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.1206 - predict_loss: 0.0000e+00 - loss_loss: 0.1206 - val_loss: 0.0642 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0642\n",
      "Epoch 754/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.0890 - predict_loss: 0.0000e+00 - loss_loss: 0.0890 - val_loss: 0.0588 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0588\n",
      "Epoch 755/1500\n",
      "204/204 [==============================] - 0s 347us/step - loss: 0.0716 - predict_loss: 0.0000e+00 - loss_loss: 0.0716 - val_loss: 0.0628 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0628\n",
      "Epoch 756/1500\n",
      "204/204 [==============================] - 0s 353us/step - loss: 0.0676 - predict_loss: 0.0000e+00 - loss_loss: 0.0676 - val_loss: 0.0592 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0592\n",
      "Epoch 757/1500\n",
      "204/204 [==============================] - 0s 395us/step - loss: 0.1240 - predict_loss: 0.0000e+00 - loss_loss: 0.1240 - val_loss: 0.0665 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0665\n",
      "Epoch 758/1500\n",
      "204/204 [==============================] - 0s 388us/step - loss: 0.0641 - predict_loss: 0.0000e+00 - loss_loss: 0.0641 - val_loss: 0.0565 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0565\n",
      "Epoch 759/1500\n",
      "204/204 [==============================] - 0s 378us/step - loss: 0.0970 - predict_loss: 0.0000e+00 - loss_loss: 0.0970 - val_loss: 0.0548 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0548\n",
      "Epoch 760/1500\n",
      "204/204 [==============================] - 0s 370us/step - loss: 0.0685 - predict_loss: 0.0000e+00 - loss_loss: 0.0685 - val_loss: 0.0545 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0545\n",
      "Epoch 761/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0954 - predict_loss: 0.0000e+00 - loss_loss: 0.0954 - val_loss: 0.0568 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0568\n",
      "Epoch 762/1500\n",
      "204/204 [==============================] - 0s 368us/step - loss: 0.0853 - predict_loss: 0.0000e+00 - loss_loss: 0.0853 - val_loss: 0.0562 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0562\n",
      "Epoch 763/1500\n",
      "204/204 [==============================] - 0s 391us/step - loss: 0.0999 - predict_loss: 0.0000e+00 - loss_loss: 0.0999 - val_loss: 0.0572 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0572\n",
      "Epoch 764/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0672 - predict_loss: 0.0000e+00 - loss_loss: 0.0672 - val_loss: 0.0606 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0606\n",
      "Epoch 765/1500\n",
      "204/204 [==============================] - 0s 291us/step - loss: 0.0884 - predict_loss: 0.0000e+00 - loss_loss: 0.0884 - val_loss: 0.0579 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0579\n",
      "Epoch 766/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0886 - predict_loss: 0.0000e+00 - loss_loss: 0.0886 - val_loss: 0.0557 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0557\n",
      "Epoch 767/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 301us/step - loss: 0.0776 - predict_loss: 0.0000e+00 - loss_loss: 0.0776 - val_loss: 0.0587 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0587\n",
      "Epoch 768/1500\n",
      "204/204 [==============================] - 0s 296us/step - loss: 0.0895 - predict_loss: 0.0000e+00 - loss_loss: 0.0895 - val_loss: 0.0548 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0548\n",
      "Epoch 769/1500\n",
      "204/204 [==============================] - 0s 289us/step - loss: 0.0871 - predict_loss: 0.0000e+00 - loss_loss: 0.0871 - val_loss: 0.0686 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0686\n",
      "Epoch 770/1500\n",
      "204/204 [==============================] - 0s 297us/step - loss: 0.0664 - predict_loss: 0.0000e+00 - loss_loss: 0.0664 - val_loss: 0.0647 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0647\n",
      "Epoch 771/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.0910 - predict_loss: 0.0000e+00 - loss_loss: 0.0910 - val_loss: 0.0646 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0646\n",
      "Epoch 772/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.1157 - predict_loss: 0.0000e+00 - loss_loss: 0.1157 - val_loss: 0.0562 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0562\n",
      "Epoch 773/1500\n",
      "204/204 [==============================] - 0s 296us/step - loss: 0.0713 - predict_loss: 0.0000e+00 - loss_loss: 0.0713 - val_loss: 0.0524 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0524\n",
      "Epoch 774/1500\n",
      "204/204 [==============================] - 0s 298us/step - loss: 0.0868 - predict_loss: 0.0000e+00 - loss_loss: 0.0868 - val_loss: 0.0526 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0526\n",
      "Epoch 775/1500\n",
      "204/204 [==============================] - 0s 294us/step - loss: 0.0845 - predict_loss: 0.0000e+00 - loss_loss: 0.0845 - val_loss: 0.0633 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0633\n",
      "Epoch 776/1500\n",
      "204/204 [==============================] - 0s 309us/step - loss: 0.0962 - predict_loss: 0.0000e+00 - loss_loss: 0.0962 - val_loss: 0.0719 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0719\n",
      "Epoch 777/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.0768 - predict_loss: 0.0000e+00 - loss_loss: 0.0768 - val_loss: 0.0625 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0625\n",
      "Epoch 778/1500\n",
      "204/204 [==============================] - 0s 302us/step - loss: 0.1032 - predict_loss: 0.0000e+00 - loss_loss: 0.1032 - val_loss: 0.0640 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0640\n",
      "Epoch 779/1500\n",
      "204/204 [==============================] - 0s 295us/step - loss: 0.0721 - predict_loss: 0.0000e+00 - loss_loss: 0.0721 - val_loss: 0.0575 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0575\n",
      "Epoch 780/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0761 - predict_loss: 0.0000e+00 - loss_loss: 0.0761 - val_loss: 0.0603 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0603\n",
      "Epoch 781/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.1165 - predict_loss: 0.0000e+00 - loss_loss: 0.1165 - val_loss: 0.0607 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0607\n",
      "Epoch 782/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.0653 - predict_loss: 0.0000e+00 - loss_loss: 0.0653 - val_loss: 0.0582 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0582\n",
      "Epoch 783/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.0959 - predict_loss: 0.0000e+00 - loss_loss: 0.0959 - val_loss: 0.0675 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0675\n",
      "Epoch 784/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.1050 - predict_loss: 0.0000e+00 - loss_loss: 0.1050 - val_loss: 0.0640 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0640\n",
      "Epoch 785/1500\n",
      "204/204 [==============================] - 0s 305us/step - loss: 0.0603 - predict_loss: 0.0000e+00 - loss_loss: 0.0603 - val_loss: 0.0552 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0552\n",
      "Epoch 786/1500\n",
      "204/204 [==============================] - 0s 290us/step - loss: 0.0887 - predict_loss: 0.0000e+00 - loss_loss: 0.0887 - val_loss: 0.0723 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0723\n",
      "Epoch 787/1500\n",
      "204/204 [==============================] - 0s 307us/step - loss: 0.0845 - predict_loss: 0.0000e+00 - loss_loss: 0.0845 - val_loss: 0.0691 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0691\n",
      "Epoch 788/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0804 - predict_loss: 0.0000e+00 - loss_loss: 0.0804 - val_loss: 0.0523 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0523\n",
      "Epoch 789/1500\n",
      "204/204 [==============================] - 0s 302us/step - loss: 0.0826 - predict_loss: 0.0000e+00 - loss_loss: 0.0826 - val_loss: 0.0501 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0501\n",
      "Epoch 790/1500\n",
      "204/204 [==============================] - 0s 293us/step - loss: 0.0973 - predict_loss: 0.0000e+00 - loss_loss: 0.0973 - val_loss: 0.0608 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0608\n",
      "Epoch 791/1500\n",
      "204/204 [==============================] - 0s 295us/step - loss: 0.0860 - predict_loss: 0.0000e+00 - loss_loss: 0.0860 - val_loss: 0.0615 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0615\n",
      "Epoch 792/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.0880 - predict_loss: 0.0000e+00 - loss_loss: 0.0880 - val_loss: 0.0674 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0674\n",
      "Epoch 793/1500\n",
      "204/204 [==============================] - 0s 292us/step - loss: 0.0888 - predict_loss: 0.0000e+00 - loss_loss: 0.0888 - val_loss: 0.0566 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0566\n",
      "Epoch 794/1500\n",
      "204/204 [==============================] - 0s 295us/step - loss: 0.1005 - predict_loss: 0.0000e+00 - loss_loss: 0.1005 - val_loss: 0.0567 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0567\n",
      "Epoch 795/1500\n",
      "204/204 [==============================] - 0s 296us/step - loss: 0.0730 - predict_loss: 0.0000e+00 - loss_loss: 0.0730 - val_loss: 0.0540 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0540\n",
      "Epoch 796/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0665 - predict_loss: 0.0000e+00 - loss_loss: 0.0665 - val_loss: 0.0553 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0553\n",
      "Epoch 797/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.1054 - predict_loss: 0.0000e+00 - loss_loss: 0.1054 - val_loss: 0.0662 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0662\n",
      "Epoch 798/1500\n",
      "204/204 [==============================] - 0s 298us/step - loss: 0.0746 - predict_loss: 0.0000e+00 - loss_loss: 0.0746 - val_loss: 0.0534 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0534\n",
      "Epoch 799/1500\n",
      "204/204 [==============================] - 0s 291us/step - loss: 0.1033 - predict_loss: 0.0000e+00 - loss_loss: 0.1033 - val_loss: 0.0533 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0533\n",
      "Epoch 800/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0692 - predict_loss: 0.0000e+00 - loss_loss: 0.0692 - val_loss: 0.0575 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0575\n",
      "Epoch 801/1500\n",
      "204/204 [==============================] - 0s 290us/step - loss: 0.1009 - predict_loss: 0.0000e+00 - loss_loss: 0.1009 - val_loss: 0.0511 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0511\n",
      "Epoch 802/1500\n",
      "204/204 [==============================] - 0s 295us/step - loss: 0.0853 - predict_loss: 0.0000e+00 - loss_loss: 0.0853 - val_loss: 0.0545 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0545\n",
      "Epoch 803/1500\n",
      "204/204 [==============================] - 0s 301us/step - loss: 0.0709 - predict_loss: 0.0000e+00 - loss_loss: 0.0709 - val_loss: 0.0563 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0563\n",
      "Epoch 804/1500\n",
      "204/204 [==============================] - 0s 293us/step - loss: 0.0632 - predict_loss: 0.0000e+00 - loss_loss: 0.0632 - val_loss: 0.0641 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0641\n",
      "Epoch 805/1500\n",
      "204/204 [==============================] - 0s 291us/step - loss: 0.0948 - predict_loss: 0.0000e+00 - loss_loss: 0.0948 - val_loss: 0.0631 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0631\n",
      "Epoch 806/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 288us/step - loss: 0.1145 - predict_loss: 0.0000e+00 - loss_loss: 0.1145 - val_loss: 0.0567 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0567\n",
      "Epoch 807/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0654 - predict_loss: 0.0000e+00 - loss_loss: 0.0654 - val_loss: 0.0527 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0527\n",
      "Epoch 808/1500\n",
      "204/204 [==============================] - 0s 314us/step - loss: 0.0942 - predict_loss: 0.0000e+00 - loss_loss: 0.0942 - val_loss: 0.0551 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0551\n",
      "Epoch 809/1500\n",
      "204/204 [==============================] - 0s 286us/step - loss: 0.0700 - predict_loss: 0.0000e+00 - loss_loss: 0.0700 - val_loss: 0.0547 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0547\n",
      "Epoch 810/1500\n",
      "204/204 [==============================] - 0s 302us/step - loss: 0.0848 - predict_loss: 0.0000e+00 - loss_loss: 0.0848 - val_loss: 0.0542 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0542\n",
      "Epoch 811/1500\n",
      "204/204 [==============================] - 0s 298us/step - loss: 0.0752 - predict_loss: 0.0000e+00 - loss_loss: 0.0752 - val_loss: 0.0545 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0545\n",
      "Epoch 812/1500\n",
      "204/204 [==============================] - 0s 294us/step - loss: 0.0580 - predict_loss: 0.0000e+00 - loss_loss: 0.0580 - val_loss: 0.0705 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0705\n",
      "Epoch 813/1500\n",
      "204/204 [==============================] - 0s 354us/step - loss: 0.1233 - predict_loss: 0.0000e+00 - loss_loss: 0.1233 - val_loss: 0.0588 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0588\n",
      "Epoch 814/1500\n",
      "204/204 [==============================] - 0s 336us/step - loss: 0.0826 - predict_loss: 0.0000e+00 - loss_loss: 0.0826 - val_loss: 0.0593 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0593\n",
      "Epoch 815/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0826 - predict_loss: 0.0000e+00 - loss_loss: 0.0826 - val_loss: 0.0569 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0569\n",
      "Epoch 816/1500\n",
      "204/204 [==============================] - 0s 343us/step - loss: 0.0963 - predict_loss: 0.0000e+00 - loss_loss: 0.0963 - val_loss: 0.0612 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0612\n",
      "Epoch 817/1500\n",
      "204/204 [==============================] - 0s 368us/step - loss: 0.0746 - predict_loss: 0.0000e+00 - loss_loss: 0.0746 - val_loss: 0.0593 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0593\n",
      "Epoch 818/1500\n",
      "204/204 [==============================] - 0s 344us/step - loss: 0.0832 - predict_loss: 0.0000e+00 - loss_loss: 0.0832 - val_loss: 0.0557 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0557\n",
      "Epoch 819/1500\n",
      "204/204 [==============================] - 0s 357us/step - loss: 0.0796 - predict_loss: 0.0000e+00 - loss_loss: 0.0796 - val_loss: 0.0508 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0508\n",
      "Epoch 820/1500\n",
      "204/204 [==============================] - 0s 422us/step - loss: 0.1018 - predict_loss: 0.0000e+00 - loss_loss: 0.1018 - val_loss: 0.0576 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0576\n",
      "Epoch 821/1500\n",
      "204/204 [==============================] - 0s 373us/step - loss: 0.0564 - predict_loss: 0.0000e+00 - loss_loss: 0.0564 - val_loss: 0.0660 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0660\n",
      "Epoch 822/1500\n",
      "204/204 [==============================] - 0s 404us/step - loss: 0.1203 - predict_loss: 0.0000e+00 - loss_loss: 0.1203 - val_loss: 0.0513 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0513\n",
      "Epoch 823/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0722 - predict_loss: 0.0000e+00 - loss_loss: 0.0722 - val_loss: 0.0501 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0501\n",
      "Epoch 824/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.0909 - predict_loss: 0.0000e+00 - loss_loss: 0.0909 - val_loss: 0.0537 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0537\n",
      "Epoch 825/1500\n",
      "204/204 [==============================] - 0s 328us/step - loss: 0.0772 - predict_loss: 0.0000e+00 - loss_loss: 0.0772 - val_loss: 0.0522 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0522\n",
      "Epoch 826/1500\n",
      "204/204 [==============================] - 0s 348us/step - loss: 0.0662 - predict_loss: 0.0000e+00 - loss_loss: 0.0662 - val_loss: 0.0541 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0541\n",
      "Epoch 827/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 0.1130 - predict_loss: 0.0000e+00 - loss_loss: 0.1130 - val_loss: 0.0555 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0555\n",
      "Epoch 828/1500\n",
      "204/204 [==============================] - 0s 413us/step - loss: 0.0712 - predict_loss: 0.0000e+00 - loss_loss: 0.0712 - val_loss: 0.0494 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0494\n",
      "Epoch 829/1500\n",
      "204/204 [==============================] - 0s 413us/step - loss: 0.0736 - predict_loss: 0.0000e+00 - loss_loss: 0.0736 - val_loss: 0.0488 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0488\n",
      "Epoch 830/1500\n",
      "204/204 [==============================] - 0s 410us/step - loss: 0.0662 - predict_loss: 0.0000e+00 - loss_loss: 0.0662 - val_loss: 0.0549 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0549\n",
      "Epoch 831/1500\n",
      "204/204 [==============================] - 0s 418us/step - loss: 0.1235 - predict_loss: 0.0000e+00 - loss_loss: 0.1235 - val_loss: 0.0548 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0548\n",
      "Epoch 832/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.0686 - predict_loss: 0.0000e+00 - loss_loss: 0.0686 - val_loss: 0.0533 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0533\n",
      "Epoch 833/1500\n",
      "204/204 [==============================] - 0s 343us/step - loss: 0.0968 - predict_loss: 0.0000e+00 - loss_loss: 0.0968 - val_loss: 0.0524 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0524\n",
      "Epoch 834/1500\n",
      "204/204 [==============================] - 0s 310us/step - loss: 0.0725 - predict_loss: 0.0000e+00 - loss_loss: 0.0725 - val_loss: 0.0593 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0593\n",
      "Epoch 835/1500\n",
      "204/204 [==============================] - 0s 336us/step - loss: 0.0896 - predict_loss: 0.0000e+00 - loss_loss: 0.0896 - val_loss: 0.0590 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0590\n",
      "Epoch 836/1500\n",
      "204/204 [==============================] - 0s 409us/step - loss: 0.0789 - predict_loss: 0.0000e+00 - loss_loss: 0.0789 - val_loss: 0.0486 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0486\n",
      "Epoch 837/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.0849 - predict_loss: 0.0000e+00 - loss_loss: 0.0849 - val_loss: 0.0500 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0500\n",
      "Epoch 838/1500\n",
      "204/204 [==============================] - 0s 406us/step - loss: 0.0928 - predict_loss: 0.0000e+00 - loss_loss: 0.0928 - val_loss: 0.0530 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0530\n",
      "Epoch 839/1500\n",
      "204/204 [==============================] - 0s 424us/step - loss: 0.0782 - predict_loss: 0.0000e+00 - loss_loss: 0.0782 - val_loss: 0.0488 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0488\n",
      "Epoch 840/1500\n",
      "204/204 [==============================] - 0s 429us/step - loss: 0.0940 - predict_loss: 0.0000e+00 - loss_loss: 0.0940 - val_loss: 0.0492 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0492\n",
      "Epoch 841/1500\n",
      "204/204 [==============================] - 0s 434us/step - loss: 0.0664 - predict_loss: 0.0000e+00 - loss_loss: 0.0664 - val_loss: 0.0576 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0576\n",
      "Epoch 842/1500\n",
      "204/204 [==============================] - 0s 489us/step - loss: 0.0584 - predict_loss: 0.0000e+00 - loss_loss: 0.0584 - val_loss: 0.0500 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0500\n",
      "Epoch 843/1500\n",
      "204/204 [==============================] - 0s 514us/step - loss: 0.1182 - predict_loss: 0.0000e+00 - loss_loss: 0.1182 - val_loss: 0.0552 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0552\n",
      "Epoch 844/1500\n",
      "204/204 [==============================] - 0s 396us/step - loss: 0.0925 - predict_loss: 0.0000e+00 - loss_loss: 0.0925 - val_loss: 0.0474 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0474\n",
      "Epoch 845/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 353us/step - loss: 0.0681 - predict_loss: 0.0000e+00 - loss_loss: 0.0681 - val_loss: 0.0522 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0522\n",
      "Epoch 846/1500\n",
      "204/204 [==============================] - 0s 366us/step - loss: 0.0677 - predict_loss: 0.0000e+00 - loss_loss: 0.0677 - val_loss: 0.0556 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0556\n",
      "Epoch 847/1500\n",
      "204/204 [==============================] - 0s 413us/step - loss: 0.0926 - predict_loss: 0.0000e+00 - loss_loss: 0.0926 - val_loss: 0.0605 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0605\n",
      "Epoch 848/1500\n",
      "204/204 [==============================] - 0s 419us/step - loss: 0.0691 - predict_loss: 0.0000e+00 - loss_loss: 0.0691 - val_loss: 0.0520 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0520\n",
      "Epoch 849/1500\n",
      "204/204 [==============================] - 0s 367us/step - loss: 0.1001 - predict_loss: 0.0000e+00 - loss_loss: 0.1001 - val_loss: 0.0496 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0496\n",
      "Epoch 850/1500\n",
      "204/204 [==============================] - 0s 455us/step - loss: 0.0601 - predict_loss: 0.0000e+00 - loss_loss: 0.0601 - val_loss: 0.0486 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0486\n",
      "Epoch 851/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 0.1040 - predict_loss: 0.0000e+00 - loss_loss: 0.1040 - val_loss: 0.0548 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0548\n",
      "Epoch 852/1500\n",
      "204/204 [==============================] - 0s 365us/step - loss: 0.0573 - predict_loss: 0.0000e+00 - loss_loss: 0.0573 - val_loss: 0.0503 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0503\n",
      "Epoch 853/1500\n",
      "204/204 [==============================] - 0s 435us/step - loss: 0.0925 - predict_loss: 0.0000e+00 - loss_loss: 0.0925 - val_loss: 0.0518 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0518\n",
      "Epoch 854/1500\n",
      "204/204 [==============================] - 0s 465us/step - loss: 0.0881 - predict_loss: 0.0000e+00 - loss_loss: 0.0881 - val_loss: 0.0468 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0468\n",
      "Epoch 855/1500\n",
      "204/204 [==============================] - 0s 340us/step - loss: 0.0721 - predict_loss: 0.0000e+00 - loss_loss: 0.0721 - val_loss: 0.0669 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0669\n",
      "Epoch 856/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.0626 - predict_loss: 0.0000e+00 - loss_loss: 0.0626 - val_loss: 0.0499 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0499\n",
      "Epoch 857/1500\n",
      "204/204 [==============================] - 0s 410us/step - loss: 0.1091 - predict_loss: 0.0000e+00 - loss_loss: 0.1091 - val_loss: 0.0570 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0570\n",
      "Epoch 858/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.0643 - predict_loss: 0.0000e+00 - loss_loss: 0.0643 - val_loss: 0.0507 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0507\n",
      "Epoch 859/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.0911 - predict_loss: 0.0000e+00 - loss_loss: 0.0911 - val_loss: 0.0576 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0576\n",
      "Epoch 860/1500\n",
      "204/204 [==============================] - 0s 424us/step - loss: 0.0754 - predict_loss: 0.0000e+00 - loss_loss: 0.0754 - val_loss: 0.0571 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0571\n",
      "Epoch 861/1500\n",
      "204/204 [==============================] - 0s 331us/step - loss: 0.0957 - predict_loss: 0.0000e+00 - loss_loss: 0.0957 - val_loss: 0.0647 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0647\n",
      "Epoch 862/1500\n",
      "204/204 [==============================] - 0s 325us/step - loss: 0.0670 - predict_loss: 0.0000e+00 - loss_loss: 0.0670 - val_loss: 0.0538 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0538\n",
      "Epoch 863/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0990 - predict_loss: 0.0000e+00 - loss_loss: 0.0990 - val_loss: 0.0524 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0524\n",
      "Epoch 864/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0737 - predict_loss: 0.0000e+00 - loss_loss: 0.0737 - val_loss: 0.0521 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0521\n",
      "Epoch 865/1500\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.0785 - predict_loss: 0.0000e+00 - loss_loss: 0.0785 - val_loss: 0.0586 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0586\n",
      "Epoch 866/1500\n",
      "204/204 [==============================] - 0s 322us/step - loss: 0.0857 - predict_loss: 0.0000e+00 - loss_loss: 0.0857 - val_loss: 0.0511 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0511\n",
      "Epoch 867/1500\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.0762 - predict_loss: 0.0000e+00 - loss_loss: 0.0762 - val_loss: 0.0521 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0521\n",
      "Epoch 868/1500\n",
      "204/204 [==============================] - 0s 316us/step - loss: 0.1003 - predict_loss: 0.0000e+00 - loss_loss: 0.1003 - val_loss: 0.0589 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0589\n",
      "Epoch 869/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.0646 - predict_loss: 0.0000e+00 - loss_loss: 0.0646 - val_loss: 0.0583 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0583\n",
      "Epoch 870/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0632 - predict_loss: 0.0000e+00 - loss_loss: 0.0632 - val_loss: 0.0564 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0564\n",
      "Epoch 871/1500\n",
      "204/204 [==============================] - 0s 310us/step - loss: 0.0996 - predict_loss: 0.0000e+00 - loss_loss: 0.0996 - val_loss: 0.0532 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0532\n",
      "Epoch 872/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0595 - predict_loss: 0.0000e+00 - loss_loss: 0.0595 - val_loss: 0.0532 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0532\n",
      "Epoch 873/1500\n",
      "204/204 [==============================] - 0s 331us/step - loss: 0.0522 - predict_loss: 0.0000e+00 - loss_loss: 0.0522 - val_loss: 0.0542 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0542\n",
      "Epoch 874/1500\n",
      "204/204 [==============================] - 0s 310us/step - loss: 0.0542 - predict_loss: 0.0000e+00 - loss_loss: 0.0542 - val_loss: 0.0508 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0508\n",
      "Epoch 875/1500\n",
      "204/204 [==============================] - 0s 330us/step - loss: 0.0604 - predict_loss: 0.0000e+00 - loss_loss: 0.0604 - val_loss: 0.0493 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0493\n",
      "Epoch 876/1500\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.0599 - predict_loss: 0.0000e+00 - loss_loss: 0.0599 - val_loss: 0.0492 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0492\n",
      "Epoch 877/1500\n",
      "204/204 [==============================] - 0s 321us/step - loss: 0.0576 - predict_loss: 0.0000e+00 - loss_loss: 0.0576 - val_loss: 0.0522 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0522\n",
      "Epoch 878/1500\n",
      "204/204 [==============================] - 0s 317us/step - loss: 0.0580 - predict_loss: 0.0000e+00 - loss_loss: 0.0580 - val_loss: 0.0513 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0513\n",
      "Epoch 879/1500\n",
      "204/204 [==============================] - 0s 330us/step - loss: 0.0586 - predict_loss: 0.0000e+00 - loss_loss: 0.0586 - val_loss: 0.0473 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0473\n",
      "Epoch 880/1500\n",
      "204/204 [==============================] - 0s 318us/step - loss: 0.0575 - predict_loss: 0.0000e+00 - loss_loss: 0.0575 - val_loss: 0.0471 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0471\n",
      "Epoch 881/1500\n",
      "204/204 [==============================] - 0s 314us/step - loss: 0.0613 - predict_loss: 0.0000e+00 - loss_loss: 0.0613 - val_loss: 0.0521 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0521\n",
      "Epoch 882/1500\n",
      "204/204 [==============================] - 0s 319us/step - loss: 0.0524 - predict_loss: 0.0000e+00 - loss_loss: 0.0524 - val_loss: 0.0529 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0529\n",
      "Epoch 883/1500\n",
      "204/204 [==============================] - 0s 302us/step - loss: 0.0646 - predict_loss: 0.0000e+00 - loss_loss: 0.0646 - val_loss: 0.0518 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0518\n",
      "Epoch 884/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 297us/step - loss: 0.0556 - predict_loss: 0.0000e+00 - loss_loss: 0.0556 - val_loss: 0.0516 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0516\n",
      "Epoch 885/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0558 - predict_loss: 0.0000e+00 - loss_loss: 0.0558 - val_loss: 0.0467 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0467\n",
      "Epoch 886/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0670 - predict_loss: 0.0000e+00 - loss_loss: 0.0670 - val_loss: 0.0556 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0556\n",
      "Epoch 887/1500\n",
      "204/204 [==============================] - 0s 308us/step - loss: 0.0585 - predict_loss: 0.0000e+00 - loss_loss: 0.0585 - val_loss: 0.0522 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0522\n",
      "Epoch 888/1500\n",
      "204/204 [==============================] - 0s 312us/step - loss: 0.0510 - predict_loss: 0.0000e+00 - loss_loss: 0.0510 - val_loss: 0.0481 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0481\n",
      "Epoch 889/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0714 - predict_loss: 0.0000e+00 - loss_loss: 0.0714 - val_loss: 0.0511 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0511\n",
      "Epoch 890/1500\n",
      "204/204 [==============================] - 0s 296us/step - loss: 0.0514 - predict_loss: 0.0000e+00 - loss_loss: 0.0514 - val_loss: 0.0505 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0505\n",
      "Epoch 891/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0604 - predict_loss: 0.0000e+00 - loss_loss: 0.0604 - val_loss: 0.0495 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0495\n",
      "Epoch 892/1500\n",
      "204/204 [==============================] - 0s 307us/step - loss: 0.0562 - predict_loss: 0.0000e+00 - loss_loss: 0.0562 - val_loss: 0.0493 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0493\n",
      "Epoch 893/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.0528 - predict_loss: 0.0000e+00 - loss_loss: 0.0528 - val_loss: 0.0526 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0526\n",
      "Epoch 894/1500\n",
      "204/204 [==============================] - 0s 317us/step - loss: 0.0517 - predict_loss: 0.0000e+00 - loss_loss: 0.0517 - val_loss: 0.0484 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0484\n",
      "Epoch 895/1500\n",
      "204/204 [==============================] - 0s 302us/step - loss: 0.0601 - predict_loss: 0.0000e+00 - loss_loss: 0.0601 - val_loss: 0.0509 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0509\n",
      "Epoch 896/1500\n",
      "204/204 [==============================] - 0s 301us/step - loss: 0.0649 - predict_loss: 0.0000e+00 - loss_loss: 0.0649 - val_loss: 0.0501 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0501\n",
      "Epoch 897/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.0516 - predict_loss: 0.0000e+00 - loss_loss: 0.0516 - val_loss: 0.0465 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0465\n",
      "Epoch 898/1500\n",
      "204/204 [==============================] - 0s 296us/step - loss: 0.0627 - predict_loss: 0.0000e+00 - loss_loss: 0.0627 - val_loss: 0.0476 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0476\n",
      "Epoch 899/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.0499 - predict_loss: 0.0000e+00 - loss_loss: 0.0499 - val_loss: 0.0511 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0511\n",
      "Epoch 900/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.0582 - predict_loss: 0.0000e+00 - loss_loss: 0.0582 - val_loss: 0.0495 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0495\n",
      "Epoch 901/1500\n",
      "204/204 [==============================] - 0s 295us/step - loss: 0.0580 - predict_loss: 0.0000e+00 - loss_loss: 0.0580 - val_loss: 0.0513 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0513\n",
      "Epoch 902/1500\n",
      "204/204 [==============================] - 0s 297us/step - loss: 0.0570 - predict_loss: 0.0000e+00 - loss_loss: 0.0570 - val_loss: 0.0470 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0470\n",
      "Epoch 903/1500\n",
      "204/204 [==============================] - 0s 301us/step - loss: 0.0567 - predict_loss: 0.0000e+00 - loss_loss: 0.0567 - val_loss: 0.0449 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0449\n",
      "Epoch 904/1500\n",
      "204/204 [==============================] - 0s 298us/step - loss: 0.0579 - predict_loss: 0.0000e+00 - loss_loss: 0.0579 - val_loss: 0.0533 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0533\n",
      "Epoch 905/1500\n",
      "204/204 [==============================] - 0s 312us/step - loss: 0.0631 - predict_loss: 0.0000e+00 - loss_loss: 0.0631 - val_loss: 0.0538 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0538\n",
      "Epoch 906/1500\n",
      "204/204 [==============================] - 0s 311us/step - loss: 0.0526 - predict_loss: 0.0000e+00 - loss_loss: 0.0526 - val_loss: 0.0479 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0479\n",
      "Epoch 907/1500\n",
      "204/204 [==============================] - 0s 349us/step - loss: 0.0573 - predict_loss: 0.0000e+00 - loss_loss: 0.0573 - val_loss: 0.0472 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0472\n",
      "Epoch 908/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0614 - predict_loss: 0.0000e+00 - loss_loss: 0.0614 - val_loss: 0.0479 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0479\n",
      "Epoch 909/1500\n",
      "204/204 [==============================] - 0s 383us/step - loss: 0.0525 - predict_loss: 0.0000e+00 - loss_loss: 0.0525 - val_loss: 0.0477 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0477\n",
      "Epoch 910/1500\n",
      "204/204 [==============================] - 0s 355us/step - loss: 0.0540 - predict_loss: 0.0000e+00 - loss_loss: 0.0540 - val_loss: 0.0485 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0485\n",
      "Epoch 911/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.0554 - predict_loss: 0.0000e+00 - loss_loss: 0.0554 - val_loss: 0.0481 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0481\n",
      "Epoch 912/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0503 - predict_loss: 0.0000e+00 - loss_loss: 0.0503 - val_loss: 0.0477 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0477\n",
      "Epoch 913/1500\n",
      "204/204 [==============================] - 0s 365us/step - loss: 0.0613 - predict_loss: 0.0000e+00 - loss_loss: 0.0613 - val_loss: 0.0496 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0496\n",
      "Epoch 914/1500\n",
      "204/204 [==============================] - 0s 433us/step - loss: 0.0578 - predict_loss: 0.0000e+00 - loss_loss: 0.0578 - val_loss: 0.0624 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0624\n",
      "Epoch 915/1500\n",
      "204/204 [==============================] - 0s 394us/step - loss: 0.0586 - predict_loss: 0.0000e+00 - loss_loss: 0.0586 - val_loss: 0.0481 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0481\n",
      "Epoch 916/1500\n",
      "204/204 [==============================] - 0s 380us/step - loss: 0.0519 - predict_loss: 0.0000e+00 - loss_loss: 0.0519 - val_loss: 0.0464 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0464\n",
      "Epoch 917/1500\n",
      "204/204 [==============================] - 0s 358us/step - loss: 0.0604 - predict_loss: 0.0000e+00 - loss_loss: 0.0604 - val_loss: 0.0520 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0520\n",
      "Epoch 918/1500\n",
      "204/204 [==============================] - 0s 392us/step - loss: 0.0520 - predict_loss: 0.0000e+00 - loss_loss: 0.0520 - val_loss: 0.0455 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0455\n",
      "Epoch 919/1500\n",
      "204/204 [==============================] - 0s 361us/step - loss: 0.0645 - predict_loss: 0.0000e+00 - loss_loss: 0.0645 - val_loss: 0.0452 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0452\n",
      "Epoch 920/1500\n",
      "204/204 [==============================] - 0s 295us/step - loss: 0.0566 - predict_loss: 0.0000e+00 - loss_loss: 0.0566 - val_loss: 0.0497 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0497\n",
      "Epoch 921/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.0501 - predict_loss: 0.0000e+00 - loss_loss: 0.0501 - val_loss: 0.0665 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0665\n",
      "Epoch 922/1500\n",
      "204/204 [==============================] - 0s 308us/step - loss: 0.0586 - predict_loss: 0.0000e+00 - loss_loss: 0.0586 - val_loss: 0.0445 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0445\n",
      "Epoch 923/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 325us/step - loss: 0.0595 - predict_loss: 0.0000e+00 - loss_loss: 0.0595 - val_loss: 0.0475 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0475\n",
      "Epoch 924/1500\n",
      "204/204 [==============================] - 0s 392us/step - loss: 0.0578 - predict_loss: 0.0000e+00 - loss_loss: 0.0578 - val_loss: 0.0472 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0472\n",
      "Epoch 925/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.0499 - predict_loss: 0.0000e+00 - loss_loss: 0.0499 - val_loss: 0.0460 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0460\n",
      "Epoch 926/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 0.0560 - predict_loss: 0.0000e+00 - loss_loss: 0.0560 - val_loss: 0.0534 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0534\n",
      "Epoch 927/1500\n",
      "204/204 [==============================] - 0s 419us/step - loss: 0.0562 - predict_loss: 0.0000e+00 - loss_loss: 0.0562 - val_loss: 0.0479 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0479\n",
      "Epoch 928/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.0571 - predict_loss: 0.0000e+00 - loss_loss: 0.0571 - val_loss: 0.0510 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0510\n",
      "Epoch 929/1500\n",
      "204/204 [==============================] - 0s 295us/step - loss: 0.0591 - predict_loss: 0.0000e+00 - loss_loss: 0.0591 - val_loss: 0.0488 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0488\n",
      "Epoch 930/1500\n",
      "204/204 [==============================] - 0s 323us/step - loss: 0.0518 - predict_loss: 0.0000e+00 - loss_loss: 0.0518 - val_loss: 0.0500 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0500\n",
      "Epoch 931/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.0654 - predict_loss: 0.0000e+00 - loss_loss: 0.0654 - val_loss: 0.0487 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0487\n",
      "Epoch 932/1500\n",
      "204/204 [==============================] - 0s 355us/step - loss: 0.0493 - predict_loss: 0.0000e+00 - loss_loss: 0.0493 - val_loss: 0.0454 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0454\n",
      "Epoch 933/1500\n",
      "204/204 [==============================] - 0s 418us/step - loss: 0.0596 - predict_loss: 0.0000e+00 - loss_loss: 0.0596 - val_loss: 0.0490 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0490\n",
      "Epoch 934/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.0534 - predict_loss: 0.0000e+00 - loss_loss: 0.0534 - val_loss: 0.0477 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0477\n",
      "Epoch 935/1500\n",
      "204/204 [==============================] - 0s 324us/step - loss: 0.0531 - predict_loss: 0.0000e+00 - loss_loss: 0.0531 - val_loss: 0.0454 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0454\n",
      "Epoch 936/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0503 - predict_loss: 0.0000e+00 - loss_loss: 0.0503 - val_loss: 0.0444 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0444\n",
      "Epoch 937/1500\n",
      "204/204 [==============================] - 0s 319us/step - loss: 0.0620 - predict_loss: 0.0000e+00 - loss_loss: 0.0620 - val_loss: 0.0482 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0482\n",
      "Epoch 938/1500\n",
      "204/204 [==============================] - 0s 343us/step - loss: 0.0535 - predict_loss: 0.0000e+00 - loss_loss: 0.0535 - val_loss: 0.0483 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0483\n",
      "Epoch 939/1500\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.0571 - predict_loss: 0.0000e+00 - loss_loss: 0.0571 - val_loss: 0.0473 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0473\n",
      "Epoch 940/1500\n",
      "204/204 [==============================] - 0s 305us/step - loss: 0.0593 - predict_loss: 0.0000e+00 - loss_loss: 0.0593 - val_loss: 0.0481 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0481\n",
      "Epoch 941/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.0551 - predict_loss: 0.0000e+00 - loss_loss: 0.0551 - val_loss: 0.0502 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0502\n",
      "Epoch 942/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0556 - predict_loss: 0.0000e+00 - loss_loss: 0.0556 - val_loss: 0.0447 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0447\n",
      "Epoch 943/1500\n",
      "204/204 [==============================] - 0s 308us/step - loss: 0.0477 - predict_loss: 0.0000e+00 - loss_loss: 0.0477 - val_loss: 0.0674 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0674\n",
      "Epoch 944/1500\n",
      "204/204 [==============================] - 0s 346us/step - loss: 0.0649 - predict_loss: 0.0000e+00 - loss_loss: 0.0649 - val_loss: 0.0572 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0572\n",
      "Epoch 945/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.0547 - predict_loss: 0.0000e+00 - loss_loss: 0.0547 - val_loss: 0.0501 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0501\n",
      "Epoch 946/1500\n",
      "204/204 [==============================] - 0s 426us/step - loss: 0.0611 - predict_loss: 0.0000e+00 - loss_loss: 0.0611 - val_loss: 0.0474 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0474\n",
      "Epoch 947/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.0592 - predict_loss: 0.0000e+00 - loss_loss: 0.0592 - val_loss: 0.0467 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0467\n",
      "Epoch 948/1500\n",
      "204/204 [==============================] - 0s 407us/step - loss: 0.0545 - predict_loss: 0.0000e+00 - loss_loss: 0.0545 - val_loss: 0.0466 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0466\n",
      "Epoch 949/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.0458 - predict_loss: 0.0000e+00 - loss_loss: 0.0458 - val_loss: 0.0494 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0494\n",
      "Epoch 950/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.0493 - predict_loss: 0.0000e+00 - loss_loss: 0.0493 - val_loss: 0.0486 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0486\n",
      "Epoch 951/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.0635 - predict_loss: 0.0000e+00 - loss_loss: 0.0635 - val_loss: 0.0458 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0458\n",
      "Epoch 952/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0601 - predict_loss: 0.0000e+00 - loss_loss: 0.0601 - val_loss: 0.0459 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0459\n",
      "Epoch 953/1500\n",
      "204/204 [==============================] - 0s 347us/step - loss: 0.0512 - predict_loss: 0.0000e+00 - loss_loss: 0.0512 - val_loss: 0.0496 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0496\n",
      "Epoch 954/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0604 - predict_loss: 0.0000e+00 - loss_loss: 0.0604 - val_loss: 0.0452 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0452\n",
      "Epoch 955/1500\n",
      "204/204 [==============================] - 0s 349us/step - loss: 0.0506 - predict_loss: 0.0000e+00 - loss_loss: 0.0506 - val_loss: 0.0496 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0496\n",
      "Epoch 956/1500\n",
      "204/204 [==============================] - 0s 464us/step - loss: 0.0577 - predict_loss: 0.0000e+00 - loss_loss: 0.0577 - val_loss: 0.0529 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0529\n",
      "Epoch 957/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 0.0490 - predict_loss: 0.0000e+00 - loss_loss: 0.0490 - val_loss: 0.0562 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0562\n",
      "Epoch 958/1500\n",
      "204/204 [==============================] - 0s 394us/step - loss: 0.0587 - predict_loss: 0.0000e+00 - loss_loss: 0.0587 - val_loss: 0.0473 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0473\n",
      "Epoch 959/1500\n",
      "204/204 [==============================] - 0s 337us/step - loss: 0.0485 - predict_loss: 0.0000e+00 - loss_loss: 0.0485 - val_loss: 0.0461 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0461\n",
      "Epoch 960/1500\n",
      "204/204 [==============================] - 0s 359us/step - loss: 0.0681 - predict_loss: 0.0000e+00 - loss_loss: 0.0681 - val_loss: 0.0472 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0472\n",
      "Epoch 961/1500\n",
      "204/204 [==============================] - 0s 382us/step - loss: 0.0486 - predict_loss: 0.0000e+00 - loss_loss: 0.0486 - val_loss: 0.0515 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0515\n",
      "Epoch 962/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 366us/step - loss: 0.0487 - predict_loss: 0.0000e+00 - loss_loss: 0.0487 - val_loss: 0.0471 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0471\n",
      "Epoch 963/1500\n",
      "204/204 [==============================] - 0s 363us/step - loss: 0.0621 - predict_loss: 0.0000e+00 - loss_loss: 0.0621 - val_loss: 0.0462 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0462\n",
      "Epoch 964/1500\n",
      "204/204 [==============================] - 0s 377us/step - loss: 0.0499 - predict_loss: 0.0000e+00 - loss_loss: 0.0499 - val_loss: 0.0480 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0480\n",
      "Epoch 965/1500\n",
      "204/204 [==============================] - 0s 354us/step - loss: 0.0678 - predict_loss: 0.0000e+00 - loss_loss: 0.0678 - val_loss: 0.0475 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0475\n",
      "Epoch 966/1500\n",
      "204/204 [==============================] - 0s 377us/step - loss: 0.0515 - predict_loss: 0.0000e+00 - loss_loss: 0.0515 - val_loss: 0.0456 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0456\n",
      "Epoch 967/1500\n",
      "204/204 [==============================] - 0s 342us/step - loss: 0.0526 - predict_loss: 0.0000e+00 - loss_loss: 0.0526 - val_loss: 0.0470 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0470\n",
      "Epoch 968/1500\n",
      "204/204 [==============================] - 0s 376us/step - loss: 0.0607 - predict_loss: 0.0000e+00 - loss_loss: 0.0607 - val_loss: 0.0510 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0510\n",
      "Epoch 969/1500\n",
      "204/204 [==============================] - 0s 381us/step - loss: 0.0529 - predict_loss: 0.0000e+00 - loss_loss: 0.0529 - val_loss: 0.0508 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0508\n",
      "Epoch 970/1500\n",
      "204/204 [==============================] - 0s 339us/step - loss: 0.0629 - predict_loss: 0.0000e+00 - loss_loss: 0.0629 - val_loss: 0.0433 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0433\n",
      "Epoch 971/1500\n",
      "204/204 [==============================] - 0s 334us/step - loss: 0.0523 - predict_loss: 0.0000e+00 - loss_loss: 0.0523 - val_loss: 0.0526 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0526\n",
      "Epoch 972/1500\n",
      "204/204 [==============================] - 0s 358us/step - loss: 0.0614 - predict_loss: 0.0000e+00 - loss_loss: 0.0614 - val_loss: 0.0534 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0534\n",
      "Epoch 973/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0496 - predict_loss: 0.0000e+00 - loss_loss: 0.0496 - val_loss: 0.0453 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0453\n",
      "Epoch 974/1500\n",
      "204/204 [==============================] - 0s 329us/step - loss: 0.0508 - predict_loss: 0.0000e+00 - loss_loss: 0.0508 - val_loss: 0.0559 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0559\n",
      "Epoch 975/1500\n",
      "204/204 [==============================] - 0s 327us/step - loss: 0.0528 - predict_loss: 0.0000e+00 - loss_loss: 0.0528 - val_loss: 0.0432 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0432\n",
      "Epoch 976/1500\n",
      "204/204 [==============================] - 0s 321us/step - loss: 0.0640 - predict_loss: 0.0000e+00 - loss_loss: 0.0640 - val_loss: 0.0487 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0487\n",
      "Epoch 977/1500\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.0577 - predict_loss: 0.0000e+00 - loss_loss: 0.0577 - val_loss: 0.0449 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0449\n",
      "Epoch 978/1500\n",
      "204/204 [==============================] - 0s 334us/step - loss: 0.0628 - predict_loss: 0.0000e+00 - loss_loss: 0.0628 - val_loss: 0.0428 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0428\n",
      "Epoch 979/1500\n",
      "204/204 [==============================] - 0s 317us/step - loss: 0.0485 - predict_loss: 0.0000e+00 - loss_loss: 0.0485 - val_loss: 0.0475 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0475\n",
      "Epoch 980/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0561 - predict_loss: 0.0000e+00 - loss_loss: 0.0561 - val_loss: 0.0528 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0528\n",
      "Epoch 981/1500\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.0564 - predict_loss: 0.0000e+00 - loss_loss: 0.0564 - val_loss: 0.0480 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0480\n",
      "Epoch 982/1500\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.0544 - predict_loss: 0.0000e+00 - loss_loss: 0.0544 - val_loss: 0.0461 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0461\n",
      "Epoch 983/1500\n",
      "204/204 [==============================] - 0s 309us/step - loss: 0.0522 - predict_loss: 0.0000e+00 - loss_loss: 0.0522 - val_loss: 0.0464 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0464\n",
      "Epoch 984/1500\n",
      "204/204 [==============================] - 0s 324us/step - loss: 0.0644 - predict_loss: 0.0000e+00 - loss_loss: 0.0644 - val_loss: 0.0466 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0466\n",
      "Epoch 985/1500\n",
      "204/204 [==============================] - 0s 355us/step - loss: 0.0487 - predict_loss: 0.0000e+00 - loss_loss: 0.0487 - val_loss: 0.0467 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0467\n",
      "Epoch 986/1500\n",
      "204/204 [==============================] - 0s 378us/step - loss: 0.0544 - predict_loss: 0.0000e+00 - loss_loss: 0.0544 - val_loss: 0.0492 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0492\n",
      "Epoch 987/1500\n",
      "204/204 [==============================] - 0s 379us/step - loss: 0.0576 - predict_loss: 0.0000e+00 - loss_loss: 0.0576 - val_loss: 0.0518 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0518\n",
      "Epoch 988/1500\n",
      "204/204 [==============================] - 0s 382us/step - loss: 0.0535 - predict_loss: 0.0000e+00 - loss_loss: 0.0535 - val_loss: 0.0433 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0433\n",
      "Epoch 989/1500\n",
      "204/204 [==============================] - 0s 325us/step - loss: 0.0559 - predict_loss: 0.0000e+00 - loss_loss: 0.0559 - val_loss: 0.0425 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0425\n",
      "Epoch 990/1500\n",
      "204/204 [==============================] - 0s 384us/step - loss: 0.0548 - predict_loss: 0.0000e+00 - loss_loss: 0.0548 - val_loss: 0.0449 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0449\n",
      "Epoch 991/1500\n",
      "204/204 [==============================] - 0s 377us/step - loss: 0.0546 - predict_loss: 0.0000e+00 - loss_loss: 0.0546 - val_loss: 0.0445 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0445\n",
      "Epoch 992/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.0547 - predict_loss: 0.0000e+00 - loss_loss: 0.0547 - val_loss: 0.0444 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0444\n",
      "Epoch 993/1500\n",
      "204/204 [==============================] - 0s 572us/step - loss: 0.0527 - predict_loss: 0.0000e+00 - loss_loss: 0.0527 - val_loss: 0.0454 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0454\n",
      "Epoch 994/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 0.0497 - predict_loss: 0.0000e+00 - loss_loss: 0.0497 - val_loss: 0.0466 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0466\n",
      "Epoch 995/1500\n",
      "204/204 [==============================] - 0s 464us/step - loss: 0.0626 - predict_loss: 0.0000e+00 - loss_loss: 0.0626 - val_loss: 0.0491 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0491\n",
      "Epoch 996/1500\n",
      "204/204 [==============================] - 0s 414us/step - loss: 0.0498 - predict_loss: 0.0000e+00 - loss_loss: 0.0498 - val_loss: 0.0468 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0468\n",
      "Epoch 997/1500\n",
      "204/204 [==============================] - 0s 495us/step - loss: 0.0471 - predict_loss: 0.0000e+00 - loss_loss: 0.0471 - val_loss: 0.0444 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0444\n",
      "Epoch 998/1500\n",
      "204/204 [==============================] - 0s 445us/step - loss: 0.0707 - predict_loss: 0.0000e+00 - loss_loss: 0.0707 - val_loss: 0.0456 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0456\n",
      "Epoch 999/1500\n",
      "204/204 [==============================] - 0s 359us/step - loss: 0.0472 - predict_loss: 0.0000e+00 - loss_loss: 0.0472 - val_loss: 0.0441 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0441\n",
      "Epoch 1000/1500\n",
      "204/204 [==============================] - 0s 429us/step - loss: 0.0536 - predict_loss: 0.0000e+00 - loss_loss: 0.0536 - val_loss: 0.0429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0429\n",
      "Epoch 1001/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 420us/step - loss: 0.0472 - predict_loss: 0.0000e+00 - loss_loss: 0.0472 - val_loss: 0.0435 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0435\n",
      "Epoch 1002/1500\n",
      "204/204 [==============================] - 0s 438us/step - loss: 0.0459 - predict_loss: 0.0000e+00 - loss_loss: 0.0459 - val_loss: 0.0442 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0442\n",
      "Epoch 1003/1500\n",
      "204/204 [==============================] - 0s 511us/step - loss: 0.0476 - predict_loss: 0.0000e+00 - loss_loss: 0.0476 - val_loss: 0.0449 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0449\n",
      "Epoch 1004/1500\n",
      "204/204 [==============================] - 0s 388us/step - loss: 0.0517 - predict_loss: 0.0000e+00 - loss_loss: 0.0517 - val_loss: 0.0491 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0491\n",
      "Epoch 1005/1500\n",
      "204/204 [==============================] - 0s 481us/step - loss: 0.0475 - predict_loss: 0.0000e+00 - loss_loss: 0.0475 - val_loss: 0.0452 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0452\n",
      "Epoch 1006/1500\n",
      "204/204 [==============================] - 0s 443us/step - loss: 0.0456 - predict_loss: 0.0000e+00 - loss_loss: 0.0456 - val_loss: 0.0429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0429\n",
      "Epoch 1007/1500\n",
      "204/204 [==============================] - 0s 321us/step - loss: 0.0463 - predict_loss: 0.0000e+00 - loss_loss: 0.0463 - val_loss: 0.0424 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0424\n",
      "Epoch 1008/1500\n",
      "204/204 [==============================] - 0s 568us/step - loss: 0.0487 - predict_loss: 0.0000e+00 - loss_loss: 0.0487 - val_loss: 0.0459 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0459\n",
      "Epoch 1009/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0494 - predict_loss: 0.0000e+00 - loss_loss: 0.0494 - val_loss: 0.0455 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0455\n",
      "Epoch 1010/1500\n",
      "204/204 [==============================] - 0s 343us/step - loss: 0.0501 - predict_loss: 0.0000e+00 - loss_loss: 0.0501 - val_loss: 0.0464 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0464\n",
      "Epoch 1011/1500\n",
      "204/204 [==============================] - 0s 301us/step - loss: 0.0461 - predict_loss: 0.0000e+00 - loss_loss: 0.0461 - val_loss: 0.0439 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0439\n",
      "Epoch 1012/1500\n",
      "204/204 [==============================] - 0s 319us/step - loss: 0.0501 - predict_loss: 0.0000e+00 - loss_loss: 0.0501 - val_loss: 0.0449 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0449\n",
      "Epoch 1013/1500\n",
      "204/204 [==============================] - 0s 314us/step - loss: 0.0478 - predict_loss: 0.0000e+00 - loss_loss: 0.0478 - val_loss: 0.0431 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0431\n",
      "Epoch 1014/1500\n",
      "204/204 [==============================] - 0s 370us/step - loss: 0.0462 - predict_loss: 0.0000e+00 - loss_loss: 0.0462 - val_loss: 0.0488 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0488\n",
      "Epoch 1015/1500\n",
      "204/204 [==============================] - 0s 348us/step - loss: 0.0497 - predict_loss: 0.0000e+00 - loss_loss: 0.0497 - val_loss: 0.0435 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0435\n",
      "Epoch 1016/1500\n",
      "204/204 [==============================] - 0s 426us/step - loss: 0.0449 - predict_loss: 0.0000e+00 - loss_loss: 0.0449 - val_loss: 0.0435 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0435\n",
      "Epoch 1017/1500\n",
      "204/204 [==============================] - 0s 658us/step - loss: 0.0470 - predict_loss: 0.0000e+00 - loss_loss: 0.0470 - val_loss: 0.0443 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0443\n",
      "Epoch 1018/1500\n",
      "204/204 [==============================] - 0s 657us/step - loss: 0.0447 - predict_loss: 0.0000e+00 - loss_loss: 0.0447 - val_loss: 0.0464 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0464\n",
      "Epoch 1019/1500\n",
      "204/204 [==============================] - 0s 568us/step - loss: 0.0496 - predict_loss: 0.0000e+00 - loss_loss: 0.0496 - val_loss: 0.0469 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0469\n",
      "Epoch 1020/1500\n",
      "204/204 [==============================] - 0s 435us/step - loss: 0.0479 - predict_loss: 0.0000e+00 - loss_loss: 0.0479 - val_loss: 0.0448 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0448\n",
      "Epoch 1021/1500\n",
      "204/204 [==============================] - 0s 447us/step - loss: 0.0477 - predict_loss: 0.0000e+00 - loss_loss: 0.0477 - val_loss: 0.0441 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0441\n",
      "Epoch 1022/1500\n",
      "204/204 [==============================] - 0s 425us/step - loss: 0.0466 - predict_loss: 0.0000e+00 - loss_loss: 0.0466 - val_loss: 0.0443 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0443\n",
      "Epoch 1023/1500\n",
      "204/204 [==============================] - 0s 514us/step - loss: 0.0473 - predict_loss: 0.0000e+00 - loss_loss: 0.0473 - val_loss: 0.0470 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0470\n",
      "Epoch 1024/1500\n",
      "204/204 [==============================] - 0s 512us/step - loss: 0.0486 - predict_loss: 0.0000e+00 - loss_loss: 0.0486 - val_loss: 0.0444 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0444\n",
      "Epoch 1025/1500\n",
      "204/204 [==============================] - 0s 507us/step - loss: 0.0481 - predict_loss: 0.0000e+00 - loss_loss: 0.0481 - val_loss: 0.0440 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0440\n",
      "Epoch 1026/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 0.0466 - predict_loss: 0.0000e+00 - loss_loss: 0.0466 - val_loss: 0.0524 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0524\n",
      "Epoch 1027/1500\n",
      "204/204 [==============================] - 0s 396us/step - loss: 0.0469 - predict_loss: 0.0000e+00 - loss_loss: 0.0469 - val_loss: 0.0493 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0493\n",
      "Epoch 1028/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0482 - predict_loss: 0.0000e+00 - loss_loss: 0.0482 - val_loss: 0.0429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0429\n",
      "Epoch 1029/1500\n",
      "204/204 [==============================] - 0s 417us/step - loss: 0.0463 - predict_loss: 0.0000e+00 - loss_loss: 0.0463 - val_loss: 0.0436 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0436\n",
      "Epoch 1030/1500\n",
      "204/204 [==============================] - 0s 409us/step - loss: 0.0470 - predict_loss: 0.0000e+00 - loss_loss: 0.0470 - val_loss: 0.0434 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0434\n",
      "Epoch 1031/1500\n",
      "204/204 [==============================] - 0s 432us/step - loss: 0.0482 - predict_loss: 0.0000e+00 - loss_loss: 0.0482 - val_loss: 0.0450 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0450\n",
      "Epoch 1032/1500\n",
      "204/204 [==============================] - 0s 449us/step - loss: 0.0464 - predict_loss: 0.0000e+00 - loss_loss: 0.0464 - val_loss: 0.0443 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0443\n",
      "Epoch 1033/1500\n",
      "204/204 [==============================] - 0s 293us/step - loss: 0.0475 - predict_loss: 0.0000e+00 - loss_loss: 0.0475 - val_loss: 0.0442 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0442\n",
      "Epoch 1034/1500\n",
      "204/204 [==============================] - 0s 319us/step - loss: 0.0460 - predict_loss: 0.0000e+00 - loss_loss: 0.0460 - val_loss: 0.0421 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0421\n",
      "Epoch 1035/1500\n",
      "204/204 [==============================] - 0s 426us/step - loss: 0.0497 - predict_loss: 0.0000e+00 - loss_loss: 0.0497 - val_loss: 0.0432 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0432\n",
      "Epoch 1036/1500\n",
      "204/204 [==============================] - 0s 503us/step - loss: 0.0472 - predict_loss: 0.0000e+00 - loss_loss: 0.0472 - val_loss: 0.0437 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0437\n",
      "Epoch 1037/1500\n",
      "204/204 [==============================] - 0s 517us/step - loss: 0.0448 - predict_loss: 0.0000e+00 - loss_loss: 0.0448 - val_loss: 0.0439 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0439\n",
      "Epoch 1038/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.0496 - predict_loss: 0.0000e+00 - loss_loss: 0.0496 - val_loss: 0.0437 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0437\n",
      "Epoch 1039/1500\n",
      "204/204 [==============================] - 0s 584us/step - loss: 0.0480 - predict_loss: 0.0000e+00 - loss_loss: 0.0480 - val_loss: 0.0429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0429\n",
      "Epoch 1040/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 503us/step - loss: 0.0472 - predict_loss: 0.0000e+00 - loss_loss: 0.0472 - val_loss: 0.0448 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0448\n",
      "Epoch 1041/1500\n",
      "204/204 [==============================] - 0s 314us/step - loss: 0.0461 - predict_loss: 0.0000e+00 - loss_loss: 0.0461 - val_loss: 0.0455 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0455\n",
      "Epoch 1042/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0462 - predict_loss: 0.0000e+00 - loss_loss: 0.0462 - val_loss: 0.0454 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0454\n",
      "Epoch 1043/1500\n",
      "204/204 [==============================] - 0s 322us/step - loss: 0.0427 - predict_loss: 0.0000e+00 - loss_loss: 0.0427 - val_loss: 0.0456 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0456\n",
      "Epoch 1044/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0480 - predict_loss: 0.0000e+00 - loss_loss: 0.0480 - val_loss: 0.0464 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0464\n",
      "Epoch 1045/1500\n",
      "204/204 [==============================] - 0s 307us/step - loss: 0.0460 - predict_loss: 0.0000e+00 - loss_loss: 0.0460 - val_loss: 0.0438 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0438\n",
      "Epoch 1046/1500\n",
      "204/204 [==============================] - 0s 308us/step - loss: 0.0468 - predict_loss: 0.0000e+00 - loss_loss: 0.0468 - val_loss: 0.0443 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0443\n",
      "Epoch 1047/1500\n",
      "204/204 [==============================] - 0s 336us/step - loss: 0.0472 - predict_loss: 0.0000e+00 - loss_loss: 0.0472 - val_loss: 0.0449 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0449\n",
      "Epoch 1048/1500\n",
      "204/204 [==============================] - 0s 331us/step - loss: 0.0468 - predict_loss: 0.0000e+00 - loss_loss: 0.0468 - val_loss: 0.0438 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0438\n",
      "Epoch 1049/1500\n",
      "204/204 [==============================] - 0s 348us/step - loss: 0.0467 - predict_loss: 0.0000e+00 - loss_loss: 0.0467 - val_loss: 0.0422 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0422\n",
      "Epoch 1050/1500\n",
      "204/204 [==============================] - 0s 353us/step - loss: 0.0473 - predict_loss: 0.0000e+00 - loss_loss: 0.0473 - val_loss: 0.0491 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0491\n",
      "Epoch 1051/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.0475 - predict_loss: 0.0000e+00 - loss_loss: 0.0475 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1052/1500\n",
      "204/204 [==============================] - 0s 322us/step - loss: 0.0503 - predict_loss: 0.0000e+00 - loss_loss: 0.0503 - val_loss: 0.0440 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0440\n",
      "Epoch 1053/1500\n",
      "204/204 [==============================] - 0s 318us/step - loss: 0.0465 - predict_loss: 0.0000e+00 - loss_loss: 0.0465 - val_loss: 0.0437 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0437\n",
      "Epoch 1054/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.0468 - predict_loss: 0.0000e+00 - loss_loss: 0.0468 - val_loss: 0.0422 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0422\n",
      "Epoch 1055/1500\n",
      "204/204 [==============================] - 0s 327us/step - loss: 0.0501 - predict_loss: 0.0000e+00 - loss_loss: 0.0501 - val_loss: 0.0447 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0447\n",
      "Epoch 1056/1500\n",
      "204/204 [==============================] - 0s 343us/step - loss: 0.0482 - predict_loss: 0.0000e+00 - loss_loss: 0.0482 - val_loss: 0.0497 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0497\n",
      "Epoch 1057/1500\n",
      "204/204 [==============================] - 0s 319us/step - loss: 0.0467 - predict_loss: 0.0000e+00 - loss_loss: 0.0467 - val_loss: 0.0438 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0438\n",
      "Epoch 1058/1500\n",
      "204/204 [==============================] - 0s 308us/step - loss: 0.0463 - predict_loss: 0.0000e+00 - loss_loss: 0.0463 - val_loss: 0.0442 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0442\n",
      "Epoch 1059/1500\n",
      "204/204 [==============================] - 0s 422us/step - loss: 0.0490 - predict_loss: 0.0000e+00 - loss_loss: 0.0490 - val_loss: 0.0432 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0432\n",
      "Epoch 1060/1500\n",
      "204/204 [==============================] - 0s 371us/step - loss: 0.0468 - predict_loss: 0.0000e+00 - loss_loss: 0.0468 - val_loss: 0.0436 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0436\n",
      "Epoch 1061/1500\n",
      "204/204 [==============================] - 0s 298us/step - loss: 0.0449 - predict_loss: 0.0000e+00 - loss_loss: 0.0449 - val_loss: 0.0443 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0443\n",
      "Epoch 1062/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.0500 - predict_loss: 0.0000e+00 - loss_loss: 0.0500 - val_loss: 0.0434 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0434\n",
      "Epoch 1063/1500\n",
      "204/204 [==============================] - 0s 323us/step - loss: 0.0438 - predict_loss: 0.0000e+00 - loss_loss: 0.0438 - val_loss: 0.0445 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0445\n",
      "Epoch 1064/1500\n",
      "204/204 [==============================] - 0s 301us/step - loss: 0.0446 - predict_loss: 0.0000e+00 - loss_loss: 0.0446 - val_loss: 0.0459 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0459\n",
      "Epoch 1065/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.0479 - predict_loss: 0.0000e+00 - loss_loss: 0.0479 - val_loss: 0.0427 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0427\n",
      "Epoch 1066/1500\n",
      "204/204 [==============================] - 0s 298us/step - loss: 0.0467 - predict_loss: 0.0000e+00 - loss_loss: 0.0467 - val_loss: 0.0439 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0439\n",
      "Epoch 1067/1500\n",
      "204/204 [==============================] - 0s 307us/step - loss: 0.0449 - predict_loss: 0.0000e+00 - loss_loss: 0.0449 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1068/1500\n",
      "204/204 [==============================] - 0s 420us/step - loss: 0.0445 - predict_loss: 0.0000e+00 - loss_loss: 0.0445 - val_loss: 0.0443 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0443\n",
      "Epoch 1069/1500\n",
      "204/204 [==============================] - 0s 520us/step - loss: 0.0466 - predict_loss: 0.0000e+00 - loss_loss: 0.0466 - val_loss: 0.0429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0429\n",
      "Epoch 1070/1500\n",
      "204/204 [==============================] - 0s 517us/step - loss: 0.0457 - predict_loss: 0.0000e+00 - loss_loss: 0.0457 - val_loss: 0.0428 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0428\n",
      "Epoch 1071/1500\n",
      "204/204 [==============================] - 0s 516us/step - loss: 0.0486 - predict_loss: 0.0000e+00 - loss_loss: 0.0486 - val_loss: 0.0421 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0421\n",
      "Epoch 1072/1500\n",
      "204/204 [==============================] - 0s 459us/step - loss: 0.0449 - predict_loss: 0.0000e+00 - loss_loss: 0.0449 - val_loss: 0.0431 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0431\n",
      "Epoch 1073/1500\n",
      "204/204 [==============================] - 0s 401us/step - loss: 0.0451 - predict_loss: 0.0000e+00 - loss_loss: 0.0451 - val_loss: 0.0438 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0438\n",
      "Epoch 1074/1500\n",
      "204/204 [==============================] - 0s 367us/step - loss: 0.0494 - predict_loss: 0.0000e+00 - loss_loss: 0.0494 - val_loss: 0.0447 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0447\n",
      "Epoch 1075/1500\n",
      "204/204 [==============================] - 0s 413us/step - loss: 0.0482 - predict_loss: 0.0000e+00 - loss_loss: 0.0482 - val_loss: 0.0422 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0422\n",
      "Epoch 1076/1500\n",
      "204/204 [==============================] - 0s 366us/step - loss: 0.0459 - predict_loss: 0.0000e+00 - loss_loss: 0.0459 - val_loss: 0.0436 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0436\n",
      "Epoch 1077/1500\n",
      "204/204 [==============================] - 0s 305us/step - loss: 0.0458 - predict_loss: 0.0000e+00 - loss_loss: 0.0458 - val_loss: 0.0426 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0426\n",
      "Epoch 1078/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0473 - predict_loss: 0.0000e+00 - loss_loss: 0.0473 - val_loss: 0.0435 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0435\n",
      "Epoch 1079/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 368us/step - loss: 0.0450 - predict_loss: 0.0000e+00 - loss_loss: 0.0450 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1080/1500\n",
      "204/204 [==============================] - 0s 352us/step - loss: 0.0464 - predict_loss: 0.0000e+00 - loss_loss: 0.0464 - val_loss: 0.0454 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0454\n",
      "Epoch 1081/1500\n",
      "204/204 [==============================] - 0s 395us/step - loss: 0.0465 - predict_loss: 0.0000e+00 - loss_loss: 0.0465 - val_loss: 0.0422 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0422\n",
      "Epoch 1082/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0445 - predict_loss: 0.0000e+00 - loss_loss: 0.0445 - val_loss: 0.0441 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0441\n",
      "Epoch 1083/1500\n",
      "204/204 [==============================] - 0s 395us/step - loss: 0.0477 - predict_loss: 0.0000e+00 - loss_loss: 0.0477 - val_loss: 0.0438 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0438\n",
      "Epoch 1084/1500\n",
      "204/204 [==============================] - 0s 538us/step - loss: 0.0471 - predict_loss: 0.0000e+00 - loss_loss: 0.0471 - val_loss: 0.0442 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0442\n",
      "Epoch 1085/1500\n",
      "204/204 [==============================] - 0s 495us/step - loss: 0.0448 - predict_loss: 0.0000e+00 - loss_loss: 0.0448 - val_loss: 0.0460 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0460\n",
      "Epoch 1086/1500\n",
      "204/204 [==============================] - 0s 435us/step - loss: 0.0419 - predict_loss: 0.0000e+00 - loss_loss: 0.0419 - val_loss: 0.0426 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0426\n",
      "Epoch 1087/1500\n",
      "204/204 [==============================] - 0s 411us/step - loss: 0.0502 - predict_loss: 0.0000e+00 - loss_loss: 0.0502 - val_loss: 0.0437 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0437\n",
      "Epoch 1088/1500\n",
      "204/204 [==============================] - 0s 316us/step - loss: 0.0443 - predict_loss: 0.0000e+00 - loss_loss: 0.0443 - val_loss: 0.0457 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0457\n",
      "Epoch 1089/1500\n",
      "204/204 [==============================] - 0s 358us/step - loss: 0.0462 - predict_loss: 0.0000e+00 - loss_loss: 0.0462 - val_loss: 0.0440 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0440\n",
      "Epoch 1090/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.0448 - predict_loss: 0.0000e+00 - loss_loss: 0.0448 - val_loss: 0.0441 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0441\n",
      "Epoch 1091/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0466 - predict_loss: 0.0000e+00 - loss_loss: 0.0466 - val_loss: 0.0427 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0427\n",
      "Epoch 1092/1500\n",
      "204/204 [==============================] - 0s 296us/step - loss: 0.0475 - predict_loss: 0.0000e+00 - loss_loss: 0.0475 - val_loss: 0.0454 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0454\n",
      "Epoch 1093/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0446 - predict_loss: 0.0000e+00 - loss_loss: 0.0446 - val_loss: 0.0417 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0417\n",
      "Epoch 1094/1500\n",
      "204/204 [==============================] - 0s 317us/step - loss: 0.0472 - predict_loss: 0.0000e+00 - loss_loss: 0.0472 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1095/1500\n",
      "204/204 [==============================] - 0s 337us/step - loss: 0.0420 - predict_loss: 0.0000e+00 - loss_loss: 0.0420 - val_loss: 0.0415 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0415\n",
      "Epoch 1096/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.0470 - predict_loss: 0.0000e+00 - loss_loss: 0.0470 - val_loss: 0.0423 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0423\n",
      "Epoch 1097/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 0.0441 - predict_loss: 0.0000e+00 - loss_loss: 0.0441 - val_loss: 0.0418 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0418\n",
      "Epoch 1098/1500\n",
      "204/204 [==============================] - 0s 420us/step - loss: 0.0467 - predict_loss: 0.0000e+00 - loss_loss: 0.0467 - val_loss: 0.0438 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0438\n",
      "Epoch 1099/1500\n",
      "204/204 [==============================] - 0s 388us/step - loss: 0.0455 - predict_loss: 0.0000e+00 - loss_loss: 0.0455 - val_loss: 0.0428 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0428\n",
      "Epoch 1100/1500\n",
      "204/204 [==============================] - 0s 399us/step - loss: 0.0470 - predict_loss: 0.0000e+00 - loss_loss: 0.0470 - val_loss: 0.0436 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0436\n",
      "Epoch 1101/1500\n",
      "204/204 [==============================] - 0s 397us/step - loss: 0.0446 - predict_loss: 0.0000e+00 - loss_loss: 0.0446 - val_loss: 0.0417 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0417\n",
      "Epoch 1102/1500\n",
      "204/204 [==============================] - 0s 654us/step - loss: 0.0427 - predict_loss: 0.0000e+00 - loss_loss: 0.0427 - val_loss: 0.0436 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0436\n",
      "Epoch 1103/1500\n",
      "204/204 [==============================] - 0s 849us/step - loss: 0.0480 - predict_loss: 0.0000e+00 - loss_loss: 0.0480 - val_loss: 0.0415 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0415\n",
      "Epoch 1104/1500\n",
      "204/204 [==============================] - 0s 418us/step - loss: 0.0485 - predict_loss: 0.0000e+00 - loss_loss: 0.0485 - val_loss: 0.0416 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0416\n",
      "Epoch 1105/1500\n",
      "204/204 [==============================] - 0s 494us/step - loss: 0.0459 - predict_loss: 0.0000e+00 - loss_loss: 0.0459 - val_loss: 0.0418 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0418\n",
      "Epoch 1106/1500\n",
      "204/204 [==============================] - 0s 504us/step - loss: 0.0424 - predict_loss: 0.0000e+00 - loss_loss: 0.0424 - val_loss: 0.0460 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0460\n",
      "Epoch 1107/1500\n",
      "204/204 [==============================] - 0s 420us/step - loss: 0.0436 - predict_loss: 0.0000e+00 - loss_loss: 0.0436 - val_loss: 0.0455 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0455\n",
      "Epoch 1108/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 0.0470 - predict_loss: 0.0000e+00 - loss_loss: 0.0470 - val_loss: 0.0410 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0410\n",
      "Epoch 1109/1500\n",
      "204/204 [==============================] - 0s 356us/step - loss: 0.0421 - predict_loss: 0.0000e+00 - loss_loss: 0.0421 - val_loss: 0.0436 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0436\n",
      "Epoch 1110/1500\n",
      "204/204 [==============================] - 0s 373us/step - loss: 0.0512 - predict_loss: 0.0000e+00 - loss_loss: 0.0512 - val_loss: 0.0418 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0418\n",
      "Epoch 1111/1500\n",
      "204/204 [==============================] - 0s 462us/step - loss: 0.0457 - predict_loss: 0.0000e+00 - loss_loss: 0.0457 - val_loss: 0.0423 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0423\n",
      "Epoch 1112/1500\n",
      "204/204 [==============================] - 0s 342us/step - loss: 0.0437 - predict_loss: 0.0000e+00 - loss_loss: 0.0437 - val_loss: 0.0423 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0423\n",
      "Epoch 1113/1500\n",
      "204/204 [==============================] - 0s 348us/step - loss: 0.0443 - predict_loss: 0.0000e+00 - loss_loss: 0.0443 - val_loss: 0.0465 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0465\n",
      "Epoch 1114/1500\n",
      "204/204 [==============================] - 0s 411us/step - loss: 0.0440 - predict_loss: 0.0000e+00 - loss_loss: 0.0440 - val_loss: 0.0437 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0437\n",
      "Epoch 1115/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0491 - predict_loss: 0.0000e+00 - loss_loss: 0.0491 - val_loss: 0.0424 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0424\n",
      "Epoch 1116/1500\n",
      "204/204 [==============================] - 0s 409us/step - loss: 0.0458 - predict_loss: 0.0000e+00 - loss_loss: 0.0458 - val_loss: 0.0428 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0428\n",
      "Epoch 1117/1500\n",
      "204/204 [==============================] - 0s 350us/step - loss: 0.0461 - predict_loss: 0.0000e+00 - loss_loss: 0.0461 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1118/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 346us/step - loss: 0.0438 - predict_loss: 0.0000e+00 - loss_loss: 0.0438 - val_loss: 0.0415 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0415\n",
      "Epoch 1119/1500\n",
      "204/204 [==============================] - 0s 372us/step - loss: 0.0472 - predict_loss: 0.0000e+00 - loss_loss: 0.0472 - val_loss: 0.0414 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0414\n",
      "Epoch 1120/1500\n",
      "204/204 [==============================] - 0s 363us/step - loss: 0.0426 - predict_loss: 0.0000e+00 - loss_loss: 0.0426 - val_loss: 0.0434 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0434\n",
      "Epoch 1121/1500\n",
      "204/204 [==============================] - 0s 416us/step - loss: 0.0459 - predict_loss: 0.0000e+00 - loss_loss: 0.0459 - val_loss: 0.0419 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0419\n",
      "Epoch 1122/1500\n",
      "204/204 [==============================] - 0s 504us/step - loss: 0.0496 - predict_loss: 0.0000e+00 - loss_loss: 0.0496 - val_loss: 0.0410 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0410\n",
      "Epoch 1123/1500\n",
      "204/204 [==============================] - 0s 492us/step - loss: 0.0453 - predict_loss: 0.0000e+00 - loss_loss: 0.0453 - val_loss: 0.0423 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0423\n",
      "Epoch 1124/1500\n",
      "204/204 [==============================] - 0s 342us/step - loss: 0.0418 - predict_loss: 0.0000e+00 - loss_loss: 0.0418 - val_loss: 0.0442 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0442\n",
      "Epoch 1125/1500\n",
      "204/204 [==============================] - 0s 416us/step - loss: 0.0434 - predict_loss: 0.0000e+00 - loss_loss: 0.0434 - val_loss: 0.0412 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0412\n",
      "Epoch 1126/1500\n",
      "204/204 [==============================] - 0s 401us/step - loss: 0.0422 - predict_loss: 0.0000e+00 - loss_loss: 0.0422 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1127/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.0456 - predict_loss: 0.0000e+00 - loss_loss: 0.0456 - val_loss: 0.0422 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0422\n",
      "Epoch 1128/1500\n",
      "204/204 [==============================] - 0s 433us/step - loss: 0.0461 - predict_loss: 0.0000e+00 - loss_loss: 0.0461 - val_loss: 0.0435 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0435\n",
      "Epoch 1129/1500\n",
      "204/204 [==============================] - 0s 542us/step - loss: 0.0476 - predict_loss: 0.0000e+00 - loss_loss: 0.0476 - val_loss: 0.0432 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0432\n",
      "Epoch 1130/1500\n",
      "204/204 [==============================] - 0s 510us/step - loss: 0.0428 - predict_loss: 0.0000e+00 - loss_loss: 0.0428 - val_loss: 0.0431 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0431\n",
      "Epoch 1131/1500\n",
      "204/204 [==============================] - 0s 322us/step - loss: 0.0421 - predict_loss: 0.0000e+00 - loss_loss: 0.0421 - val_loss: 0.0429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0429\n",
      "Epoch 1132/1500\n",
      "204/204 [==============================] - 0s 560us/step - loss: 0.0473 - predict_loss: 0.0000e+00 - loss_loss: 0.0473 - val_loss: 0.0414 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0414\n",
      "Epoch 1133/1500\n",
      "204/204 [==============================] - 0s 777us/step - loss: 0.0449 - predict_loss: 0.0000e+00 - loss_loss: 0.0449 - val_loss: 0.0413 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0413\n",
      "Epoch 1134/1500\n",
      "204/204 [==============================] - 0s 680us/step - loss: 0.0429 - predict_loss: 0.0000e+00 - loss_loss: 0.0429 - val_loss: 0.0463 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0463\n",
      "Epoch 1135/1500\n",
      "204/204 [==============================] - 0s 646us/step - loss: 0.0508 - predict_loss: 0.0000e+00 - loss_loss: 0.0508 - val_loss: 0.0413 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0413\n",
      "Epoch 1136/1500\n",
      "204/204 [==============================] - 0s 810us/step - loss: 0.0419 - predict_loss: 0.0000e+00 - loss_loss: 0.0419 - val_loss: 0.0431 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0431\n",
      "Epoch 1137/1500\n",
      "204/204 [==============================] - 0s 775us/step - loss: 0.0443 - predict_loss: 0.0000e+00 - loss_loss: 0.0443 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1138/1500\n",
      "204/204 [==============================] - 0s 740us/step - loss: 0.0470 - predict_loss: 0.0000e+00 - loss_loss: 0.0470 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1139/1500\n",
      "204/204 [==============================] - 0s 768us/step - loss: 0.0469 - predict_loss: 0.0000e+00 - loss_loss: 0.0469 - val_loss: 0.0433 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0433\n",
      "Epoch 1140/1500\n",
      "204/204 [==============================] - 0s 742us/step - loss: 0.0451 - predict_loss: 0.0000e+00 - loss_loss: 0.0451 - val_loss: 0.0407 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0407\n",
      "Epoch 1141/1500\n",
      "204/204 [==============================] - 0s 989us/step - loss: 0.0434 - predict_loss: 0.0000e+00 - loss_loss: 0.0434 - val_loss: 0.0413 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0413\n",
      "Epoch 1142/1500\n",
      "204/204 [==============================] - 0s 800us/step - loss: 0.0474 - predict_loss: 0.0000e+00 - loss_loss: 0.0474 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1143/1500\n",
      "204/204 [==============================] - 0s 944us/step - loss: 0.0440 - predict_loss: 0.0000e+00 - loss_loss: 0.0440 - val_loss: 0.0432 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0432\n",
      "Epoch 1144/1500\n",
      "204/204 [==============================] - 0s 758us/step - loss: 0.0491 - predict_loss: 0.0000e+00 - loss_loss: 0.0491 - val_loss: 0.0446 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0446\n",
      "Epoch 1145/1500\n",
      "204/204 [==============================] - 0s 555us/step - loss: 0.0435 - predict_loss: 0.0000e+00 - loss_loss: 0.0435 - val_loss: 0.0441 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0441\n",
      "Epoch 1146/1500\n",
      "204/204 [==============================] - 0s 489us/step - loss: 0.0439 - predict_loss: 0.0000e+00 - loss_loss: 0.0439 - val_loss: 0.0410 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0410\n",
      "Epoch 1147/1500\n",
      "204/204 [==============================] - 0s 442us/step - loss: 0.0455 - predict_loss: 0.0000e+00 - loss_loss: 0.0455 - val_loss: 0.0444 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0444\n",
      "Epoch 1148/1500\n",
      "204/204 [==============================] - 0s 630us/step - loss: 0.0424 - predict_loss: 0.0000e+00 - loss_loss: 0.0424 - val_loss: 0.0425 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0425\n",
      "Epoch 1149/1500\n",
      "204/204 [==============================] - 0s 552us/step - loss: 0.0428 - predict_loss: 0.0000e+00 - loss_loss: 0.0428 - val_loss: 0.0440 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0440\n",
      "Epoch 1150/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.0426 - predict_loss: 0.0000e+00 - loss_loss: 0.0426 - val_loss: 0.0423 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0423\n",
      "Epoch 1151/1500\n",
      "204/204 [==============================] - 0s 422us/step - loss: 0.0472 - predict_loss: 0.0000e+00 - loss_loss: 0.0472 - val_loss: 0.0435 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0435\n",
      "Epoch 1152/1500\n",
      "204/204 [==============================] - 0s 332us/step - loss: 0.0439 - predict_loss: 0.0000e+00 - loss_loss: 0.0439 - val_loss: 0.0424 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0424\n",
      "Epoch 1153/1500\n",
      "204/204 [==============================] - 0s 332us/step - loss: 0.0427 - predict_loss: 0.0000e+00 - loss_loss: 0.0427 - val_loss: 0.0418 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0418\n",
      "Epoch 1154/1500\n",
      "204/204 [==============================] - 0s 332us/step - loss: 0.0464 - predict_loss: 0.0000e+00 - loss_loss: 0.0464 - val_loss: 0.0418 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0418\n",
      "Epoch 1155/1500\n",
      "204/204 [==============================] - 0s 352us/step - loss: 0.0452 - predict_loss: 0.0000e+00 - loss_loss: 0.0452 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1156/1500\n",
      "204/204 [==============================] - 0s 404us/step - loss: 0.0430 - predict_loss: 0.0000e+00 - loss_loss: 0.0430 - val_loss: 0.0437 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0437\n",
      "Epoch 1157/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 362us/step - loss: 0.0422 - predict_loss: 0.0000e+00 - loss_loss: 0.0422 - val_loss: 0.0453 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0453\n",
      "Epoch 1158/1500\n",
      "204/204 [==============================] - 0s 446us/step - loss: 0.0466 - predict_loss: 0.0000e+00 - loss_loss: 0.0466 - val_loss: 0.0406 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0406\n",
      "Epoch 1159/1500\n",
      "204/204 [==============================] - 0s 410us/step - loss: 0.0429 - predict_loss: 0.0000e+00 - loss_loss: 0.0429 - val_loss: 0.0411 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0411\n",
      "Epoch 1160/1500\n",
      "204/204 [==============================] - 0s 443us/step - loss: 0.0438 - predict_loss: 0.0000e+00 - loss_loss: 0.0438 - val_loss: 0.0411 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0411\n",
      "Epoch 1161/1500\n",
      "204/204 [==============================] - 0s 437us/step - loss: 0.0475 - predict_loss: 0.0000e+00 - loss_loss: 0.0475 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1162/1500\n",
      "204/204 [==============================] - 0s 467us/step - loss: 0.0448 - predict_loss: 0.0000e+00 - loss_loss: 0.0448 - val_loss: 0.0428 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0428\n",
      "Epoch 1163/1500\n",
      "204/204 [==============================] - 0s 437us/step - loss: 0.0442 - predict_loss: 0.0000e+00 - loss_loss: 0.0442 - val_loss: 0.0406 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0406\n",
      "Epoch 1164/1500\n",
      "204/204 [==============================] - 0s 601us/step - loss: 0.0443 - predict_loss: 0.0000e+00 - loss_loss: 0.0443 - val_loss: 0.0416 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0416\n",
      "Epoch 1165/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.0437 - predict_loss: 0.0000e+00 - loss_loss: 0.0437 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1166/1500\n",
      "204/204 [==============================] - 0s 463us/step - loss: 0.0438 - predict_loss: 0.0000e+00 - loss_loss: 0.0438 - val_loss: 0.0415 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0415\n",
      "Epoch 1167/1500\n",
      "204/204 [==============================] - 0s 469us/step - loss: 0.0450 - predict_loss: 0.0000e+00 - loss_loss: 0.0450 - val_loss: 0.0422 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0422\n",
      "Epoch 1168/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.0454 - predict_loss: 0.0000e+00 - loss_loss: 0.0454 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1169/1500\n",
      "204/204 [==============================] - 0s 406us/step - loss: 0.0436 - predict_loss: 0.0000e+00 - loss_loss: 0.0436 - val_loss: 0.0434 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0434\n",
      "Epoch 1170/1500\n",
      "204/204 [==============================] - 0s 391us/step - loss: 0.0444 - predict_loss: 0.0000e+00 - loss_loss: 0.0444 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1171/1500\n",
      "204/204 [==============================] - 0s 339us/step - loss: 0.0460 - predict_loss: 0.0000e+00 - loss_loss: 0.0460 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1172/1500\n",
      "204/204 [==============================] - 0s 326us/step - loss: 0.0448 - predict_loss: 0.0000e+00 - loss_loss: 0.0448 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1173/1500\n",
      "204/204 [==============================] - 0s 323us/step - loss: 0.0445 - predict_loss: 0.0000e+00 - loss_loss: 0.0445 - val_loss: 0.0428 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0428\n",
      "Epoch 1174/1500\n",
      "204/204 [==============================] - 0s 398us/step - loss: 0.0423 - predict_loss: 0.0000e+00 - loss_loss: 0.0423 - val_loss: 0.0451 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0451\n",
      "Epoch 1175/1500\n",
      "204/204 [==============================] - 0s 476us/step - loss: 0.0467 - predict_loss: 0.0000e+00 - loss_loss: 0.0467 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1176/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.0419 - predict_loss: 0.0000e+00 - loss_loss: 0.0419 - val_loss: 0.0405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0405\n",
      "Epoch 1177/1500\n",
      "204/204 [==============================] - 0s 476us/step - loss: 0.0409 - predict_loss: 0.0000e+00 - loss_loss: 0.0409 - val_loss: 0.0414 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0414\n",
      "Epoch 1178/1500\n",
      "204/204 [==============================] - 0s 352us/step - loss: 0.0419 - predict_loss: 0.0000e+00 - loss_loss: 0.0419 - val_loss: 0.0406 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0406\n",
      "Epoch 1179/1500\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.0418 - predict_loss: 0.0000e+00 - loss_loss: 0.0418 - val_loss: 0.0456 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0456\n",
      "Epoch 1180/1500\n",
      "204/204 [==============================] - 0s 337us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0410 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0410\n",
      "Epoch 1181/1500\n",
      "204/204 [==============================] - 0s 334us/step - loss: 0.0423 - predict_loss: 0.0000e+00 - loss_loss: 0.0423 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1182/1500\n",
      "204/204 [==============================] - 0s 323us/step - loss: 0.0424 - predict_loss: 0.0000e+00 - loss_loss: 0.0424 - val_loss: 0.0430 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0430\n",
      "Epoch 1183/1500\n",
      "204/204 [==============================] - 0s 336us/step - loss: 0.0418 - predict_loss: 0.0000e+00 - loss_loss: 0.0418 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1184/1500\n",
      "204/204 [==============================] - 0s 314us/step - loss: 0.0429 - predict_loss: 0.0000e+00 - loss_loss: 0.0429 - val_loss: 0.0406 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0406\n",
      "Epoch 1185/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0415 - predict_loss: 0.0000e+00 - loss_loss: 0.0415 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1186/1500\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.0423 - predict_loss: 0.0000e+00 - loss_loss: 0.0423 - val_loss: 0.0406 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0406\n",
      "Epoch 1187/1500\n",
      "204/204 [==============================] - 0s 326us/step - loss: 0.0414 - predict_loss: 0.0000e+00 - loss_loss: 0.0414 - val_loss: 0.0441 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0441\n",
      "Epoch 1188/1500\n",
      "204/204 [==============================] - 0s 328us/step - loss: 0.0410 - predict_loss: 0.0000e+00 - loss_loss: 0.0410 - val_loss: 0.0416 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0416\n",
      "Epoch 1189/1500\n",
      "204/204 [==============================] - 0s 318us/step - loss: 0.0433 - predict_loss: 0.0000e+00 - loss_loss: 0.0433 - val_loss: 0.0404 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0404\n",
      "Epoch 1190/1500\n",
      "204/204 [==============================] - 0s 322us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0397 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0397\n",
      "Epoch 1191/1500\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.0414 - predict_loss: 0.0000e+00 - loss_loss: 0.0414 - val_loss: 0.0403 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0403\n",
      "Epoch 1192/1500\n",
      "204/204 [==============================] - 0s 468us/step - loss: 0.0423 - predict_loss: 0.0000e+00 - loss_loss: 0.0423 - val_loss: 0.0407 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0407\n",
      "Epoch 1193/1500\n",
      "204/204 [==============================] - 0s 484us/step - loss: 0.0440 - predict_loss: 0.0000e+00 - loss_loss: 0.0440 - val_loss: 0.0418 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0418\n",
      "Epoch 1194/1500\n",
      "204/204 [==============================] - 0s 383us/step - loss: 0.0422 - predict_loss: 0.0000e+00 - loss_loss: 0.0422 - val_loss: 0.0407 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0407\n",
      "Epoch 1195/1500\n",
      "204/204 [==============================] - 0s 376us/step - loss: 0.0440 - predict_loss: 0.0000e+00 - loss_loss: 0.0440 - val_loss: 0.0411 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0411\n",
      "Epoch 1196/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 344us/step - loss: 0.0407 - predict_loss: 0.0000e+00 - loss_loss: 0.0407 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1197/1500\n",
      "204/204 [==============================] - 0s 417us/step - loss: 0.0434 - predict_loss: 0.0000e+00 - loss_loss: 0.0434 - val_loss: 0.0407 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0407\n",
      "Epoch 1198/1500\n",
      "204/204 [==============================] - 0s 331us/step - loss: 0.0419 - predict_loss: 0.0000e+00 - loss_loss: 0.0419 - val_loss: 0.0433 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0433\n",
      "Epoch 1199/1500\n",
      "204/204 [==============================] - 0s 316us/step - loss: 0.0418 - predict_loss: 0.0000e+00 - loss_loss: 0.0418 - val_loss: 0.0405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0405\n",
      "Epoch 1200/1500\n",
      "204/204 [==============================] - 0s 332us/step - loss: 0.0417 - predict_loss: 0.0000e+00 - loss_loss: 0.0417 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1201/1500\n",
      "204/204 [==============================] - 0s 353us/step - loss: 0.0426 - predict_loss: 0.0000e+00 - loss_loss: 0.0426 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1202/1500\n",
      "204/204 [==============================] - 0s 428us/step - loss: 0.0421 - predict_loss: 0.0000e+00 - loss_loss: 0.0421 - val_loss: 0.0418 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0418\n",
      "Epoch 1203/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.0424 - predict_loss: 0.0000e+00 - loss_loss: 0.0424 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1204/1500\n",
      "204/204 [==============================] - 0s 361us/step - loss: 0.0430 - predict_loss: 0.0000e+00 - loss_loss: 0.0430 - val_loss: 0.0411 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0411\n",
      "Epoch 1205/1500\n",
      "204/204 [==============================] - 0s 382us/step - loss: 0.0410 - predict_loss: 0.0000e+00 - loss_loss: 0.0410 - val_loss: 0.0405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0405\n",
      "Epoch 1206/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0406 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0406\n",
      "Epoch 1207/1500\n",
      "204/204 [==============================] - 0s 442us/step - loss: 0.0427 - predict_loss: 0.0000e+00 - loss_loss: 0.0427 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1208/1500\n",
      "204/204 [==============================] - 0s 422us/step - loss: 0.0406 - predict_loss: 0.0000e+00 - loss_loss: 0.0406 - val_loss: 0.0431 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0431\n",
      "Epoch 1209/1500\n",
      "204/204 [==============================] - 0s 405us/step - loss: 0.0425 - predict_loss: 0.0000e+00 - loss_loss: 0.0425 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1210/1500\n",
      "204/204 [==============================] - 0s 399us/step - loss: 0.0422 - predict_loss: 0.0000e+00 - loss_loss: 0.0422 - val_loss: 0.0404 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0404\n",
      "Epoch 1211/1500\n",
      "204/204 [==============================] - 0s 421us/step - loss: 0.0421 - predict_loss: 0.0000e+00 - loss_loss: 0.0421 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1212/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 0.0435 - predict_loss: 0.0000e+00 - loss_loss: 0.0435 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1213/1500\n",
      "204/204 [==============================] - 0s 431us/step - loss: 0.0408 - predict_loss: 0.0000e+00 - loss_loss: 0.0408 - val_loss: 0.0421 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0421\n",
      "Epoch 1214/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0412 - predict_loss: 0.0000e+00 - loss_loss: 0.0412 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1215/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0398 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0398\n",
      "Epoch 1216/1500\n",
      "204/204 [==============================] - 0s 425us/step - loss: 0.0430 - predict_loss: 0.0000e+00 - loss_loss: 0.0430 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1217/1500\n",
      "204/204 [==============================] - 0s 398us/step - loss: 0.0406 - predict_loss: 0.0000e+00 - loss_loss: 0.0406 - val_loss: 0.0407 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0407\n",
      "Epoch 1218/1500\n",
      "204/204 [==============================] - 0s 388us/step - loss: 0.0407 - predict_loss: 0.0000e+00 - loss_loss: 0.0407 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1219/1500\n",
      "204/204 [==============================] - 0s 321us/step - loss: 0.0416 - predict_loss: 0.0000e+00 - loss_loss: 0.0416 - val_loss: 0.0418 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0418\n",
      "Epoch 1220/1500\n",
      "204/204 [==============================] - 0s 316us/step - loss: 0.0423 - predict_loss: 0.0000e+00 - loss_loss: 0.0423 - val_loss: 0.0407 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0407\n",
      "Epoch 1221/1500\n",
      "204/204 [==============================] - 0s 382us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0402 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0402\n",
      "Epoch 1222/1500\n",
      "204/204 [==============================] - 0s 368us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1223/1500\n",
      "204/204 [==============================] - 0s 351us/step - loss: 0.0418 - predict_loss: 0.0000e+00 - loss_loss: 0.0418 - val_loss: 0.0406 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0406\n",
      "Epoch 1224/1500\n",
      "204/204 [==============================] - 0s 372us/step - loss: 0.0420 - predict_loss: 0.0000e+00 - loss_loss: 0.0420 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1225/1500\n",
      "204/204 [==============================] - 0s 361us/step - loss: 0.0425 - predict_loss: 0.0000e+00 - loss_loss: 0.0425 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1226/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 0.0386 - predict_loss: 0.0000e+00 - loss_loss: 0.0386 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1227/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 0.0426 - predict_loss: 0.0000e+00 - loss_loss: 0.0426 - val_loss: 0.0397 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0397\n",
      "Epoch 1228/1500\n",
      "204/204 [==============================] - 0s 321us/step - loss: 0.0417 - predict_loss: 0.0000e+00 - loss_loss: 0.0417 - val_loss: 0.0421 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0421\n",
      "Epoch 1229/1500\n",
      "204/204 [==============================] - 0s 293us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1230/1500\n",
      "204/204 [==============================] - 0s 309us/step - loss: 0.0421 - predict_loss: 0.0000e+00 - loss_loss: 0.0421 - val_loss: 0.0404 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0404\n",
      "Epoch 1231/1500\n",
      "204/204 [==============================] - 0s 392us/step - loss: 0.0389 - predict_loss: 0.0000e+00 - loss_loss: 0.0389 - val_loss: 0.0420 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0420\n",
      "Epoch 1232/1500\n",
      "204/204 [==============================] - 0s 297us/step - loss: 0.0409 - predict_loss: 0.0000e+00 - loss_loss: 0.0409 - val_loss: 0.0409 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0409\n",
      "Epoch 1233/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.0402 - predict_loss: 0.0000e+00 - loss_loss: 0.0402 - val_loss: 0.0403 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0403\n",
      "Epoch 1234/1500\n",
      "204/204 [==============================] - 0s 296us/step - loss: 0.0413 - predict_loss: 0.0000e+00 - loss_loss: 0.0413 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1235/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 295us/step - loss: 0.0421 - predict_loss: 0.0000e+00 - loss_loss: 0.0421 - val_loss: 0.0402 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0402\n",
      "Epoch 1236/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0421 - predict_loss: 0.0000e+00 - loss_loss: 0.0421 - val_loss: 0.0429 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0429\n",
      "Epoch 1237/1500\n",
      "204/204 [==============================] - 0s 420us/step - loss: 0.0417 - predict_loss: 0.0000e+00 - loss_loss: 0.0417 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1238/1500\n",
      "204/204 [==============================] - 0s 378us/step - loss: 0.0432 - predict_loss: 0.0000e+00 - loss_loss: 0.0432 - val_loss: 0.0404 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0404\n",
      "Epoch 1239/1500\n",
      "204/204 [==============================] - 0s 389us/step - loss: 0.0389 - predict_loss: 0.0000e+00 - loss_loss: 0.0389 - val_loss: 0.0398 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0398\n",
      "Epoch 1240/1500\n",
      "204/204 [==============================] - 0s 523us/step - loss: 0.0412 - predict_loss: 0.0000e+00 - loss_loss: 0.0412 - val_loss: 0.0424 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0424\n",
      "Epoch 1241/1500\n",
      "204/204 [==============================] - 0s 365us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0407 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0407\n",
      "Epoch 1242/1500\n",
      "204/204 [==============================] - 0s 314us/step - loss: 0.0411 - predict_loss: 0.0000e+00 - loss_loss: 0.0411 - val_loss: 0.0431 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0431\n",
      "Epoch 1243/1500\n",
      "204/204 [==============================] - 0s 388us/step - loss: 0.0423 - predict_loss: 0.0000e+00 - loss_loss: 0.0423 - val_loss: 0.0415 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0415\n",
      "Epoch 1244/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 0.0417 - predict_loss: 0.0000e+00 - loss_loss: 0.0417 - val_loss: 0.0400 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0400\n",
      "Epoch 1245/1500\n",
      "204/204 [==============================] - 0s 356us/step - loss: 0.0416 - predict_loss: 0.0000e+00 - loss_loss: 0.0416 - val_loss: 0.0411 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0411\n",
      "Epoch 1246/1500\n",
      "204/204 [==============================] - 0s 409us/step - loss: 0.0408 - predict_loss: 0.0000e+00 - loss_loss: 0.0408 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1247/1500\n",
      "204/204 [==============================] - 0s 406us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1248/1500\n",
      "204/204 [==============================] - 0s 346us/step - loss: 0.0411 - predict_loss: 0.0000e+00 - loss_loss: 0.0411 - val_loss: 0.0403 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0403\n",
      "Epoch 1249/1500\n",
      "204/204 [==============================] - 0s 421us/step - loss: 0.0414 - predict_loss: 0.0000e+00 - loss_loss: 0.0414 - val_loss: 0.0403 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0403\n",
      "Epoch 1250/1500\n",
      "204/204 [==============================] - 0s 379us/step - loss: 0.0417 - predict_loss: 0.0000e+00 - loss_loss: 0.0417 - val_loss: 0.0400 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0400\n",
      "Epoch 1251/1500\n",
      "204/204 [==============================] - 0s 338us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0395 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0395\n",
      "Epoch 1252/1500\n",
      "204/204 [==============================] - 0s 319us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0414 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0414\n",
      "Epoch 1253/1500\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.0421 - predict_loss: 0.0000e+00 - loss_loss: 0.0421 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1254/1500\n",
      "204/204 [==============================] - 0s 307us/step - loss: 0.0408 - predict_loss: 0.0000e+00 - loss_loss: 0.0408 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1255/1500\n",
      "204/204 [==============================] - 0s 348us/step - loss: 0.0422 - predict_loss: 0.0000e+00 - loss_loss: 0.0422 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1256/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.0416 - predict_loss: 0.0000e+00 - loss_loss: 0.0416 - val_loss: 0.0410 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0410\n",
      "Epoch 1257/1500\n",
      "204/204 [==============================] - 0s 344us/step - loss: 0.0428 - predict_loss: 0.0000e+00 - loss_loss: 0.0428 - val_loss: 0.0405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0405\n",
      "Epoch 1258/1500\n",
      "204/204 [==============================] - 0s 392us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1259/1500\n",
      "204/204 [==============================] - 0s 383us/step - loss: 0.0420 - predict_loss: 0.0000e+00 - loss_loss: 0.0420 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1260/1500\n",
      "204/204 [==============================] - 0s 383us/step - loss: 0.0420 - predict_loss: 0.0000e+00 - loss_loss: 0.0420 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1261/1500\n",
      "204/204 [==============================] - 0s 402us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1262/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0416 - predict_loss: 0.0000e+00 - loss_loss: 0.0416 - val_loss: 0.0428 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0428\n",
      "Epoch 1263/1500\n",
      "204/204 [==============================] - 0s 398us/step - loss: 0.0420 - predict_loss: 0.0000e+00 - loss_loss: 0.0420 - val_loss: 0.0406 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0406\n",
      "Epoch 1264/1500\n",
      "204/204 [==============================] - 0s 368us/step - loss: 0.0420 - predict_loss: 0.0000e+00 - loss_loss: 0.0420 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1265/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1266/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0407 - predict_loss: 0.0000e+00 - loss_loss: 0.0407 - val_loss: 0.0400 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0400\n",
      "Epoch 1267/1500\n",
      "204/204 [==============================] - 0s 416us/step - loss: 0.0417 - predict_loss: 0.0000e+00 - loss_loss: 0.0417 - val_loss: 0.0392 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0392\n",
      "Epoch 1268/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0395 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0395\n",
      "Epoch 1269/1500\n",
      "204/204 [==============================] - 0s 488us/step - loss: 0.0416 - predict_loss: 0.0000e+00 - loss_loss: 0.0416 - val_loss: 0.0395 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0395\n",
      "Epoch 1270/1500\n",
      "204/204 [==============================] - 0s 478us/step - loss: 0.0410 - predict_loss: 0.0000e+00 - loss_loss: 0.0410 - val_loss: 0.0392 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0392\n",
      "Epoch 1271/1500\n",
      "204/204 [==============================] - 0s 430us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1272/1500\n",
      "204/204 [==============================] - 0s 356us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1273/1500\n",
      "204/204 [==============================] - 0s 391us/step - loss: 0.0426 - predict_loss: 0.0000e+00 - loss_loss: 0.0426 - val_loss: 0.0404 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0404\n",
      "Epoch 1274/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 358us/step - loss: 0.0407 - predict_loss: 0.0000e+00 - loss_loss: 0.0407 - val_loss: 0.0415 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0415\n",
      "Epoch 1275/1500\n",
      "204/204 [==============================] - 0s 363us/step - loss: 0.0410 - predict_loss: 0.0000e+00 - loss_loss: 0.0410 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1276/1500\n",
      "204/204 [==============================] - 0s 361us/step - loss: 0.0409 - predict_loss: 0.0000e+00 - loss_loss: 0.0409 - val_loss: 0.0433 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0433\n",
      "Epoch 1277/1500\n",
      "204/204 [==============================] - 0s 377us/step - loss: 0.0417 - predict_loss: 0.0000e+00 - loss_loss: 0.0417 - val_loss: 0.0405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0405\n",
      "Epoch 1278/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0400 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0400\n",
      "Epoch 1279/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0377 - predict_loss: 0.0000e+00 - loss_loss: 0.0377 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1280/1500\n",
      "204/204 [==============================] - 0s 291us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1281/1500\n",
      "204/204 [==============================] - 0s 310us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0398 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0398\n",
      "Epoch 1282/1500\n",
      "204/204 [==============================] - 0s 352us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1283/1500\n",
      "204/204 [==============================] - 0s 335us/step - loss: 0.0384 - predict_loss: 0.0000e+00 - loss_loss: 0.0384 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1284/1500\n",
      "204/204 [==============================] - 0s 343us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1285/1500\n",
      "204/204 [==============================] - 0s 363us/step - loss: 0.0404 - predict_loss: 0.0000e+00 - loss_loss: 0.0404 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1286/1500\n",
      "204/204 [==============================] - 0s 389us/step - loss: 0.0408 - predict_loss: 0.0000e+00 - loss_loss: 0.0408 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1287/1500\n",
      "204/204 [==============================] - 0s 357us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1288/1500\n",
      "204/204 [==============================] - 0s 338us/step - loss: 0.0408 - predict_loss: 0.0000e+00 - loss_loss: 0.0408 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1289/1500\n",
      "204/204 [==============================] - 0s 438us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1290/1500\n",
      "204/204 [==============================] - 0s 498us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0405\n",
      "Epoch 1291/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 0.0409 - predict_loss: 0.0000e+00 - loss_loss: 0.0409 - val_loss: 0.0407 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0407\n",
      "Epoch 1292/1500\n",
      "204/204 [==============================] - 0s 451us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1293/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.0382 - predict_loss: 0.0000e+00 - loss_loss: 0.0382 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1294/1500\n",
      "204/204 [==============================] - 0s 428us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1295/1500\n",
      "204/204 [==============================] - 0s 355us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0395 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0395\n",
      "Epoch 1296/1500\n",
      "204/204 [==============================] - 0s 335us/step - loss: 0.0415 - predict_loss: 0.0000e+00 - loss_loss: 0.0415 - val_loss: 0.0395 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0395\n",
      "Epoch 1297/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0384 - predict_loss: 0.0000e+00 - loss_loss: 0.0384 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1298/1500\n",
      "204/204 [==============================] - 0s 337us/step - loss: 0.0411 - predict_loss: 0.0000e+00 - loss_loss: 0.0411 - val_loss: 0.0400 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0400\n",
      "Epoch 1299/1500\n",
      "204/204 [==============================] - 0s 372us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0398 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0398\n",
      "Epoch 1300/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0404 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0404\n",
      "Epoch 1301/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0404 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0404\n",
      "Epoch 1302/1500\n",
      "204/204 [==============================] - 0s 396us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1303/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0404 - predict_loss: 0.0000e+00 - loss_loss: 0.0404 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1304/1500\n",
      "204/204 [==============================] - 0s 338us/step - loss: 0.0410 - predict_loss: 0.0000e+00 - loss_loss: 0.0410 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1305/1500\n",
      "204/204 [==============================] - 0s 388us/step - loss: 0.0406 - predict_loss: 0.0000e+00 - loss_loss: 0.0406 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1306/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 0.0393 - predict_loss: 0.0000e+00 - loss_loss: 0.0393 - val_loss: 0.0392 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0392\n",
      "Epoch 1307/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0395 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0395\n",
      "Epoch 1308/1500\n",
      "204/204 [==============================] - 0s 359us/step - loss: 0.0406 - predict_loss: 0.0000e+00 - loss_loss: 0.0406 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1309/1500\n",
      "204/204 [==============================] - 0s 364us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1310/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.0376 - predict_loss: 0.0000e+00 - loss_loss: 0.0376 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1311/1500\n",
      "204/204 [==============================] - 0s 344us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0401 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0401\n",
      "Epoch 1312/1500\n",
      "204/204 [==============================] - 0s 383us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1313/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 375us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1314/1500\n",
      "204/204 [==============================] - 0s 500us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1315/1500\n",
      "204/204 [==============================] - 0s 521us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1316/1500\n",
      "204/204 [==============================] - 0s 429us/step - loss: 0.0406 - predict_loss: 0.0000e+00 - loss_loss: 0.0406 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1317/1500\n",
      "204/204 [==============================] - 0s 384us/step - loss: 0.0400 - predict_loss: 0.0000e+00 - loss_loss: 0.0400 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1318/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1319/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.0402 - predict_loss: 0.0000e+00 - loss_loss: 0.0402 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1320/1500\n",
      "204/204 [==============================] - 0s 409us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0399 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0399\n",
      "Epoch 1321/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 0.0406 - predict_loss: 0.0000e+00 - loss_loss: 0.0406 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1322/1500\n",
      "204/204 [==============================] - 0s 406us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0392 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0392\n",
      "Epoch 1323/1500\n",
      "204/204 [==============================] - 0s 380us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0405 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0405\n",
      "Epoch 1324/1500\n",
      "204/204 [==============================] - 0s 432us/step - loss: 0.0404 - predict_loss: 0.0000e+00 - loss_loss: 0.0404 - val_loss: 0.0403 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0403\n",
      "Epoch 1325/1500\n",
      "204/204 [==============================] - 0s 419us/step - loss: 0.0404 - predict_loss: 0.0000e+00 - loss_loss: 0.0404 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1326/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0408 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0408\n",
      "Epoch 1327/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1328/1500\n",
      "204/204 [==============================] - 0s 417us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0400 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0400\n",
      "Epoch 1329/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.0404 - predict_loss: 0.0000e+00 - loss_loss: 0.0404 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1330/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.0406 - predict_loss: 0.0000e+00 - loss_loss: 0.0406 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1331/1500\n",
      "204/204 [==============================] - 0s 401us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1332/1500\n",
      "204/204 [==============================] - 0s 378us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1333/1500\n",
      "204/204 [==============================] - 0s 399us/step - loss: 0.0386 - predict_loss: 0.0000e+00 - loss_loss: 0.0386 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1334/1500\n",
      "204/204 [==============================] - 0s 347us/step - loss: 0.0389 - predict_loss: 0.0000e+00 - loss_loss: 0.0389 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1335/1500\n",
      "204/204 [==============================] - 0s 371us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1336/1500\n",
      "204/204 [==============================] - 0s 327us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0398 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0398\n",
      "Epoch 1337/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1338/1500\n",
      "204/204 [==============================] - 0s 333us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1339/1500\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1340/1500\n",
      "204/204 [==============================] - 0s 326us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0400 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0400\n",
      "Epoch 1341/1500\n",
      "204/204 [==============================] - 0s 307us/step - loss: 0.0375 - predict_loss: 0.0000e+00 - loss_loss: 0.0375 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1342/1500\n",
      "204/204 [==============================] - 0s 336us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1343/1500\n",
      "204/204 [==============================] - 0s 300us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1344/1500\n",
      "204/204 [==============================] - 0s 305us/step - loss: 0.0397 - predict_loss: 0.0000e+00 - loss_loss: 0.0397 - val_loss: 0.0400 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0400\n",
      "Epoch 1345/1500\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1346/1500\n",
      "204/204 [==============================] - 0s 317us/step - loss: 0.0402 - predict_loss: 0.0000e+00 - loss_loss: 0.0402 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1347/1500\n",
      "204/204 [==============================] - 0s 335us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1348/1500\n",
      "204/204 [==============================] - 0s 366us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1349/1500\n",
      "204/204 [==============================] - 0s 386us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1350/1500\n",
      "204/204 [==============================] - 0s 370us/step - loss: 0.0402 - predict_loss: 0.0000e+00 - loss_loss: 0.0402 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1351/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1352/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 366us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1353/1500\n",
      "204/204 [==============================] - 0s 395us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1354/1500\n",
      "204/204 [==============================] - 0s 390us/step - loss: 0.0400 - predict_loss: 0.0000e+00 - loss_loss: 0.0400 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1355/1500\n",
      "204/204 [==============================] - 0s 552us/step - loss: 0.0403 - predict_loss: 0.0000e+00 - loss_loss: 0.0403 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1356/1500\n",
      "204/204 [==============================] - 0s 801us/step - loss: 0.0393 - predict_loss: 0.0000e+00 - loss_loss: 0.0393 - val_loss: 0.0402 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0402\n",
      "Epoch 1357/1500\n",
      "204/204 [==============================] - 0s 526us/step - loss: 0.0379 - predict_loss: 0.0000e+00 - loss_loss: 0.0379 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1358/1500\n",
      "204/204 [==============================] - 0s 451us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0395 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0395\n",
      "Epoch 1359/1500\n",
      "204/204 [==============================] - 0s 460us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1360/1500\n",
      "204/204 [==============================] - 0s 333us/step - loss: 0.0404 - predict_loss: 0.0000e+00 - loss_loss: 0.0404 - val_loss: 0.0396 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0396\n",
      "Epoch 1361/1500\n",
      "204/204 [==============================] - 0s 588us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0392 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0392\n",
      "Epoch 1362/1500\n",
      "204/204 [==============================] - 0s 670us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1363/1500\n",
      "204/204 [==============================] - 0s 541us/step - loss: 0.0376 - predict_loss: 0.0000e+00 - loss_loss: 0.0376 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1364/1500\n",
      "204/204 [==============================] - 0s 513us/step - loss: 0.0397 - predict_loss: 0.0000e+00 - loss_loss: 0.0397 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1365/1500\n",
      "204/204 [==============================] - 0s 467us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1366/1500\n",
      "204/204 [==============================] - 0s 410us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1367/1500\n",
      "204/204 [==============================] - 0s 500us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1368/1500\n",
      "204/204 [==============================] - 0s 465us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1369/1500\n",
      "204/204 [==============================] - 0s 393us/step - loss: 0.0388 - predict_loss: 0.0000e+00 - loss_loss: 0.0388 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1370/1500\n",
      "204/204 [==============================] - 0s 384us/step - loss: 0.0376 - predict_loss: 0.0000e+00 - loss_loss: 0.0376 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1371/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0400 - predict_loss: 0.0000e+00 - loss_loss: 0.0400 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1372/1500\n",
      "204/204 [==============================] - 0s 500us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1373/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0394 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0394\n",
      "Epoch 1374/1500\n",
      "204/204 [==============================] - 0s 402us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1375/1500\n",
      "204/204 [==============================] - 0s 397us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1376/1500\n",
      "204/204 [==============================] - 0s 418us/step - loss: 0.0376 - predict_loss: 0.0000e+00 - loss_loss: 0.0376 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1377/1500\n",
      "204/204 [==============================] - 0s 419us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1378/1500\n",
      "204/204 [==============================] - 0s 446us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1379/1500\n",
      "204/204 [==============================] - 0s 478us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1380/1500\n",
      "204/204 [==============================] - 0s 428us/step - loss: 0.0380 - predict_loss: 0.0000e+00 - loss_loss: 0.0380 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1381/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1382/1500\n",
      "204/204 [==============================] - 0s 429us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0393 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0393\n",
      "Epoch 1383/1500\n",
      "204/204 [==============================] - 0s 446us/step - loss: 0.0375 - predict_loss: 0.0000e+00 - loss_loss: 0.0375 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1384/1500\n",
      "204/204 [==============================] - 0s 408us/step - loss: 0.0389 - predict_loss: 0.0000e+00 - loss_loss: 0.0389 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1385/1500\n",
      "204/204 [==============================] - 0s 355us/step - loss: 0.0363 - predict_loss: 0.0000e+00 - loss_loss: 0.0363 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1386/1500\n",
      "204/204 [==============================] - 0s 446us/step - loss: 0.0362 - predict_loss: 0.0000e+00 - loss_loss: 0.0362 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1387/1500\n",
      "204/204 [==============================] - 0s 391us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1388/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1389/1500\n",
      "204/204 [==============================] - 0s 410us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1390/1500\n",
      "204/204 [==============================] - 0s 365us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1391/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 382us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1392/1500\n",
      "204/204 [==============================] - 0s 363us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1393/1500\n",
      "204/204 [==============================] - 0s 498us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1394/1500\n",
      "204/204 [==============================] - 0s 452us/step - loss: 0.0397 - predict_loss: 0.0000e+00 - loss_loss: 0.0397 - val_loss: 0.0391 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0391\n",
      "Epoch 1395/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0392 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0392\n",
      "Epoch 1396/1500\n",
      "204/204 [==============================] - 0s 352us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1397/1500\n",
      "204/204 [==============================] - 0s 399us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1398/1500\n",
      "204/204 [==============================] - 0s 399us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1399/1500\n",
      "204/204 [==============================] - 0s 407us/step - loss: 0.0389 - predict_loss: 0.0000e+00 - loss_loss: 0.0389 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1400/1500\n",
      "204/204 [==============================] - 0s 432us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1401/1500\n",
      "204/204 [==============================] - 0s 395us/step - loss: 0.0393 - predict_loss: 0.0000e+00 - loss_loss: 0.0393 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1402/1500\n",
      "204/204 [==============================] - 0s 367us/step - loss: 0.0401 - predict_loss: 0.0000e+00 - loss_loss: 0.0401 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1403/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 0.0402 - predict_loss: 0.0000e+00 - loss_loss: 0.0402 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1404/1500\n",
      "204/204 [==============================] - 0s 377us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1405/1500\n",
      "204/204 [==============================] - 0s 413us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1406/1500\n",
      "204/204 [==============================] - 0s 357us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1407/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0388 - predict_loss: 0.0000e+00 - loss_loss: 0.0388 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1408/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.0400 - predict_loss: 0.0000e+00 - loss_loss: 0.0400 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1409/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.0369 - predict_loss: 0.0000e+00 - loss_loss: 0.0369 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1410/1500\n",
      "204/204 [==============================] - 0s 471us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1411/1500\n",
      "204/204 [==============================] - 0s 388us/step - loss: 0.0372 - predict_loss: 0.0000e+00 - loss_loss: 0.0372 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1412/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.0398 - predict_loss: 0.0000e+00 - loss_loss: 0.0398 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1413/1500\n",
      "204/204 [==============================] - 0s 313us/step - loss: 0.0387 - predict_loss: 0.0000e+00 - loss_loss: 0.0387 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1414/1500\n",
      "204/204 [==============================] - 0s 345us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1415/1500\n",
      "204/204 [==============================] - 0s 304us/step - loss: 0.0388 - predict_loss: 0.0000e+00 - loss_loss: 0.0388 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1416/1500\n",
      "204/204 [==============================] - 0s 305us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1417/1500\n",
      "204/204 [==============================] - 0s 308us/step - loss: 0.0368 - predict_loss: 0.0000e+00 - loss_loss: 0.0368 - val_loss: 0.0385 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0385\n",
      "Epoch 1418/1500\n",
      "204/204 [==============================] - 0s 330us/step - loss: 0.0405 - predict_loss: 0.0000e+00 - loss_loss: 0.0405 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1419/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0397 - predict_loss: 0.0000e+00 - loss_loss: 0.0397 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1420/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1421/1500\n",
      "204/204 [==============================] - 0s 324us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1422/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1423/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1424/1500\n",
      "204/204 [==============================] - 0s 316us/step - loss: 0.0383 - predict_loss: 0.0000e+00 - loss_loss: 0.0383 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1425/1500\n",
      "204/204 [==============================] - 0s 315us/step - loss: 0.0383 - predict_loss: 0.0000e+00 - loss_loss: 0.0383 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1426/1500\n",
      "204/204 [==============================] - 0s 387us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1427/1500\n",
      "204/204 [==============================] - 0s 381us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1428/1500\n",
      "204/204 [==============================] - 0s 397us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0390 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0390\n",
      "Epoch 1429/1500\n",
      "204/204 [==============================] - 0s 400us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1430/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 397us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1431/1500\n",
      "204/204 [==============================] - 0s 364us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1432/1500\n",
      "204/204 [==============================] - 0s 319us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1433/1500\n",
      "204/204 [==============================] - 0s 303us/step - loss: 0.0399 - predict_loss: 0.0000e+00 - loss_loss: 0.0399 - val_loss: 0.0385 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0385\n",
      "Epoch 1434/1500\n",
      "204/204 [==============================] - 0s 301us/step - loss: 0.0383 - predict_loss: 0.0000e+00 - loss_loss: 0.0383 - val_loss: 0.0385 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0385\n",
      "Epoch 1435/1500\n",
      "204/204 [==============================] - 0s 465us/step - loss: 0.0370 - predict_loss: 0.0000e+00 - loss_loss: 0.0370 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1436/1500\n",
      "204/204 [==============================] - 0s 374us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1437/1500\n",
      "204/204 [==============================] - 0s 298us/step - loss: 0.0388 - predict_loss: 0.0000e+00 - loss_loss: 0.0388 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1438/1500\n",
      "204/204 [==============================] - 0s 320us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1439/1500\n",
      "204/204 [==============================] - 0s 327us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1440/1500\n",
      "204/204 [==============================] - 0s 391us/step - loss: 0.0382 - predict_loss: 0.0000e+00 - loss_loss: 0.0382 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1441/1500\n",
      "204/204 [==============================] - 0s 428us/step - loss: 0.0393 - predict_loss: 0.0000e+00 - loss_loss: 0.0393 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1442/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0387 - predict_loss: 0.0000e+00 - loss_loss: 0.0387 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1443/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1444/1500\n",
      "204/204 [==============================] - 0s 349us/step - loss: 0.0388 - predict_loss: 0.0000e+00 - loss_loss: 0.0388 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1445/1500\n",
      "204/204 [==============================] - 0s 292us/step - loss: 0.0387 - predict_loss: 0.0000e+00 - loss_loss: 0.0387 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1446/1500\n",
      "204/204 [==============================] - 0s 293us/step - loss: 0.0389 - predict_loss: 0.0000e+00 - loss_loss: 0.0389 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1447/1500\n",
      "204/204 [==============================] - 0s 341us/step - loss: 0.0384 - predict_loss: 0.0000e+00 - loss_loss: 0.0384 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1448/1500\n",
      "204/204 [==============================] - 0s 365us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1449/1500\n",
      "204/204 [==============================] - 0s 443us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1450/1500\n",
      "204/204 [==============================] - 0s 308us/step - loss: 0.0385 - predict_loss: 0.0000e+00 - loss_loss: 0.0385 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1451/1500\n",
      "204/204 [==============================] - 0s 294us/step - loss: 0.0389 - predict_loss: 0.0000e+00 - loss_loss: 0.0389 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1452/1500\n",
      "204/204 [==============================] - 0s 297us/step - loss: 0.0386 - predict_loss: 0.0000e+00 - loss_loss: 0.0386 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1453/1500\n",
      "204/204 [==============================] - 0s 299us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1454/1500\n",
      "204/204 [==============================] - 0s 356us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1455/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1456/1500\n",
      "204/204 [==============================] - 0s 337us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1457/1500\n",
      "204/204 [==============================] - 0s 485us/step - loss: 0.0388 - predict_loss: 0.0000e+00 - loss_loss: 0.0388 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1458/1500\n",
      "204/204 [==============================] - 0s 444us/step - loss: 0.0388 - predict_loss: 0.0000e+00 - loss_loss: 0.0388 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1459/1500\n",
      "204/204 [==============================] - 0s 327us/step - loss: 0.0397 - predict_loss: 0.0000e+00 - loss_loss: 0.0397 - val_loss: 0.0389 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0389\n",
      "Epoch 1460/1500\n",
      "204/204 [==============================] - 0s 306us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1461/1500\n",
      "204/204 [==============================] - 0s 426us/step - loss: 0.0368 - predict_loss: 0.0000e+00 - loss_loss: 0.0368 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1462/1500\n",
      "204/204 [==============================] - 0s 424us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0385 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0385\n",
      "Epoch 1463/1500\n",
      "204/204 [==============================] - 0s 330us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1464/1500\n",
      "204/204 [==============================] - 0s 385us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1465/1500\n",
      "204/204 [==============================] - 0s 362us/step - loss: 0.0393 - predict_loss: 0.0000e+00 - loss_loss: 0.0393 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1466/1500\n",
      "204/204 [==============================] - 0s 436us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1467/1500\n",
      "204/204 [==============================] - 0s 383us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1468/1500\n",
      "204/204 [==============================] - 0s 321us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1469/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 0s 355us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1470/1500\n",
      "204/204 [==============================] - 0s 460us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1471/1500\n",
      "204/204 [==============================] - 0s 415us/step - loss: 0.0373 - predict_loss: 0.0000e+00 - loss_loss: 0.0373 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1472/1500\n",
      "204/204 [==============================] - 0s 364us/step - loss: 0.0362 - predict_loss: 0.0000e+00 - loss_loss: 0.0362 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1473/1500\n",
      "204/204 [==============================] - 0s 333us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1474/1500\n",
      "204/204 [==============================] - 0s 391us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1475/1500\n",
      "204/204 [==============================] - 0s 360us/step - loss: 0.0374 - predict_loss: 0.0000e+00 - loss_loss: 0.0374 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1476/1500\n",
      "204/204 [==============================] - 0s 381us/step - loss: 0.0375 - predict_loss: 0.0000e+00 - loss_loss: 0.0375 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1477/1500\n",
      "204/204 [==============================] - 0s 519us/step - loss: 0.0393 - predict_loss: 0.0000e+00 - loss_loss: 0.0393 - val_loss: 0.0388 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0388\n",
      "Epoch 1478/1500\n",
      "204/204 [==============================] - 0s 488us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1479/1500\n",
      "204/204 [==============================] - 0s 504us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1480/1500\n",
      "204/204 [==============================] - 0s 507us/step - loss: 0.0373 - predict_loss: 0.0000e+00 - loss_loss: 0.0373 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1481/1500\n",
      "204/204 [==============================] - 0s 569us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1482/1500\n",
      "204/204 [==============================] - 0s 509us/step - loss: 0.0393 - predict_loss: 0.0000e+00 - loss_loss: 0.0393 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1483/1500\n",
      "204/204 [==============================] - 0s 499us/step - loss: 0.0380 - predict_loss: 0.0000e+00 - loss_loss: 0.0380 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1484/1500\n",
      "204/204 [==============================] - 0s 476us/step - loss: 0.0384 - predict_loss: 0.0000e+00 - loss_loss: 0.0384 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1485/1500\n",
      "204/204 [==============================] - 0s 496us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1486/1500\n",
      "204/204 [==============================] - 0s 821us/step - loss: 0.0391 - predict_loss: 0.0000e+00 - loss_loss: 0.0391 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1487/1500\n",
      "204/204 [==============================] - 0s 566us/step - loss: 0.0383 - predict_loss: 0.0000e+00 - loss_loss: 0.0383 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1488/1500\n",
      "204/204 [==============================] - 0s 412us/step - loss: 0.0378 - predict_loss: 0.0000e+00 - loss_loss: 0.0378 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1489/1500\n",
      "204/204 [==============================] - 0s 417us/step - loss: 0.0396 - predict_loss: 0.0000e+00 - loss_loss: 0.0396 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1490/1500\n",
      "204/204 [==============================] - 0s 427us/step - loss: 0.0389 - predict_loss: 0.0000e+00 - loss_loss: 0.0389 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1491/1500\n",
      "204/204 [==============================] - 0s 356us/step - loss: 0.0382 - predict_loss: 0.0000e+00 - loss_loss: 0.0382 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1492/1500\n",
      "204/204 [==============================] - 0s 371us/step - loss: 0.0383 - predict_loss: 0.0000e+00 - loss_loss: 0.0383 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1493/1500\n",
      "204/204 [==============================] - 0s 403us/step - loss: 0.0392 - predict_loss: 0.0000e+00 - loss_loss: 0.0392 - val_loss: 0.0387 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0387\n",
      "Epoch 1494/1500\n",
      "204/204 [==============================] - 0s 414us/step - loss: 0.0393 - predict_loss: 0.0000e+00 - loss_loss: 0.0393 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1495/1500\n",
      "204/204 [==============================] - 0s 391us/step - loss: 0.0379 - predict_loss: 0.0000e+00 - loss_loss: 0.0379 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1496/1500\n",
      "204/204 [==============================] - 0s 410us/step - loss: 0.0390 - predict_loss: 0.0000e+00 - loss_loss: 0.0390 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1497/1500\n",
      "204/204 [==============================] - 0s 389us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1498/1500\n",
      "204/204 [==============================] - 0s 414us/step - loss: 0.0394 - predict_loss: 0.0000e+00 - loss_loss: 0.0394 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n",
      "Epoch 1499/1500\n",
      "204/204 [==============================] - 0s 375us/step - loss: 0.0379 - predict_loss: 0.0000e+00 - loss_loss: 0.0379 - val_loss: 0.0385 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0385\n",
      "Epoch 1500/1500\n",
      "204/204 [==============================] - 0s 423us/step - loss: 0.0395 - predict_loss: 0.0000e+00 - loss_loss: 0.0395 - val_loss: 0.0386 - val_predict_loss: 0.0000e+00 - val_loss_loss: 0.0386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c90a81f98>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now run the training!\n",
    "INPUT_LENGTH = 8\n",
    "OUTPUT_LENGTH = 4\n",
    "TOTAL_LENGTH = INPUT_LENGTH + OUTPUT_LENGTH\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "inp_ph,target_ph, model, params, loss = vanilla_lstm_model(128,\n",
    "                                                           INPUT_LENGTH,\n",
    "                                                           OUTPUT_LENGTH,\n",
    "                                                          1e-3)\n",
    "model.summary()\n",
    "indices, input_batch, target_batch = get_batch(normalized_data,BATCH_SIZE,INPUT_LENGTH,OUTPUT_LENGTH)\n",
    "\n",
    "# prepare data\n",
    "input_batch_padded = np.hstack([input_batch,np.zeros((BATCH_SIZE,OUTPUT_LENGTH,2))])\n",
    "target_batch_padded = np.hstack([np.zeros((BATCH_SIZE,INPUT_LENGTH,2)),target_batch])\n",
    "\n",
    "\n",
    "# and train\n",
    "model.fit(\n",
    "    [input_batch_padded,target_batch_padded],\n",
    "    [np.zeros((BATCH_SIZE,TOTAL_LENGTH,2)),np.zeros(BATCH_SIZE)],\n",
    "    epochs = 1500,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = get_callbacks(input_batch_padded,target_batch_padded)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning\n",
    "# model.compile(optimizer=optimizers.RMSprop(lr = 1e-5, clipvalue = 10.),\n",
    "#               loss= {\n",
    "#                     'predict': lambda _, loss: loss - loss,\n",
    "#                       'loss': lambda _, loss: loss\n",
    "#                 })\n",
    "# # and train\n",
    "# model.fit(\n",
    "#     [input_batch_padded,target_batch_padded],\n",
    "#     [np.zeros((BATCH_SIZE,TOTAL_LENGTH,2)),np.zeros(BATCH_SIZE)],\n",
    "#     epochs = 500,\n",
    "    \n",
    "#     callbacks = get_callbacks(input_batch_padded,target_batch_padded, True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Function that takes a \"close\" look of each tragectory\n",
    "    Input:\n",
    "        model: trained Keras model\n",
    "        input: the batch of input of shape (N, input_length + target_length, 2)\n",
    "        target: the batch of input of the same shape with input\n",
    "        input_length: self-explanatory\n",
    "    Output:\n",
    "        Nothing, but generate N pictures of the plot with:\n",
    "            target tragectories (should be input_length + target_length long) in black,\n",
    "            predicted tragectories (shoudl be target_length long) in blue\n",
    "'''\n",
    "def close_visualize(model, input_batch,target_batch,input_length):\n",
    "    if not input_batch.shape == target_batch.shape:\n",
    "        raise ValueError(\"input batch and target batch should have the same size\")\n",
    "    batch_size,_,__ = input_batch.shape\n",
    "    \n",
    "    prediction, loss = model.predict([input_batch,target_batch])\n",
    "    for batch_id in range(batch_size):\n",
    "        # first clear the plot...\n",
    "        plt.gcf().clear()\n",
    "        \n",
    "        # then retrieve the tragectories\n",
    "        target_tragectories = target_batch[batch_id][input_length:]\n",
    "        predicted_tragectories = prediction[batch_id]\n",
    "        # evaluate the boundary to plot\n",
    "        x_min = np.min(target_tragectories[:,0] - .1)\n",
    "        x_max = np.max(target_tragectories[:,0] + .1)\n",
    "        \n",
    "        y_min = np.min(target_tragectories[:,1] - .1)\n",
    "        y_max = np.max(target_tragectories[:,1] + .1)\n",
    "        \n",
    "        x_min_predicted = np.min(predicted_tragectories[:,0] - .1)\n",
    "        x_max_predicted = np.max(predicted_tragectories[:,0] + .1)\n",
    "        \n",
    "        y_min_predicted = np.min(predicted_tragectories[:,1] - .1)\n",
    "        y_max_predicted = np.max(predicted_tragectories[:,1] + .1)\n",
    "        \n",
    "        # set the boundary\n",
    "        x_min = min(x_min,x_min_predicted)\n",
    "        x_max = max(x_max,x_max_predicted)\n",
    "        y_min = min(y_min,y_min_predicted)\n",
    "        y_max = max(y_max,y_max_predicted)\n",
    "        \n",
    "        plt.xlim(x_min,x_max)\n",
    "        plt.ylim(y_min,y_max)\n",
    "        # plot line...\n",
    "        # first the target tragectories\n",
    "#         plt.plot(target_tragectories[:,0],target_tragectories[:,1],c = 'black')\n",
    "        # then the prediction\n",
    "        for i in range(len(target_tragectories) - 1):\n",
    "            cur_point = target_tragectories[i,:]\n",
    "            next_point = target_tragectories[i + 1,:]\n",
    "            plt.plot([cur_point[0],next_point[0]],[cur_point[1],next_point[1]],c = 'black')\n",
    "            # and predicted...\n",
    "            cur_point = predicted_tragectories[i,:]\n",
    "            next_point = predicted_tragectories[i + 1,:]\n",
    "            plt.plot([cur_point[0],next_point[0]],[cur_point[1],next_point[1]],\n",
    "                     c = 'blue',\n",
    "                     linestyle = ':'\n",
    "            )\n",
    "#         plt.plot(predicted_tragectories[:,0],\n",
    "#                   predicted_tragectories[:,1],\n",
    "#                   linestyle = ':',\n",
    "#                   c = 'blue')\n",
    "        # then save the plot...\n",
    "        plt.savefig('close-{}.png'.format(batch_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGhpJREFUeJzt3X+UVXW9//HnS36qyA1lynvlZ8nggCnIkcREqBaKioHabWEXtTLIVvTDzCt4yx+4TDSW2W3N7YZG+HUtY5GmdxSLUCSxrxRDAjLIjECpYAVeMK8/kl/v+8feXI4TMmeYM3PmzH491jpr9v6cz+fw/qw9vM6evc/ZWxGBmZllwxGlLsDMzNqOQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5llSOdSF9BY7969Y8CAAaUuw8ysrKxaterViKhoql+7C/0BAwZQW1tb6jLMzMqKpBcL6efDO2ZmGeLQNzPLEIe+mVmGFBT6ksZLqpe0UdKMgzzfX9ITktZKWiapT95zV0h6IX1cUczizcyseZoMfUmdgGrgPGAIcKmkIY26zQH+X0ScAswCbkvHHgvcCHwEGAncKKlX8co3M7PmKGRPfySwMSI2R8QuYAEwsVGfIcDSdPnJvOfPBZZExI6I2AksAca3vGwzMzschYT+CcDLeetb0rZ8a4CL0+WLgGMkHVfgWCRNk1QrqXb79u2F1m5mZs1UrBO53wTGSHoWGANsBfYWOjgi5kZELiJyFRVNfrfAzMwOUyFfztoK9M1b75O2/Z+IeIV0T19SD+CSiHhN0lZgbKOxy1pQr5mZtUAhe/orgUGSBkrqCkwGavI7SOotaf9rzQTmpcuLgXMk9UpP4J6TtpmZWQk0GfoRsQeYThLWzwMLI6JO0ixJn0y7jQXqJTUAHwBuTcfuAG4heeNYCcxK28zMrAQUEaWu4V1yuVz42jtmZs0jaVVE5Jrq52/kmplliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhhQU+pLGS6qXtFHSjIM830/Sk5KelbRW0vlp+wBJb0tanT7+s9gTMDOzwnVuqoOkTkA1MA7YAqyUVBMR6/O6fQtYGBE/lDQEeAwYkD63KSKGFbdsMzM7HIXs6Y8ENkbE5ojYBSwAJjbqE0DPdPkfgFeKV6KZmRVLIaF/AvBy3vqWtC3fTcAUSVtI9vK/kvfcwPSwz68ljT7YPyBpmqRaSbXbt28vvHozM2uWYp3IvRSYHxF9gPOB+yQdAfwJ6BcRw4FvAPdL6tl4cETMjYhcROQqKiqKVJKZmTVWSOhvBfrmrfdJ2/JdCSwEiIhngO5A74h4JyL+O21fBWwCKltatJmZHZ5CQn8lMEjSQEldgclATaM+LwGfAJBURRL62yVVpCeCkfRBYBCwuVjFm5lZ8zT56Z2I2CNpOrAY6ATMi4g6SbOA2oioAa4B7pZ0NclJ3c9GREg6G5glaTewD7gqIna02mzMzOyQFBGlruFdcrlc1NbWlroMM7OyImlVROSa6udv5JqZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6FurmzMHrrkG9u0rdSVm5tC3VrdlC/zhD3BE+tv2P/9T2nrMssyhb63urrvggQeS5W3boG9fmDevtDWZZZVD39rE/r18CS6/HM48M1nfsgXWrStdXWZZ49C3NlVRAf/+73DSScn67Nlw+umwc2dp6zLLioJCX9J4SfWSNkqacZDn+0l6UtKzktZKOj/vuZnpuHpJ5xazeCt/N98MCxdCr17J+h13wIoVpa3JrCPr3FQHSZ2AamAcsAVYKakmItbndfsWsDAifihpCPAYMCBdngwMBf4JeFxSZUTsLfZErDwddxxceGGy/PrrcOed8NprcMYZpa3LrKMqZE9/JLAxIjZHxC5gATCxUZ8AeqbL/wC8ki5PBBZExDsR8QdgY/p6Zn+nZ0/YtAlmpH9L/va3MGoUbNxY2rrMOpJCQv8E4OW89S1pW76bgCmStpDs5X+lGWORNE1SraTa7du3F1i6dURHH52EPyTH+Xftgg98IFnfts2f9TdrqWKdyL0UmB8RfYDzgfskFfzaETE3InIRkauoqChSSVbuxo+H2lo45hiIgIsvhgsuKHVVZuWtyWP6wFagb956n7Qt35XAeICIeEZSd6B3gWPN3pN0YHn6dOjUKVnety85AXzxxdC1a2lqMytHheyNrwQGSRooqSvJidmaRn1eAj4BIKkK6A5sT/tNltRN0kBgEPC7YhVv2SHB5Mnwz/+crD/+OFx6KTz8cGnrMis3Te7pR8QeSdOBxUAnYF5E1EmaBdRGRA1wDXC3pKtJTup+NiICqJO0EFgP7AG+7E/uWDGMGwdLlsDYscn6woXw8svwta9B50L+fjXLKCXZ3H7kcrmora0tdRlWZqZOhWefhZUrk78K9u078C1gsyyQtCoick31838L6xDuvhuefDIJ/LffhiFD4L77Sl2VWfvj0LcO45hjkp9//SucfDL065esv/46/OlPpavLrD1x6FuHc/zxyVU9x4xJ1r//ffjQh+DPfy5tXWbtgU95WYd36aXwvvclbwaQnPQdMSJ5IzDLGu/pW4d34onwlfQ74n/7G3zpS3DjjaWtyaxUHPpW1vbt28eiRYso9FNo3bsn1++/9dZkfds2eOqpVizQrJ1x6FtZe+ihh5gwYQJjx45l7dq1BY35x3+E/v2T5VtvhXPOgb/8pRWLNGtHHPpW1iZNmsTcuXOpq6tj+PDhfPWrX+W1114rePx3vgM1NQcu6lZf30qFmrUTDn0ra506dWLq1Kk0NDRw1VVXUV1dTWVlJfPmzWNfAZfkPProZE8f4He/g6oqf77fOjaHvnUIxx57LNXV1axatYrKykquvPJKRo0axcqVKwt+jVNPTfb8J01K1t94o5WKNSshh751KMOGDWP58uXcd999vPTSS3zkIx9h6tSpFHKfhm7dkhu4HHNMchmH8ePhC19og6LN2pBD3zocSUyZMoX6+nq+8Y1vMH/+fCorK6murmbPnj0Fvca+fTBhAnzsY8l6RPIwK3cOfeuwevbsyZw5c1izZg0jRoxg+vTp5HI5nn766SbHdu6c7PX/y78k6w88AOedBzt2tHLRZq3MoW8d3pAhQ1iyZAkPPPAAO3bsYPTo0UyZMoVXXnml6cGpN9+Ed945cCtHs3Ll0LdMkMQll1zChg0b+Na3vsXPfvYzBg8ezJw5c9i1a1eT4z/7WVi6NPkL4K234LLLoKGh9es2KzaHvmXKUUcdxS233EJdXR1jx47l2muv5dRTT2XJkiVNjt1/68Z162DRItjqG39aGXLoWyadeOKJPPLIIzz66KPs3r2bc845h0suuYQXX3yxybEjR8KLLx44yfvTn0KBXwY2KzmHvmXaBRdcwLp167j11lv5xS9+QVVVFbfccgt/+9vfDjlu/7X7d+2C66+HWbPaoFizInDoW+Z1796d66+/ng0bNjBhwgRuuOEGhg4dSk1NTZMXcuvaFWprobo6Wd+2DX772zYo2uwwOfTNUv369WPhwoU88cQTdO/enYkTJ3LBBRfwwgsvHHLccccduHbPzTcnh31efbUNCjY7DA59s0Y+/vGPs3r1au68806efvpphg4dyqhRowr6Vu9tt8GDD0Lv3sn6pk2tXKxZMzn0zQ6iS5cuXH311TQ0NPDhD3+YFStWcPrpp/PLX/7ykON69ky+xAWwYgVUVsKCBW1QsFmBHPpmh3D88cezatUqHnnkEY488kjOO+88Jk+ezJ8LuOHuKafATTcll3OA5PP9ZqXm0DcrwIQJE1i9ejWzZs3ioYce4qSTTuJHP/rRIS/ffNRR8O1vQ48esHcvjBt34LaNZqXi0DcrULdu3fj2t7/Nc889x4gRI7jqqqs466yzeO6555ocu29fct3+M85I1l95Jblfr1lbc+ibNVNlZSWPP/449957Lw0NDZx22mnMnDmTtw5x/KZLl+Rm7Psv4Hb55fDRj/rKndb2HPpmh0ESl19+ORs2bOCyyy5j9uzZnHzyySxevLig8f/2b3DddcmlHSLg+edbuWCzlEPfrAV69+7NvHnzWLZsGV27dmX8+PF85jOfafJE78c+Bp/+dLL82GMwZAj86ldtULBlnkPfrAjGjBnDmjVruPnmm3nwwQepqqpi7ty5Bd2nd/RouP32A9fyqa/3J32s9RQU+pLGS6qXtFHSjIM8/z1Jq9NHg6TX8p7bm/dcTTGLN2tPunXrxg033MDatWsZPnw4X/ziFxk9ejTr1q075LiePeFf/zU57r93L0ycCJ/8ZBsVbZnTZOhL6gRUA+cBQ4BLJQ3J7xMRV0fEsIgYBvwA+Hne02/vfy4i/KtsHd7gwYN54oknuPfee6mvr2f48OFcf/31vP32202O7dQJ7r4bbrghWd+9G5pxb3ezJhWypz8S2BgRmyNiF7AAmHiI/pcCPy1GcWblKv9E75QpU7jtttsKPtE7ejScfXay/OMfJ5dyXrWqlQu2zCgk9E8AXs5b35K2/R1J/YGBwNK85u6SaiWtkDTpPcZNS/vUFnJ9E7Ny0bt3b37yk5/w5JNP0qVLl/870fuXv/yloPFTpiTBf9ppyfozz8Abb7RiwdbhFftE7mTggYjYm9fWPyJywGeAuyR9qPGgiJgbEbmIyFVUVBS5JLPSGzt2LGvWrOGmm27iwQcf5KSTTuLuu+9u8kRvjx7w+c8nH+186y248EKYOrWNirYOqZDQ3wr0zVvvk7YdzGQaHdqJiK3pz83AMmB4s6s06wC6devGjTfeyNq1axk2bBjTpk3j7LPPpq6urqDxRx0Fjz564Hj/zp3w1FOtWLB1SIWE/kpgkKSBkrqSBPvffQpH0klAL+CZvLZekrqly72BjwLri1G4WbkaPHgwS5cuZf78+WzYsIFhw4YxYcIEduzY0eTYM86Aqqpk+XvfSz7m+cc/tm691rE0GfoRsQeYDiwGngcWRkSdpFmS8j+NMxlYEO++1VAVUCtpDfAkMDsiHPqWeZK44oor2LBhA+eeey6LFi2isrKSxx57rODXmDED/uu/YMCAZP3RR+H111unXus41NTt4NpaLpeL2traUpdh1qaqq6v5wQ9+QH19PZdccgl33XUXffr0KXj8tm3Qty986Utw112tWKi1W5JWpedPD8nfyDVrB7785S+zdu1avvOd77Bo0SKqqqq488472bNnT0Hj3/9++M1vYObMZH3TJli69NBjLJsc+mbtRNeuXZk5cybr169nzJgxXHPNNYwYMYJnnnmm6cFALnfgXr133JF8s3fnzlYs2MqSQ9+snRk4cCCPPPIIP//5z9mxYwdnnnkm06ZNK+hE737f/35yAbdevZL1efP8BmAJh75ZOySJiy66iOeff55vfvObzJs3j8GDBzN//nwKOQ/XvTuMGpUsNzTAF76QXN7BzKFv1o716NGD7373u/z+97+nsrKSz33uc4wZM6bgz/ZDcnP2Z589cKvGFSugifu7Wwfm0DcrA6eccgrLly/nnnvuoa6ujmHDhjFjxgzefPPNgsafeioceWSyPGcOfPGL8M47rViwtVsOfbMyccQRR3DllVdSX1/PZZddxu23387QoUOpqWneFcvvvz/Z0+/WrZUKtXbNoW9WZvbfrWv58uX06NGDiRMnMmnSJF566aWCxnfteuBbvZY9Dn2zMnXWWWfx7LPPcscdd7BkyRKqqqq444472L17d6lLs3bMoW9Wxrp06cK1117L+vXrGTduHNdddx3Dhw9n+fLlpS7N2imHvlkH0L9/fx5++GFqamp44403OPvss/n85z/Pq6++WurSrJ1x6Jt1IBdeeCF1dXVcd9113HfffQwePJh77rmnoBu0WzY49M06mKOPPprZs2ezevVqTj75ZKZOncro0aNZu3ZtqUuzdsChb9ZBDR06lGXLljF//nwaGho47bTTWLNmTanLshJz6Jt1YPnX7Z8zZw6nnHJKqUuyEutc6gLMrPUdd9xxfP3rXy91GdYOeE/fzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMqSg0Jc0XlK9pI2SZhzk+e9JWp0+GiS9lvfcFZJeSB9XFLN4MzNrniYvrSypE1ANjAO2ACsl1UTE+v19IuLqvP5fAYany8cCNwI5IIBV6didRZ2FmZkVpJA9/ZHAxojYHBG7gAXAxEP0vxT4abp8LrAkInakQb8EGN+Sgs3M7PAVEvonAC/nrW9J2/6OpP7AQGBpc8eamVnrK/aJ3MnAAxGxtzmDJE2TVCupdvv27UUuyczM9isk9LcCffPW+6RtBzOZA4d2Ch4bEXMjIhcRuYqKigJKMjOzw1FI6K8EBkkaKKkrSbDXNO4k6SSgF/BMXvNi4BxJvST1As5J28zMrASa/PROROyRNJ0krDsB8yKiTtIsoDYi9r8BTAYWRETkjd0h6RaSNw6AWRGxo7hTMDOzQikvo9uFXC4XtbW1pS7DzKysSFoVEbmm+vkbuWZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYhDn0zswxx6JuZZYhD38wsQxz6ZmYZ4tA3M8sQh76ZWYY49M3MMsShb2aWIQ59M7MMceibmWWIQ9/MLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEFhb6k8ZLqJW2UNOM9+nxa0npJdZLuz2vfK2l1+qgpVuFmZtZ8nZvqIKkTUA2MA7YAKyXVRMT6vD6DgJnARyNip6T3573E2xExrMh1m5nZYShkT38ksDEiNkfELmABMLFRn6lAdUTsBIiIbcUt08zMiqGQ0D8BeDlvfUvalq8SqJT0G0krJI3Pe667pNq0fVIL6zUzsxZo8vBOM15nEDAW6AM8JenDEfEa0D8itkr6ILBU0nMRsSl/sKRpwDSAfv36FakkMzNrrJA9/a1A37z1Pmlbvi1ATUTsjog/AA0kbwJExNb052ZgGTC88T8QEXMjIhcRuYqKimZPwszMClNI6K8EBkkaKKkrMBlo/Cmch0n28pHUm+Rwz2ZJvSR1y2v/KLAeMzMriSYP70TEHknTgcVAJ2BeRNRJmgXURkRN+tw5ktYDe4FrI+K/JZ0J/EjSPpI3mNn5n/oxM7O2pYgodQ3vksvlora2ttRlmJmVFUmrIiLXVD9/I9fMLEMc+mZmGeLQNzPLEIe+mVmGOPTNzDLEoW9mliEOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwyxKFvZpYh7e7SypK2Ay8W8SV7A68W8fXaK8+z48nKXD3P4ugfEU3eerDdhX6xSaot5BrT5c7z7HiyMlfPs2358I6ZWYY49M3MMiQLoT+31AW0Ec+z48nKXD3PNtThj+mbmdkBWdjTNzOzVFmHvqSvSVonqU7S1w/R73RJeyR9Kq/tCkkvpI8r2qbiw9PCee6VtDp91LRNxYenqXlKGivpr3nzuSHvufGS6iVtlDSjbStvnhbO84+Snkvba9u28uYp5Pc2nevqtM+v89rLZntCi+fatts0IsryAZwMrAOOAjoDjwMnHqRfJ2Ap8BjwqbTtWGBz+rNXutyr1HMq9jzT9jdKPYdizRMYCzz6HnPfBHwQ6AqsAYaUek7Fnmf63B+B3qWeR5Hm+T5gPdAvXX9/uW3Pls61FNu0nPf0q4DfRsRbEbEH+DVw8UH6fQV4ENiW13YusCQidkTETmAJML61Cz5MLZlnOSl0ngczEtgYEZsjYhewAJjYSnW2VEvmWU4KmedngJ9HxEsAEbH/d7ectie0bK5trpxDfx0wWtJxko4Czgf65neQdAJwEfDDRmNPAF7OW9+StrVHLZknQHdJtZJWSJrU+uUetibnmRolaY2kX0gamrZ1qO2ZOtg8AQL4laRVkqa1RcGHqZB5VgK9JC1L53N52l5O2xNaNldo423aubX/gdYSEc9Luh34FfAmsBrY26jbXcB1EbFPUluXWBRFmGf/iNgq6YPAUknPRcSmVi+8mQqc5+9J5vOGpPOBh4FBbVtpyxRhnmel2/P9wBJJGyLiqbaqv1AFzrMzMAL4BHAk8IykFW1aaBG0ZK4R0UAbb9Ny3tMnIn4cESMi4mxgJ9DQqEsOWCDpj8CngP9I93a38u534j5pW7vUgnkSEVvTn5uBZcDwtqq7uZqaZ0S8HhFvpMuPAV0k9aaDbc9DzDN/e24DHiI5FNIuFfB7uwVYHBFvRsSrwFPAqZTZ9oQWzbXtt2lbnTxojQcHTvz0AzYA7ztE3/m8+0TuH0hO4vZKl48t9XxaYZ69gG7pcm/gBdr3CbFDzhM4ngPfLRkJvASIZC9qMzCQAyf+hpZ6Pq0wz6OBY9L2o4H/D4wv9XxaMM8q4Il0+x1Fcpjk5HLbni2ca5tv07I9vJN6UNJxwG7gyxHxmqSrACLiP99rUETskHQLsDJtmhURO1q/3MN2WPMk+UX7kaR9JH/VzY6I9a1f7mFrap6fAr4kaQ/wNjA5kv8teyRNBxaTfPJjXkTUlWYKBTmseUr6APBQegivM3B/RPyyNFMoyCHnGclhkV8Ca4F9wD0RsQ6gzLYnHOZc08OubbpN/Y1cM7MMKetj+mZm1jwOfTOzDHHom5lliEPfzCxDHPpmZhni0DczyxCHvplZhjj0zcwy5H8BmknetNY32igAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "close_visualize(model,input_batch_padded,target_batch_padded,INPUT_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an overview of the prediction given the whole scene...\n",
    "def visualize_batch_overview(input_batch_padded, target_batch_padded, filename = 'overview.png'):\n",
    "\n",
    "    params, loss = model.predict([input_batch_padded,target_batch_padded])\n",
    "    # visualize the trace, as well as the distributions generated by the params...\n",
    "    # first clear the previous drawing...\n",
    "    #     try:\n",
    "    plt.gcf().clear()\n",
    "    visualize_trace(input_batch,target_batch)\n",
    "    #     params = params[:,INPUT_LENGTH + 1, :] # (B,5), and it should be the params immediately after the input\n",
    "    #     draw_heatmap(params)\n",
    "    draw_mean(params)\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_batch_overview(input_batch_padded, target_batch_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# homemade live loss callback\n",
    "def live_loss_plot(log):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
